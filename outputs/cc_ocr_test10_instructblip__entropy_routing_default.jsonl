{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["901016 -TICKET CP 2 60.000 60.000 TOTAL DISC $ -60.000 TAX 5.455 Subtotal 60.000 TOTAL 60.000 (Qty 2.00 EDC CIMB NIAGA No: xx7730 60.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.8135186210274696, "normalized_entropy_first": 0.0, "min_margin_first": 0.6188249588012695, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 109, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 110, "total_latency_s": 0.11, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.550189971923828, 0.07684727013111115], "entropies_second": null, "final_normalized_entropy": 0.0, "sequence_confidence_first": 0.41208892251014917, "sequence_confidence_second": null, "sequence_confidence_final": 0.41208892251014917, "token_confidences_first": [0.27222755551338196, 0.9869791269302368, 0.26045504212379456], "token_confidences_second": null, "final_mean_entropy": 1.8135186210274696, "final_min_margin": 0.6188249588012695, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9705882352941176, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["J.STB PROMO 17500 Y.B.BAT 46000 Y.BASO PROM 27500 TOTAL 91000 CASH 91000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt", "answer_second": "receipt for a car that was purchased in 2015", "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": "receipt for a car that was purchased in 2015", "mean_entropy_first": 1.792290173470974, "normalized_entropy_first": -21.228447556495667, "min_margin_first": 0.7424259185791016, "mean_entropy_second": 2.492061941751412, "normalized_entropy_second": 678.5433207239424, "min_margin_second": 0.016834259033203125, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 109, "latency_ms_ocr": 1833, "latency_ms_second": 396, "total_latency_ms": 2341, "total_latency_s": 2.341, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.499328136444092, 0.08525221049785614], "entropies_second": [3.4967989921569824, 0.13032802939414978, 2.8204541206359863, 3.2138614654541016, 4.510390281677246, 4.177950859069824, 2.603543996810913, 3.0449342727661133, 2.7959275245666504, 4.228205680847168, 0.8570950627326965, 0.2164653092622757, 0.8459356427192688, 1.9469759464263916], "final_normalized_entropy": -21.228447556495667, "sequence_confidence_first": 0.4446549515438094, "sequence_confidence_second": 0.3464021630911758, "sequence_confidence_final": 0.4446549515438094, "token_confidences_first": [0.3053000271320343, 0.9851621985435486, 0.29230403900146484], "token_confidences_second": [0.30978551506996155, 0.9766840934753418, 0.2458411306142807, 0.4261934161186218, 0.11391850560903549, 0.1639615297317505, 0.2665826380252838, 0.38233548402786255, 0.20039068162441254, 0.18311911821365356, 0.7126293182373047, 0.9755129814147949, 0.5347894430160522, 0.3133891224861145, 0.4808892011642456], "final_mean_entropy": 1.792290173470974, "final_min_margin": 0.7424259185791016, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9583333333333334, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["CINNAMON SUGAR 1 x 17,000 17,000 SUB TOTAL 17,000 GRAND TOTAL 17,000 CASH IDR 20,000 CHANGE DUE 3,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for cinnamon bun and sub total of $20.95", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for cinnamon bun and sub total of $20.95", "raw_answer_second": "receipt", "mean_entropy_first": 2.031019822743378, "normalized_entropy_first": 34.48580745044661, "min_margin_first": 0.09621810913085938, "mean_entropy_second": 2.015839360654354, "normalized_entropy_second": 32.10214090290087, "min_margin_second": 0.5507478713989258, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 495, "latency_ms_ocr": 114, "latency_ms_second": 125, "total_latency_ms": 736, "total_latency_s": 0.736, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.323401927947998, 0.06133522465825081, 3.401587724685669, 3.5647716522216797, 1.3730809688568115, 0.1928958147764206, 0.04499262571334839, 2.719674587249756, 0.5582910180091858, 3.011878252029419, 3.7012219429016113, 1.6092801094055176, 2.920405149459839, 1.2775821685791016, 1.7385340929031372, 2.117300033569336, 2.7806077003479004, 2.2419276237487793, 1.9506080150604248], "entropies_second": [3.9739933013916016, 0.05768541991710663], "final_normalized_entropy": 32.10214090290087, "sequence_confidence_first": 0.4732166105795861, "sequence_confidence_second": 0.4469221456477248, "sequence_confidence_final": 0.4469221456477248, "token_confidences_first": [0.39460426568984985, 0.9904749989509583, 0.287138432264328, 0.3687823712825775, 0.6798142790794373, 0.9692914485931396, 0.9955304265022278, 0.38989004492759705, 0.8544586896896362, 0.37129727005958557, 0.2868856191635132, 0.6142799258232117, 0.26096102595329285, 0.486775666475296, 0.48242270946502686, 0.4348004162311554, 0.20109105110168457, 0.3206888437271118, 0.405160129070282, 0.7696230411529541], "token_confidences_second": [0.20155981183052063, 0.9908724427223206, 0.44696542620658875], "final_mean_entropy": 2.015839360654354, "final_min_margin": 0.5507478713989258, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9702970297029703, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 BANABERRY FRESH CREAM CAK 230,000 TOTAL 230,000 CASH 230,000 CHANGE 0"], "experiment": "entropy_routing_default", "routed": {"answer": "banana berry", "used_ocr": true, "answer_first": "receipt", "answer_second": "banana berry", "raw_answer": "banana berry", "raw_answer_first": "receipt", "raw_answer_second": "banana berry", "mean_entropy_first": 2.1384633537381887, "normalized_entropy_first": 4.61137218310844, "min_margin_first": 0.7642288208007812, "mean_entropy_second": 1.8291095197200775, "normalized_entropy_second": -0.06421444083368935, "min_margin_second": 1.1066608428955078, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 105, "latency_ms_ocr": 57, "latency_ms_second": 169, "total_latency_ms": 332, "total_latency_s": 0.332, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.226307392120361, 0.05061931535601616], "entropies_second": [3.730353832244873, 1.91315758228302, 1.5959872007369995, 0.07693946361541748], "final_normalized_entropy": -0.06421444083368935, "sequence_confidence_first": 0.37438611478948197, "sequence_confidence_second": 0.5507527854444125, "sequence_confidence_final": 0.5507527854444125, "token_confidences_first": [0.23279361426830292, 0.9923570156097412, 0.22715389728546143], "token_confidences_second": [0.3279908001422882, 0.5390552282333374, 0.6843584775924683, 0.9914576411247253, 0.4224066734313965], "final_mean_entropy": 1.8291095197200775, "final_min_margin": 1.1066608428955078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9014084507042254, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["0571-1854 BLUS WANITA 1 @120,000 0% 120,000 1002-0060 SHOPPING BAG 1 @880 100% 0 TOTAL 120,000 (2 item) CC.Visa.BCA 120,000 Total Kembalian 0"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt", "answer_second": "29", "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": "29", "mean_entropy_first": 1.7255234755575657, "normalized_entropy_first": -1.2465107053693503, "min_margin_first": 0.789398193359375, "mean_entropy_second": 2.7760942379633584, "normalized_entropy_second": 8.219285634147282, "min_margin_second": 0.047519683837890625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 109, "latency_ms_ocr": 102, "latency_ms_second": 168, "total_latency_ms": 382, "total_latency_s": 0.382, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.3751144409179688, 0.07593251019716263], "entropies_second": [4.145900249481201, 1.8395506143569946, 2.34283185005188], "final_normalized_entropy": -1.2465107053693503, "sequence_confidence_first": 0.4332133848086453, "sequence_confidence_second": 0.35100820209893996, "sequence_confidence_final": 0.4332133848086453, "token_confidences_first": [0.33425381779670715, 0.987811267375946, 0.2462380975484848], "token_confidences_second": [0.14567025005817413, 0.44176971912384033, 0.47097069025039673, 0.5008507966995239], "final_mean_entropy": 1.7255234755575657, "final_min_margin": 0.789398193359375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9716312056737588, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["BASO KUAH 1 43.636 43.636 A.MINERAL GELAS 1 3,000 3,000 TOTAL 46.636 DPP 46.636 TAX 10.00 % 4.664 GRAND TOTAL 51.300 TUNAI 52.000 KEMBALI 700"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for food", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for food", "raw_answer_second": "receipt", "mean_entropy_first": 2.8130833245813847, "normalized_entropy_first": 8.50935864204187, "min_margin_first": 0.015890121459960938, "mean_entropy_second": 2.2142315581440926, "normalized_entropy_second": 3.2179937504307197, "min_margin_second": 1.3474626541137695, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 157, "latency_ms_ocr": 177, "latency_ms_second": 147, "total_latency_ms": 483, "total_latency_s": 0.483, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.5477538108825684, 0.08763469755649567, 3.32023286819458, 4.2967119216918945], "entropies_second": [4.385584831237793, 0.04287828505039215], "final_normalized_entropy": 3.2179937504307197, "sequence_confidence_first": 0.35367901986171213, "sequence_confidence_second": 0.5916876829580365, "sequence_confidence_final": 0.5916876829580365, "token_confidences_first": [0.3745657503604889, 0.9851287603378296, 0.22541549801826477, 0.24784636497497559, 0.2684473395347595], "token_confidences_second": [0.30015575885772705, 0.9948312640190125, 0.6937156319618225], "final_mean_entropy": 2.2142315581440926, "final_min_margin": 1.3474626541137695, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9716312056737588, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 RedVelvet Cheese Slc 38,000 1 Chicken Baked Rice 55,000 1 Fish n Chips 65,000 1 Mushroom Soup 35,000 1 Chamomile 25,000 1 Iced Tea 20,000 SUBTOTAL 238,000 Service 17,850 PB1 25,585 TOTAL 281,435 Coupon 100,000 CASH 200,000 Change 18,565"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt", "raw_answer_second": "yes", "mean_entropy_first": 1.8619366027414799, "normalized_entropy_first": -0.27383853499285954, "min_margin_first": 0.9826240539550781, "mean_entropy_second": 2.3790221214294434, "normalized_entropy_second": 1.4038127304959391, "min_margin_second": 2.0633277893066406, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 115, "latency_ms_ocr": 673, "latency_ms_second": 127, "total_latency_ms": 920, "total_latency_s": 0.92, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6559898853302, 0.06788332015275955], "entropies_second": [2.3790221214294434], "final_normalized_entropy": 1.4038127304959391, "sequence_confidence_first": 0.47346177037385273, "sequence_confidence_second": 0.783849667670912, "sequence_confidence_final": 0.783849667670912, "token_confidences_first": [0.33637696504592896, 0.9889485836029053, 0.31904709339141846], "token_confidences_second": [0.6359049081802368, 0.966214120388031], "final_mean_entropy": 2.3790221214294434, "final_min_margin": 2.0633277893066406, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9915966386554622, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Lemon Tea (L) 25.000 1 Caramel Small 38.000 TOTAL 63.000 CASH 70.000 CHANGED 7.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for lemon tea and caramel cake at xi cafe", "used_ocr": false, "answer_first": "receipt for lemon tea and caramel cake at xi cafe", "answer_second": null, "raw_answer": "receipt for lemon tea and caramel cake at xi cafe", "raw_answer_first": "receipt for lemon tea and caramel cake at xi cafe", "raw_answer_second": null, "mean_entropy_first": 1.5257613105315935, "normalized_entropy_first": -1.4042290892896938, "min_margin_first": 0.19397735595703125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 482, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 483, "total_latency_s": 0.483, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.455104351043701, 0.0862431675195694, 3.094738006591797, 3.5166757106781006, 0.058511435985565186, 0.36884576082229614, 2.091470956802368, 2.4833455085754395, 0.6117109060287476, 0.05284634232521057, 4.156744480133057, 0.2392757534980774, 2.5846917629241943, 1.4953837394714355, 1.4091875553131104, 0.2283957600593567, 0.004771081265062094], "entropies_second": null, "final_normalized_entropy": -1.4042290892896938, "sequence_confidence_first": 0.5823446647452752, "sequence_confidence_second": null, "sequence_confidence_final": 0.5823446647452752, "token_confidences_first": [0.2798197269439697, 0.9857552647590637, 0.3494579792022705, 0.2476176619529724, 0.9937816262245178, 0.9513184428215027, 0.5570656061172485, 0.6020838618278503, 0.8635114431381226, 0.9943641424179077, 0.12756213545799255, 0.9652747511863708, 0.3384288251399994, 0.724929928779602, 0.5646019577980042, 0.9699914455413818, 0.9996167421340942, 0.5520064234733582], "token_confidences_second": null, "final_mean_entropy": 1.5257613105315935, "final_min_margin": 0.19397735595703125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7619047619047619, "wer": 0.8666666666666667, "precision": 0.3, "recall": 0.2, "f1": 0.24, "rouge_l": 0.24, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 [LG] BLACK SAKURA 59,091 1 LONGAN 0 1 ROASTED ALMOND 0 1 IVANGGO 0 1 IVINERAL WATER (bundling) 5k 4,545 Sub Total 63,636 PB1 (10%) 6,364 Rounding 0 Total 70,000 Cash Payment 100,000 Change 30,000"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt", "raw_answer_second": "yes", "mean_entropy_first": 1.9714497439563274, "normalized_entropy_first": 0.24540876884881682, "min_margin_first": 0.5090446472167969, "mean_entropy_second": 4.553873062133789, "normalized_entropy_second": 8.721998759780138, "min_margin_second": 1.2170257568359375, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 120, "latency_ms_ocr": 162, "latency_ms_second": 127, "total_latency_ms": 411, "total_latency_s": 0.411, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.883835554122925, 0.05906393378973007], "entropies_second": [4.553873062133789], "final_normalized_entropy": 8.721998759780138, "sequence_confidence_first": 0.43723192318113374, "sequence_confidence_second": 0.4514629872002578, "sequence_confidence_final": 0.4514629872002578, "token_confidences_first": [0.25946715474128723, 0.9907399415969849, 0.3251573145389557], "token_confidences_second": [0.23995289206504822, 0.8494118452072144], "final_mean_entropy": 4.553873062133789, "final_min_margin": 1.2170257568359375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9898477157360406, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Goblin's Mace 1 25,000 Mozarella Hot Dog 2 38,000 Chili Pepper Croquette 1 14,000 Cheese Croquette 1 14,000 Plastik Amook 1 0 Plastik Putih Take Away 1 0 Subtotal 91,000 Discount (0) TOTAL Rp. 91,000 Debit 91,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.5761477798223495, "normalized_entropy_first": -1.1315160341950738, "min_margin_first": 0.7451972961425781, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 112, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 113, "total_latency_s": 0.113, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.091982841491699, 0.06031271815299988], "entropies_second": null, "final_normalized_entropy": -1.1315160341950738, "sequence_confidence_first": 0.43712648047077945, "sequence_confidence_second": null, "sequence_confidence_final": 0.43712648047077945, "token_confidences_first": [0.3798659145832062, 0.9907954335212708, 0.22192540764808655], "token_confidences_second": null, "final_mean_entropy": 1.5761477798223495, "final_min_margin": 0.7451972961425781, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9669811320754716, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Propolis Cair 1 156000 156000 Sub Tofal 156000 Tunai 156000 Kembalian Rp. 0"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for propolis car with a total of 1 56 00 0", "used_ocr": true, "answer_first": "receipt", "answer_second": "a receipt for propolis car with a total of 1 56 00 0", "raw_answer": "a receipt for propolis car with a total of 1 56 00 0", "raw_answer_first": "receipt", "raw_answer_second": "a receipt for propolis car with a total of 1 56 00 0", "mean_entropy_first": 1.8857587948441505, "normalized_entropy_first": 0.04929550384049909, "min_margin_first": 0.9272623062133789, "mean_entropy_second": 1.8771339365769, "normalized_entropy_second": 0.0197672021898166, "min_margin_second": 0.0793304443359375, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 111, "latency_ms_ocr": 60, "latency_ms_second": 553, "total_latency_ms": 726, "total_latency_s": 0.726, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6910789012908936, 0.08043868839740753], "entropies_second": [3.8538498878479004, 2.5847511291503906, 0.03712806478142738, 2.8167219161987305, 3.578235149383545, 0.1257656216621399, 2.8088674545288086, 3.802494525909424, 3.896510601043701, 4.700865745544434, 1.5914342403411865, 1.783573865890503, 0.7959757447242737, 1.733543872833252, 0.5265460014343262, 0.4569737911224365, 0.6093807816505432, 0.1693035215139389, 0.22763803601264954, 3.0605411529541016, 0.2597115635871887], "final_normalized_entropy": 0.0197672021898166, "sequence_confidence_first": 0.4669170071338112, "sequence_confidence_second": 0.5201523287647933, "sequence_confidence_final": 0.5201523287647933, "token_confidences_first": [0.34084048867225647, 0.9870823621749878, 0.30256208777427673], "token_confidences_second": [0.3484538197517395, 0.5399381518363953, 0.9954848289489746, 0.22912035882472992, 0.2996201813220978, 0.9789549112319946, 0.41821610927581787, 0.18322740495204926, 0.18599271774291992, 0.19472438097000122, 0.610801637172699, 0.6316342353820801, 0.807919442653656, 0.5910863280296326, 0.9009865522384644, 0.9221738576889038, 0.8739262819290161, 0.9727615118026733, 0.9638322591781616, 0.4297487437725067, 0.9583436250686646, 0.3151438236236572], "final_mean_entropy": 1.8771339365769, "final_min_margin": 0.0793304443359375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.76, "wer": 0.9230769230769231, "precision": 0.23076923076923078, "recall": 0.23076923076923078, "f1": 0.23076923076923078, "rouge_l": 0.23076923076923078, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["4 AMBUSH DBL CHS 60000 10 AMBUSH CHS BUR 100000 NET SALES 160000 TAX 16000 AMOUNT DUE 176000"], "experiment": "entropy_routing_default", "routed": {"answer": "4", "used_ocr": true, "answer_first": "receipt for gasoline", "answer_second": "4", "raw_answer": "4", "raw_answer_first": "receipt for gasoline", "raw_answer_second": "4", "mean_entropy_first": 2.706195852160454, "normalized_entropy_first": 3.007210299561119, "min_margin_first": 0.08806800842285156, "mean_entropy_second": 3.180027961730957, "normalized_entropy_second": 4.716977467992133, "min_margin_second": 0.6471977233886719, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 192, "latency_ms_ocr": 130, "latency_ms_second": 129, "total_latency_ms": 453, "total_latency_s": 0.453, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.9034581184387207, 0.11904536187648773, 3.2164535522460938, 4.525717735290527, 1.7663044929504395], "entropies_second": [4.6073713302612305, 1.7526845932006836], "final_normalized_entropy": 4.716977467992133, "sequence_confidence_first": 0.35245140954473386, "sequence_confidence_second": 0.30772801552737233, "sequence_confidence_final": 0.30772801552737233, "token_confidences_first": [0.3484555780887604, 0.9774301052093506, 0.23074723780155182, 0.13871870934963226, 0.6722908020019531, 0.2615373134613037], "token_confidences_second": [0.22510862350463867, 0.4298577308654785, 0.30115094780921936], "final_mean_entropy": 3.180027961730957, "final_min_margin": 0.6471977233886719, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9891304347826086, "wer": 0.9444444444444444, "precision": 1.0, "recall": 0.05555555555555555, "f1": 0.10526315789473684, "rouge_l": 0.10526315789473684, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 JASMINE MT ( L ) 24,000 COCONUT JELLY ( L ) 4,000 SUB TOTAL 28,000 TOTAL SAI S 28,000 TOTAL ITEMS 1 CASH 100,000 CHANGE 72,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt", "answer_second": "receipt that has a total of 45, 280 on it", "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": "receipt that has a total of 45, 280 on it", "mean_entropy_first": 1.820855937898159, "normalized_entropy_first": -0.37287681863126215, "min_margin_first": 1.061086654663086, "mean_entropy_second": 2.1377185407806847, "normalized_entropy_second": 0.5004784702734102, "min_margin_second": 0.0069713592529296875, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 118, "latency_ms_ocr": 130, "latency_ms_second": 500, "total_latency_ms": 749, "total_latency_s": 0.749, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.570009708404541, 0.07170216739177704], "entropies_second": [2.924516201019287, 0.09078815579414368, 2.6712841987609863, 2.185675859451294, 2.469402551651001, 5.130475997924805, 1.4446492195129395, 2.405465602874756, 2.0371274948120117, 2.463714122772217, 2.364830732345581, 0.9220285415649414, 1.7484362125396729, 0.4409288167953491, 2.9251368045806885, 3.9229421615600586, 0.1938125193119049], "final_normalized_entropy": -0.37287681863126215, "sequence_confidence_first": 0.4739263691768783, "sequence_confidence_second": 0.40022477358294695, "sequence_confidence_final": 0.4739263691768783, "token_confidences_first": [0.3444310128688812, 0.9886965751647949, 0.31258442997932434], "token_confidences_second": [0.335757315158844, 0.9846433401107788, 0.2142772525548935, 0.33413583040237427, 0.5283469557762146, 0.0857643187046051, 0.7253629565238953, 0.5199626088142395, 0.2800368368625641, 0.21484577655792236, 0.26794812083244324, 0.8194027543067932, 0.36511722207069397, 0.9142537117004395, 0.48416993021965027, 0.2271910309791565, 0.9729604125022888, 0.3636144995689392], "final_mean_entropy": 1.820855937898159, "final_min_margin": 1.061086654663086, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9609375, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 cashew nuts chkn 64,500 1 garlic pepper beef 79,500 1 red curry beef 69,500 1 phad thai 64,500 4 steamed rice 47,600 SUBTOTAL 325,600 Service chrg 17,908 10% PB1 34,351 TOTAL 377,859"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt for food", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt for food", "raw_answer_second": "yes", "mean_entropy_first": 2.7726491652429104, "normalized_entropy_first": 2.3949601298559977, "min_margin_first": 0.6300926208496094, "mean_entropy_second": 2.6584482192993164, "normalized_entropy_second": 2.0654490221013306, "min_margin_second": 2.1482486724853516, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 162, "latency_ms_ocr": 158, "latency_ms_second": 127, "total_latency_ms": 449, "total_latency_s": 0.449, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.557480812072754, 0.082029327750206, 3.350341320037842, 4.10074520111084], "entropies_second": [2.6584482192993164], "final_normalized_entropy": 2.0654490221013306, "sequence_confidence_first": 0.358270449480871, "sequence_confidence_second": 0.7523093427682681, "sequence_confidence_final": 0.7523093427682681, "token_confidences_first": [0.35387107729911804, 0.9864146113395691, 0.26611459255218506, 0.2423437237739563, 0.2622103989124298], "token_confidences_second": [0.5822925567626953, 0.971967339515686], "final_mean_entropy": 2.6584482192993164, "final_min_margin": 2.1482486724853516, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9836956521739131, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 35.000 Rp 35.000 NASI GOR SFD TLR 1 3.000 Rp 3.000 ES TEH TAWAR ***TOTAL Rp 38.000 CASH Rp 50.000 CHANGE Rp 12.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for a meal at a restaurant", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for a meal at a restaurant", "raw_answer_second": "receipt", "mean_entropy_first": 2.7264052358352475, "normalized_entropy_first": 1.6991128935722601, "min_margin_first": 0.2552013397216797, "mean_entropy_second": 2.0682481564581394, "normalized_entropy_second": 0.1033668467905958, "min_margin_second": 0.32961559295654297, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 284, "latency_ms_ocr": 121, "latency_ms_second": 146, "total_latency_ms": 553, "total_latency_s": 0.553, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.0868585109710693, 0.08598221838474274, 3.300529718399048, 4.577127933502197, 5.0429840087890625, 0.013964632526040077, 2.869462490081787, 4.185786247253418, 1.3749513626098633], "entropies_second": [4.049845218658447, 0.08665109425783157], "final_normalized_entropy": 0.1033668467905958, "sequence_confidence_first": 0.37904274808421606, "sequence_confidence_second": 0.5439126234908664, "sequence_confidence_final": 0.5439126234908664, "token_confidences_first": [0.40932297706604004, 0.9855776429176331, 0.22097870707511902, 0.17381490767002106, 0.1341252326965332, 0.9987873435020447, 0.31542423367500305, 0.24624449014663696, 0.8021968007087708, 0.4733272194862366], "token_confidences_second": [0.24108880758285522, 0.9851155877113342, 0.6775216460227966], "final_mean_entropy": 2.0682481564581394, "final_min_margin": 0.32961559295654297, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9568965517241379, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["2 [MD] SOFT STEAMED CHEESEC 20,000 2 [MD] SOFT STEAMED CHOCOCA 20,000 TOTAL 40,000 CASH 100,000 CHANGE 60,000"], "experiment": "entropy_routing_default", "routed": {"answer": "2", "used_ocr": true, "answer_first": "receipt for 40,000 yen", "answer_second": "2", "raw_answer": "2", "raw_answer_first": "receipt for 40,000 yen", "raw_answer_second": "2", "mean_entropy_first": 2.3089518938213587, "normalized_entropy_first": 0.4801117101715155, "min_margin_first": 0.026103973388671875, "mean_entropy_second": 3.061203122138977, "normalized_entropy_second": 2.1736702602335156, "min_margin_second": 0.1001434326171875, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 345, "latency_ms_ocr": 119, "latency_ms_second": 130, "total_latency_ms": 596, "total_latency_s": 0.596, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6025593280792236, 0.09049957245588303, 3.455735683441162, 4.4725661277771, 1.5858478546142578, 3.1354637145996094, 3.218001127243042, 1.5942350625991821, 0.27355605363845825, 0.8265900611877441, 4.924044609069824, 0.5283235311508179], "entropies_second": [4.178791046142578, 1.943615198135376], "final_normalized_entropy": 2.1736702602335156, "sequence_confidence_first": 0.40632061395567737, "sequence_confidence_second": 0.2542968432995011, "sequence_confidence_final": 0.2542968432995011, "token_confidences_first": [0.3298227787017822, 0.9847546815872192, 0.25994211435317993, 0.12911753356456757, 0.5404709577560425, 0.5330425500869751, 0.4292150139808655, 0.4382476210594177, 0.9596761465072632, 0.8978012800216675, 0.0899612233042717, 0.8886001110076904, 0.20222237706184387], "token_confidences_second": [0.2189948409795761, 0.2890607714653015, 0.2597765028476715], "final_mean_entropy": 3.061203122138977, "final_min_margin": 0.1001434326171875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9908256880733946, "wer": 0.9444444444444444, "precision": 1.0, "recall": 0.05555555555555555, "f1": 0.10526315789473684, "rouge_l": 0.10526315789473684, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["6 TWIST DONUT 54,000 1 REDBEAN BREAD 9,000 TOTAL 63,000 CASH 70,000 CHANGE 7,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.7429090775549412, "normalized_entropy_first": -0.8777436177884272, "min_margin_first": 0.9941625595092773, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 117, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 118, "total_latency_s": 0.118, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.415670394897461, 0.07014776021242142], "entropies_second": null, "final_normalized_entropy": -0.8777436177884272, "sequence_confidence_first": 0.48622361409078285, "sequence_confidence_second": null, "sequence_confidence_final": 0.48622361409078285, "token_confidences_first": [0.30754950642585754, 0.9887046217918396, 0.3780302405357361], "token_confidences_second": null, "final_mean_entropy": 1.7429090775549412, "final_min_margin": 0.9941625595092773, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.95, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["5001-Corn Flakes Cookies Rp.56.000 x1 Rp.56.000 5003-Chokoreto Cookies Rp.62.000 x1 Rp.62.000 6002-Plastic Bag Medium Rp.0 x1 Rp.0 Total Item: 3 Total, Rp.118.000 Debet Card 118.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.5303142443299294, "normalized_entropy_first": -1.3089856566742408, "min_margin_first": 1.791792869567871, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 114, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 115, "total_latency_s": 0.115, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.975896120071411, 0.08473236858844757], "entropies_second": null, "final_normalized_entropy": -1.3089856566742408, "sequence_confidence_first": 0.5134721540333744, "sequence_confidence_second": null, "sequence_confidence_final": 0.5134721540333744, "token_confidences_first": [0.5045343637466431, 0.9857272505760193, 0.27220943570137024], "token_confidences_second": null, "final_mean_entropy": 1.5303142443299294, "final_min_margin": 1.791792869567871, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9613259668508287, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 TWIST STRAWBERRY DONUT 10,000 1 TLJ CROQUETTE 17,000 1 POTATO PEPPER BAGEL 16,000 TOTAL 43,000 CASH 50,000 CHANGE 7,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for strawberry donut and potato pepper bagel", "used_ocr": false, "answer_first": "receipt for strawberry donut and potato pepper bagel", "answer_second": null, "raw_answer": "receipt for strawberry donut and potato pepper bagel", "raw_answer_first": "receipt for strawberry donut and potato pepper bagel", "raw_answer_second": null, "mean_entropy_first": 1.468534055352211, "normalized_entropy_first": -1.2907861935118075, "min_margin_first": 0.7546930313110352, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 411, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 412, "total_latency_s": 0.412, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.322749137878418, 0.06866970658302307, 3.419548511505127, 3.637585163116455, 0.05101403594017029, 0.2631128132343292, 1.4340863227844238, 0.32777640223503113, 2.7245941162109375, 2.5353052616119385, 0.11002908647060394, 2.4815523624420166, 0.2500411570072174, 1.1315659284591675, 0.27038082480430603], "entropies_second": null, "final_normalized_entropy": -1.2907861935118075, "sequence_confidence_first": 0.6075407319825277, "sequence_confidence_second": null, "sequence_confidence_final": 0.6075407319825277, "token_confidences_first": [0.337907075881958, 0.9887472987174988, 0.26989713311195374, 0.23908740282058716, 0.9952725768089294, 0.934576690196991, 0.7395654320716858, 0.9149324893951416, 0.38456863164901733, 0.4706036448478699, 0.9809945225715637, 0.5318164825439453, 0.9689069986343384, 0.7982097268104553, 0.958577573299408, 0.3627123236656189], "token_confidences_second": null, "final_mean_entropy": 1.468534055352211, "final_min_margin": 0.7546930313110352, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7024793388429752, "wer": 0.75, "precision": 0.625, "recall": 0.25, "f1": 0.35714285714285715, "rouge_l": 0.35714285714285715, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Cap Cay Nasi Cap Cay Porsi B esar 1 65.000 65.000 Minuman Teh Tawar 2 4.000 Lain-lain Fu Yung Hai 1 65.000 65.000 Subtotal Rp 138.000 Total Rp 138.000 Cash Rp 138.000 Change Rp 0"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.7348683029413223, "normalized_entropy_first": -0.5304711940095013, "min_margin_first": 2.248289108276367, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 114, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 115, "total_latency_s": 0.115, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.300788640975952, 0.1689479649066925], "entropies_second": null, "final_normalized_entropy": -0.5304711940095013, "sequence_confidence_first": 0.5167057687516637, "sequence_confidence_second": null, "sequence_confidence_final": 0.5167057687516637, "token_confidences_first": [0.4899664521217346, 0.9648523926734924, 0.2918117046356201], "token_confidences_second": null, "final_mean_entropy": 1.7348683029413223, "final_min_margin": 2.248289108276367, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9662921348314607, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["PKT AYAM 33,000 GULAI OTAK 23,000 2.00 ITEMS SUBTOTAL 56,000 TAX 10% 5,600 TOTAL 61,600 CHARGE5 61,600"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for food", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for food", "raw_answer_second": "receipt", "mean_entropy_first": 3.0366024086251855, "normalized_entropy_first": 2.5688680203844636, "min_margin_first": 0.07843589782714844, "mean_entropy_second": 2.015602257102728, "normalized_entropy_second": 0.16472743935793274, "min_margin_second": 2.205455780029297, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 163, "latency_ms_ocr": 125, "latency_ms_second": 151, "total_latency_ms": 442, "total_latency_s": 0.442, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.081211090087891, 0.05284583941102028, 3.3326003551483154, 4.679752349853516], "entropies_second": [3.9680023193359375, 0.06320219486951828], "final_normalized_entropy": 0.16472743935793274, "sequence_confidence_first": 0.31118124785606643, "sequence_confidence_second": 0.6298502363783497, "sequence_confidence_final": 0.6298502363783497, "token_confidences_first": [0.2558741569519043, 0.9920710921287537, 0.26349470019340515, 0.1284388303756714, 0.33964845538139343], "token_confidences_second": [0.3947697579860687, 0.99003005027771, 0.6393219828605652], "final_mean_entropy": 2.015602257102728, "final_min_margin": 2.205455780029297, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9705882352941176, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["SAMGYOPSAL 2 194,000 SUL LUNG TANG 1 75,000 MAKOLI 1 100,000 Sub Total 369,000 Service 18,450 VAT 38,745 Discount 0 TOTAL 426,195"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt that has been folded in half and is being held by someone's hand", "used_ocr": true, "answer_first": "receipt for a total of $104.97", "answer_second": "a receipt that has been folded in half and is being held by someone's hand", "raw_answer": "a receipt that has been folded in half and is being held by someone's hand", "raw_answer_first": "receipt for a total of $104.97", "raw_answer_second": "a receipt that has been folded in half and is being held by someone's hand", "mean_entropy_first": 2.639268083068041, "normalized_entropy_first": 1.1260961848833082, "min_margin_first": 0.02330780029296875, "mean_entropy_second": 1.7108459460402006, "normalized_entropy_second": -0.6625162182737404, "min_margin_second": 0.0290069580078125, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 369, "latency_ms_ocr": 169, "latency_ms_second": 552, "total_latency_ms": 1092, "total_latency_s": 1.092, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.886239528656006, 0.0607118159532547, 3.4999938011169434, 4.731783866882324, 4.837123394012451, 1.3480638265609741, 1.2056399583816528, 2.1012961864471436, 2.482598066329956, 2.9232325553894043, 2.870898485183716, 2.2192225456237793, 2.143681049346924], "entropies_second": [1.7814093828201294, 2.4002904891967773, 0.011294004507362843, 2.7548036575317383, 2.2820420265197754, 3.1610188484191895, 3.6188039779663086, 0.04156925529241562, 1.989662528038025, 0.4079892039299011, 3.1182596683502197, 3.5378427505493164, 2.761129379272461, 0.2903077006340027, 0.8422239422798157, 1.3304057121276855, 1.8054813146591187, 0.012912170961499214, 0.35862696170806885], "final_normalized_entropy": -0.6625162182737404, "sequence_confidence_first": 0.2659628361094522, "sequence_confidence_second": 0.5354463761149865, "sequence_confidence_final": 0.5354463761149865, "token_confidences_first": [0.20412448048591614, 0.9909327030181885, 0.22589604556560516, 0.15848621726036072, 0.17550842463970184, 0.7437194585800171, 0.4996704161167145, 0.30786576867103577, 0.1650685966014862, 0.10817397385835648, 0.1562972515821457, 0.21925316751003265, 0.2073035091161728, 0.48040854930877686], "token_confidences_second": [0.6968919038772583, 0.5396685600280762, 0.9988203644752502, 0.26655882596969604, 0.2649710178375244, 0.2448159009218216, 0.196869358420372, 0.9945525527000427, 0.5907601714134216, 0.9449011087417603, 0.2629070281982422, 0.25457072257995605, 0.47699210047721863, 0.9632662534713745, 0.833191454410553, 0.6590741276741028, 0.4109972417354584, 0.9991219639778137, 0.9427404403686523, 0.8085529208183289], "final_mean_entropy": 1.7108459460402006, "final_min_margin": 0.0290069580078125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8217054263565892, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["COLD OCHA 1 10,909 BCA PROMO 1 54,455 ABURA UDON SPICY 1 0 1 :-KAKE UDON 0 SKEWERED SHUMAI 1 12,727 SKEWERED TOFU ROLL 1 12,727 EBI TEMPURA 1 13,636 KITSUNE UDON (KIDS) 1 28,182 SUB, TOTAL 132,636 RESTAURANT TAX 13,264 GRAND TOTAL 145,900 ~ BCA EDC [145,900]"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for a meal at a restaurant with a total of $14 590", "used_ocr": true, "answer_first": "receipt for food", "answer_second": "a receipt for a meal at a restaurant with a total of $14 590", "raw_answer": "a receipt for a meal at a restaurant with a total of $14 590", "raw_answer_first": "receipt for food", "raw_answer_second": "a receipt for a meal at a restaurant with a total of $14 590", "mean_entropy_first": 2.6488011684268713, "normalized_entropy_first": 1.0246392919244365, "min_margin_first": 0.180267333984375, "mean_entropy_second": 2.092444318014064, "normalized_entropy_second": -0.0396942087703061, "min_margin_second": 0.0424957275390625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 156, "latency_ms_ocr": 196, "latency_ms_second": 610, "total_latency_ms": 964, "total_latency_s": 0.964, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.4095358848571777, 0.07733162492513657, 3.0817039012908936, 4.026633262634277], "entropies_second": [1.9302864074707031, 1.6897436380386353, 0.010334044694900513, 2.830737829208374, 3.3788952827453613, 3.0123062133789062, 0.007527447771281004, 2.8949365615844727, 3.0441393852233887, 1.837881088256836, 3.1952478885650635, 3.7374653816223145, 4.216341018676758, 1.6682169437408447, 1.62485933303833, 0.673316478729248, 1.5554438829421997, 2.0693488121032715, 1.0576754808425903, 1.6786580085754395, 1.8279695510864258], "final_normalized_entropy": -0.0396942087703061, "sequence_confidence_first": 0.3485498020943276, "sequence_confidence_second": 0.4488784398328947, "sequence_confidence_final": 0.4488784398328947, "token_confidences_first": [0.3380098044872284, 0.987269401550293, 0.3446372151374817, 0.19814369082450867, 0.2257443070411682], "token_confidences_second": [0.5421662330627441, 0.7477337121963501, 0.9988622665405273, 0.23160144686698914, 0.2149566113948822, 0.3627215325832367, 0.9992465972900391, 0.3005322813987732, 0.4364718198776245, 0.6536480784416199, 0.1710808426141739, 0.20946095883846283, 0.20941784977912903, 0.40294012427330017, 0.4956534802913666, 0.8818987011909485, 0.48474225401878357, 0.5563616752624512, 0.704469621181488, 0.6158400774002075, 0.6243290305137634, 0.36740967631340027], "final_mean_entropy": 2.092444318014064, "final_min_margin": 0.0424957275390625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8333333333333334, "wer": 0.9583333333333334, "precision": 0.14285714285714285, "recall": 0.041666666666666664, "f1": 0.06451612903225806, "rouge_l": 0.06451612903225806, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1X @11000 DONAT GULA 11,000 1.00xITEMs SUBTOTAL 11,000 TOTAL 11,000 CASH 11,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a purchase at dynamic market", "used_ocr": true, "answer_first": "receipt for a total of 2000 dollars", "answer_second": "receipt for a purchase at dynamic market", "raw_answer": "receipt for a purchase at dynamic market", "raw_answer_first": "receipt for a total of 2000 dollars", "raw_answer_second": "receipt for a purchase at dynamic market", "mean_entropy_first": 2.824025879924496, "normalized_entropy_first": 1.2608660981201143, "min_margin_first": 0.0176544189453125, "mean_entropy_second": 3.131023577414453, "normalized_entropy_second": 1.8497901118855387, "min_margin_second": 0.09856986999511719, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 340, "latency_ms_ocr": 110, "latency_ms_second": 272, "total_latency_ms": 725, "total_latency_s": 0.725, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.937289237976074, 0.0850222185254097, 3.0196707248687744, 4.887850761413574, 5.128220081329346, 1.1962196826934814, 1.057234525680542, 1.7120212316513062, 2.520799398422241, 3.250758647918701, 3.5660810470581055, 4.5271430015563965], "entropies_second": [3.046833038330078, 0.08145087212324142, 2.9015398025512695, 3.4012680053710938, 4.553483963012695, 2.144193172454834, 3.1349329948425293, 5.784486770629883], "final_normalized_entropy": 1.8497901118855387, "sequence_confidence_first": 0.31456184050795044, "sequence_confidence_second": 0.3045885918810551, "sequence_confidence_final": 0.3045885918810551, "token_confidences_first": [0.5057137608528137, 0.9855960607528687, 0.2697606086730957, 0.14569351077079773, 0.12533451616764069, 0.8000403642654419, 0.4828013479709625, 0.36170902848243713, 0.21420806646347046, 0.22148078680038452, 0.32785242795944214, 0.16525350511074066, 0.334845632314682], "token_confidences_second": [0.42214202880859375, 0.9865359663963318, 0.2534017264842987, 0.40683525800704956, 0.22589382529258728, 0.40635645389556885, 0.3457874357700348, 0.05576060712337494, 0.29694417119026184], "final_mean_entropy": 3.131023577414453, "final_min_margin": 0.09856986999511719, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8481012658227848, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Kupon 3 28,636 Subtotal 28,636 PB1 (10%) 2,864 Dine In Total 31,500 Cash 50,000 Change 18,500"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.5189782232046127, "normalized_entropy_first": -1.3401740506890156, "min_margin_first": 1.607452392578125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 114, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 116, "total_latency_s": 0.116, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.9434709548950195, 0.09448549151420593], "entropies_second": null, "final_normalized_entropy": -1.3401740506890156, "sequence_confidence_first": 0.5079340759965016, "sequence_confidence_second": null, "sequence_confidence_final": 0.5079340759965016, "token_confidences_first": [0.5132988095283508, 0.9838796257972717, 0.25948354601860046], "token_confidences_second": null, "final_mean_entropy": 1.5189782232046127, "final_min_margin": 1.607452392578125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.967741935483871, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 SALMON PESTO 85,500 1 SALMON PESTO 85,500 Disc -100% (ITM06) -85,500 SUBTTL 85,500 SVC CHG 6% 10,260 PB1 10% 18,126 TOTAL 113,886"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.7529234252870083, "normalized_entropy_first": -0.744143366869042, "min_margin_first": 1.049276351928711, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 127, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 131, "total_latency_s": 0.131, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.443377733230591, 0.06246911734342575], "entropies_second": null, "final_normalized_entropy": -0.744143366869042, "sequence_confidence_first": 0.5161582142506838, "sequence_confidence_second": null, "sequence_confidence_final": 0.5161582142506838, "token_confidences_first": [0.3559226393699646, 0.9899829626083374, 0.39027002453804016], "token_confidences_second": null, "final_mean_entropy": 1.7529234252870083, "final_min_margin": 1.049276351928711, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9618320610687023, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["THAI ICED GREEN TEA 1 @24.000 24.000 SUB-TOTAL 24.000 GRANDTOTAL 24.000 CASH 50.000 CHANGED 26.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.671085512265563, "normalized_entropy_first": -0.840261637729161, "min_margin_first": 0.6964406967163086, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 121, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 124, "total_latency_s": 0.124, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.2864267826080322, 0.055744241923093796], "entropies_second": null, "final_normalized_entropy": -0.840261637729161, "sequence_confidence_first": 0.4397330252369016, "sequence_confidence_second": null, "sequence_confidence_final": 0.4397330252369016, "token_confidences_first": [0.3295213580131531, 0.9914494156837463, 0.2602634131908417], "token_confidences_second": null, "final_mean_entropy": 1.671085512265563, "final_min_margin": 0.6964406967163086, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9591836734693877, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 GRILLED BABY POTATO (R 50,500 1 HOT TUNA 67,000 1 HOT TUNA 67,000 Disc -100% (ITM06) -67,000 SUBTTL 117,500 SVC CHG 6% 11,070 PB1 10% 19,557 TOTAL 148,127"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.6360316574573517, "normalized_entropy_first": -0.8372050940641681, "min_margin_first": 1.4002265930175781, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 111, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 112, "total_latency_s": 0.112, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.200364828109741, 0.07169848680496216], "entropies_second": null, "final_normalized_entropy": -0.8372050940641681, "sequence_confidence_first": 0.5088136847741997, "sequence_confidence_second": null, "sequence_confidence_final": 0.5088136847741997, "token_confidences_first": [0.43377554416656494, 0.9878007173538208, 0.30742695927619934], "token_confidences_second": null, "final_mean_entropy": 1.6360316574573517, "final_min_margin": 1.4002265930175781, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9615384615384616, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Ash Chick Sambal Matah 5 75.000 Jamur Goreng 2 10.000 Subtotal 85.000 Pajak (10%) 8.500 Total 93.500 Tunai 100.000 Kembali 6.500"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for a meal at a restaurant in jakarta", "used_ocr": true, "answer_first": "a receipt with a blue and white logo on it", "answer_second": "a receipt for a meal at a restaurant in jakarta", "raw_answer": "a receipt for a meal at a restaurant in jakarta", "raw_answer_first": "a receipt with a blue and white logo on it", "raw_answer_second": "a receipt for a meal at a restaurant in jakarta", "mean_entropy_first": 2.6476316057484257, "normalized_entropy_first": 1.1964388650817708, "min_margin_first": 0.05902671813964844, "mean_entropy_second": 2.643799921282782, "normalized_entropy_second": 1.1889988617337761, "min_margin_second": 0.12652587890625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 323, "latency_ms_ocr": 142, "latency_ms_second": 387, "total_latency_ms": 853, "total_latency_s": 0.853, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.693483352661133, 2.955000400543213, 0.014185262843966484, 2.1830239295959473, 3.8257369995117188, 4.280628204345703, 3.9691519737243652, 0.7756634950637817, 4.218636989593506, 1.8836462497711182, 0.3247908055782318], "entropies_second": [5.455137252807617, 1.9380356073379517, 0.008139261044561863, 2.5416183471679688, 4.586175918579102, 4.572479248046875, 0.019125627353787422, 2.7327353954315186, 3.9718379974365234, 1.163840413093567, 2.9169387817382812, 4.310381889343262, 0.15295323729515076], "final_normalized_entropy": 1.1889988617337761, "sequence_confidence_first": 0.37153310152192953, "sequence_confidence_second": 0.3433665637780314, "sequence_confidence_final": 0.3433665637780314, "token_confidences_first": [0.10648520290851593, 0.5731258988380432, 0.9982444047927856, 0.34406960010528564, 0.17233924567699432, 0.15152592957019806, 0.20451140403747559, 0.8446619510650635, 0.18388120830059052, 0.5339897871017456, 0.9368003606796265, 0.7953507900238037], "token_confidences_second": [0.10360302776098251, 0.6981258988380432, 0.9992272853851318, 0.3062067925930023, 0.13704228401184082, 0.18682073056697845, 0.9981516003608704, 0.36625605821609497, 0.20678676664829254, 0.836359441280365, 0.206563338637352, 0.2031891644001007, 0.9809282422065735, 0.21471333503723145], "final_mean_entropy": 2.643799921282782, "final_min_margin": 0.12652587890625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8125, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["2 TWIST DONUT 18,000 1 BANANA DONUT 11,000 1 CREAMCHEESE BREAD 13,000 1 FRANKFRUT SAUSAGE ROLL 12,000 TOTAL 54,000 CASH 104,000 CHANGE 50,000"], "experiment": "entropy_routing_default", "routed": {"answer": "50 dollars and 40 cents is on this receipt", "used_ocr": true, "answer_first": "receipt for a sandwich and bread", "answer_second": "50 dollars and 40 cents is on this receipt", "raw_answer": "50 dollars and 40 cents is on this receipt", "raw_answer_first": "receipt for a sandwich and bread", "raw_answer_second": "50 dollars and 40 cents is on this receipt", "mean_entropy_first": 2.808180969208479, "normalized_entropy_first": 1.3689402172966876, "min_margin_first": 0.024094581604003906, "mean_entropy_second": 2.0977429828296104, "normalized_entropy_second": 0.008945100632234146, "min_margin_second": 0.03498268127441406, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 247, "latency_ms_ocr": 156, "latency_ms_second": 459, "total_latency_ms": 865, "total_latency_s": 0.865, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.465521812438965, 0.09283503890037537, 3.4065663814544678, 4.268683433532715, 4.587389945983887, 0.15160608291625977, 2.6794304847717285, 3.8134145736694336], "entropies_second": [3.729429244995117, 1.7196719646453857, 3.917506217956543, 3.57222580909729, 2.185561180114746, 2.3820080757141113, 1.8565822839736938, 2.107020616531372, 1.2994344234466553, 0.010309027507901192, 2.6659631729125977, 3.2528271675109863, 1.2130506038665771, 1.5263572931289673, 0.02819766104221344], "final_normalized_entropy": 0.008945100632234146, "sequence_confidence_first": 0.30725651461234865, "sequence_confidence_second": 0.41733783608893443, "sequence_confidence_final": 0.41733783608893443, "token_confidences_first": [0.31797924637794495, 0.9836433529853821, 0.26755470037460327, 0.13066741824150085, 0.11273443698883057, 0.9757055640220642, 0.45895326137542725, 0.13840456306934357, 0.3194473683834076], "token_confidences_second": [0.16874760389328003, 0.4463824927806854, 0.1679583638906479, 0.18778392672538757, 0.463191419839859, 0.4144909381866455, 0.3358241617679596, 0.4789009988307953, 0.7799700498580933, 0.9990410208702087, 0.2756890654563904, 0.2010987102985382, 0.6203296184539795, 0.7709347009658813, 0.9964603781700134, 0.5607585310935974], "final_mean_entropy": 2.0977429828296104, "final_min_margin": 0.03498268127441406, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8297872340425532, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 XXL Crispy Chicken 40,000 1 - Sedang 0 ITEMS: 1 40,000 Total 40,000 Cash 100,000 Pay Change : 60,000"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": true, "answer_first": "1000", "answer_second": "45", "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": "45", "mean_entropy_first": 2.6428776025772094, "normalized_entropy_first": 0.8857037375191354, "min_margin_first": 0.4109230041503906, "mean_entropy_second": 3.5096728801727295, "normalized_entropy_second": 2.490825499489642, "min_margin_second": 0.04938793182373047, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 196, "latency_ms_ocr": 246, "latency_ms_second": 162, "total_latency_ms": 610, "total_latency_s": 0.61, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.9605939388275146, 1.705678105354309, 1.045562982559204, 2.735846996307373, 3.7667059898376465], "entropies_second": [4.287393093109131, 1.9788734912872314, 4.262752056121826], "final_normalized_entropy": 0.8857037375191354, "sequence_confidence_first": 0.3850697150610526, "sequence_confidence_second": 0.208930531757435, "sequence_confidence_final": 0.3850697150610526, "token_confidences_first": [0.2397478073835373, 0.5064592957496643, 0.827002763748169, 0.5398538708686829, 0.3818010687828064, 0.1575130969285965], "token_confidences_second": [0.1312829852104187, 0.3113132417201996, 0.13239113986492157, 0.3521621525287628], "final_mean_entropy": 2.6428776025772094, "final_min_margin": 0.4109230041503906, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9607843137254902, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Popcorn Salt (S) 1 20.000 TOTAL 20.000 CASH 50.000 CHANGED 30.000"], "experiment": "entropy_routing_default", "routed": {"answer": "2400", "used_ocr": true, "answer_first": "receipt for a movie ticket", "answer_second": "2400", "raw_answer": "2400", "raw_answer_first": "receipt for a movie ticket", "raw_answer_second": "2400", "mean_entropy_first": 3.0829040507475534, "normalized_entropy_first": 1.6361989619216806, "min_margin_first": 0.21541213989257812, "mean_entropy_second": 2.39079110622406, "normalized_entropy_second": 0.3352875070742842, "min_margin_second": 0.19735336303710938, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 206, "latency_ms_ocr": 54, "latency_ms_second": 201, "total_latency_ms": 463, "total_latency_s": 0.463, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.030625820159912, 0.07107728719711304, 3.316314220428467, 4.515820503234863, 4.622964859008789, 1.9406216144561768], "entropies_second": [4.207945823669434, 1.1452327966690063, 2.4313135147094727, 2.7979559898376465, 1.3715074062347412], "final_normalized_entropy": 0.3352875070742842, "sequence_confidence_first": 0.32885451836144114, "sequence_confidence_second": 0.40261882162226814, "sequence_confidence_final": 0.40261882162226814, "token_confidences_first": [0.2759067416191101, 0.9885446429252625, 0.2647172510623932, 0.14516013860702515, 0.2039397656917572, 0.6452698707580566, 0.3015748858451843], "token_confidences_second": [0.1668090969324112, 0.6999244093894958, 0.24589812755584717, 0.2553466260433197, 0.7128276824951172, 0.815123975276947], "final_mean_entropy": 2.39079110622406, "final_min_margin": 0.19735336303710938, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9538461538461539, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 XLB Org Pork 10x 78,000 1 Sicito Babi 65,000 1 Hotplate Tahu 58,000 1 DF Fish Fillet Garlc 108,000 1 LM Pork Belly 88,000 1 Siew Mai 38,800 5 Kwan Yin Cup 50,000 1 Herbal Jelly 38,000 1 Onde-Onde 38,000 561,800 ITEMS: 13 Service charge 42,135 PB1 60,394 Total 664,329"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt for a meal at a restaurant", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt for a meal at a restaurant", "raw_answer_second": "yes", "mean_entropy_first": 2.9044710761970944, "normalized_entropy_first": 1.0646378536530139, "min_margin_first": 0.20585155487060547, "mean_entropy_second": 3.393246650695801, "normalized_entropy_second": 1.924736456388974, "min_margin_second": 0.5194454193115234, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 285, "latency_ms_ocr": 355, "latency_ms_second": 151, "total_latency_ms": 796, "total_latency_s": 0.796, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7169196605682373, 0.05945781245827675, 3.109896421432495, 4.736196517944336, 5.24763822555542, 0.01337641105055809, 2.787544012069702, 4.616903305053711, 1.8523073196411133], "entropies_second": [3.393246650695801], "final_normalized_entropy": 1.924736456388974, "sequence_confidence_first": 0.36260668513183736, "sequence_confidence_second": 0.5413650797608571, "sequence_confidence_final": 0.5413650797608571, "token_confidences_first": [0.3187713027000427, 0.9907652139663696, 0.27799928188323975, 0.15933488309383392, 0.11039472371339798, 0.9988810420036316, 0.3385448157787323, 0.1972944438457489, 0.7127601504325867, 0.5350779294967651], "token_confidences_second": [0.3124086856842041, 0.9381178021430969], "final_mean_entropy": 3.393246650695801, "final_min_margin": 0.5194454193115234, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9888475836431226, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["HPL754DR LUNCH BOX 3P SET W/RED BAG & SP00 N. 8 PCS 243,000 1,944,000 DISKON: (20%) 1,555,200 HPL500 RICE CASE 7L W/CUP 5 PCS 195,000 975,000 DISKON: (20%) 780,000 HPL754DB LUNCH BOX 3P SET W/BLACK BAG & SP OON 4 PCS 243,000 972,000 DISKON: (20%) 777,600 TOTAL ITEM 3 TOTAL QTY 17 BAYAR CREDIT CARD 3,112,800"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.790583711117506, "normalized_entropy_first": -1.0009281921847075, "min_margin_first": 0.9083700180053711, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 117, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 117, "total_latency_s": 0.117, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.514681100845337, 0.06648632138967514], "entropies_second": null, "final_normalized_entropy": -1.0009281921847075, "sequence_confidence_first": 0.5130945304845912, "sequence_confidence_second": null, "sequence_confidence_final": 0.5130945304845912, "token_confidences_first": [0.3566221594810486, 0.9893878698348999, 0.38283994793891907], "token_confidences_second": null, "final_mean_entropy": 1.790583711117506, "final_min_margin": 0.9083700180053711, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9772727272727273, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["ICE BLACKCOFFE 2 82,000 AVOCADO COFFEE 1 61,000 CHIKEN KATSU FF 1 51,000 SUB_TOTAL 194,000 DISCOUNT 19,400 TOTAL 174,600 CASH 200,000 CHANGE 25,400"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.9524374902248383, "normalized_entropy_first": -0.6193596872443872, "min_margin_first": 0.1613759994506836, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 114, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 114, "total_latency_s": 0.114, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.715878486633301, 0.18899649381637573], "entropies_second": null, "final_normalized_entropy": -0.6193596872443872, "sequence_confidence_first": 0.4159835708795288, "sequence_confidence_second": null, "sequence_confidence_final": 0.4159835708795288, "token_confidences_first": [0.25965574383735657, 0.9588773250579834, 0.28911295533180237], "token_confidences_second": null, "final_mean_entropy": 1.9524374902248383, "final_min_margin": 0.1613759994506836, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9659863945578231, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Snack Lestari All 27,000 2 54,000 Bakery Aneka Sisir Banana,Pizza,yoko,Mar mer,Daging,abon,keju,cokelat,dll 7,000 2 14,000 TOTAL 68,000 CASH 100,000 CHANGE 32,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.8502527996897697, "normalized_entropy_first": -0.7633611026710349, "min_margin_first": 1.3486309051513672, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 108, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 108, "total_latency_s": 0.108, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6030025482177734, 0.09750305116176605], "entropies_second": null, "final_normalized_entropy": -0.7633611026710349, "sequence_confidence_first": 0.5525449101723415, "sequence_confidence_second": null, "sequence_confidence_final": 0.5525449101723415, "token_confidences_first": [0.35134002566337585, 0.9819464087486267, 0.48897576332092285], "token_confidences_second": null, "final_mean_entropy": 1.8502527996897697, "final_min_margin": 1.3486309051513672, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9629629629629629, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Chicken Maryland 47619.00 Cappucino (Hot/Iced) 30303.00 Naga Lychee Juice 34632.00 Cafe Latte 30303.00 Hot Chocolate Marshmallo 30303.00 Chicken Cesar Salad 43290.00 Mineral Water 12987.00 Mineral Water 12987.00 Lychee/Peach/Lemon/Mango 25974.00 Chicken Maryland 47619.00 Subtotal 316017.00 Service Charge 5% + 48982.68 TOTAL 365000.00"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt for a meal at a restaurant", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt for a meal at a restaurant", "raw_answer_second": "yes", "mean_entropy_first": 2.8451803492175207, "normalized_entropy_first": 1.159082266593541, "min_margin_first": 0.25887298583984375, "mean_entropy_second": 3.898383617401123, "normalized_entropy_second": 3.131256150090148, "min_margin_second": 0.5083122253417969, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 278, "latency_ms_ocr": 215, "latency_ms_second": 162, "total_latency_ms": 657, "total_latency_s": 0.657, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.236351490020752, 0.07036301493644714, 3.333540916442871, 4.7601189613342285, 5.07883358001709, 0.016748428344726562, 3.007840156555176, 4.48313045501709, 1.6196961402893066], "entropies_second": [3.898383617401123], "final_normalized_entropy": 3.131256150090148, "sequence_confidence_first": 0.3702859703570325, "sequence_confidence_second": 0.4926177365248831, "sequence_confidence_final": 0.4926177365248831, "token_confidences_first": [0.380985289812088, 0.9886628985404968, 0.2467176467180252, 0.16738909482955933, 0.13039928674697876, 0.9985746145248413, 0.3021598160266876, 0.23692627251148224, 0.764444887638092, 0.43715646862983704], "token_confidences_second": [0.2510800063610077, 0.9665135741233826], "final_mean_entropy": 3.898383617401123, "final_min_margin": 0.5083122253417969, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.991044776119403, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Chicken HCC. 1Pcs 15.000 Sub Total 15,000 P.Rest 10 % 1,500 Total 16,500 Cash 50,000 Kembali 33,500 1 Items,"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.053673354598383, "normalized_entropy_first": -0.43444183961922456, "min_margin_first": 0.5849876403808594, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 217, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 220, "total_latency_s": 0.22, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.3796377182006836, 4.22727108001709, 1.5328731536865234, 1.9282218217849731, 1.2348637580871582, 0.01917259581387043], "entropies_second": null, "final_normalized_entropy": -0.43444183961922456, "sequence_confidence_first": 0.48728031244482983, "sequence_confidence_second": null, "sequence_confidence_final": 0.48728031244482983, "token_confidences_first": [0.28604450821876526, 0.17366108298301697, 0.7011638879776001, 0.5686905384063721, 0.8247262835502625, 0.9978437423706055, 0.40017321705818176], "token_confidences_second": null, "final_mean_entropy": 2.053673354598383, "final_min_margin": 0.5849876403808594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8727272727272727, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["6 Pcs Cheese Tart 165000.00 Box of 6 PP Carrier Subtotal: Rp 165000.00 Total Tax Included: Rp 15000.00 Total: Rp 165000.00 Customer Paid Cash: Rp 200000.00 Customer Change: Rp 35000.00"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for kate spade bag", "used_ocr": false, "answer_first": "receipt for kate spade bag", "answer_second": null, "raw_answer": "receipt for kate spade bag", "raw_answer_first": "receipt for kate spade bag", "raw_answer_second": null, "mean_entropy_first": 2.303853588178754, "normalized_entropy_first": 0.0758713157178732, "min_margin_first": 0.020627975463867188, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 259, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 264, "total_latency_s": 0.264, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.354404926300049, 0.0725405365228653, 3.299755096435547, 3.948962688446045, 3.414088010787964, 0.8524714708328247, 0.08404397964477539, 3.404561996459961], "entropies_second": null, "final_normalized_entropy": 0.0758713157178732, "sequence_confidence_first": 0.40761223280286374, "sequence_confidence_second": null, "sequence_confidence_final": 0.40761223280286374, "token_confidences_first": [0.26898935437202454, 0.9887984395027161, 0.25437799096107483, 0.2381703108549118, 0.30652114748954773, 0.895753800868988, 0.9897026419639587, 0.16462475061416626, 0.4308894872665405], "token_confidences_second": null, "final_mean_entropy": 2.303853588178754, "final_min_margin": 0.020627975463867188, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8913043478260869, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Combo 1 30.000 TOTAL 30.000 CASH 50.000 CHANGED 20.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for 3000 yen at x cafe", "used_ocr": false, "answer_first": "receipt for 3000 yen at x cafe", "answer_second": null, "raw_answer": "receipt for 3000 yen at x cafe", "raw_answer_first": "receipt for 3000 yen at x cafe", "raw_answer_second": null, "mean_entropy_first": 2.592091827121164, "normalized_entropy_first": 0.6598018910669922, "min_margin_first": 0.1732196807861328, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 391, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 392, "total_latency_s": 0.392, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.735700845718384, 0.06644947826862335, 3.3086190223693848, 3.93093204498291, 1.9499353170394897, 2.682809591293335, 2.8583428859710693, 3.1321752071380615, 4.171022415161133, 0.7124615907669067, 2.9355576038360596, 3.1201634407043457, 3.680119037628174, 0.004997098818421364], "entropies_second": null, "final_normalized_entropy": 0.6598018910669922, "sequence_confidence_first": 0.38651240609256193, "sequence_confidence_second": null, "sequence_confidence_final": 0.38651240609256193, "token_confidences_first": [0.21890957653522491, 0.9898772835731506, 0.29778745770454407, 0.16358314454555511, 0.332650750875473, 0.5157362818717957, 0.4510108530521393, 0.4298739433288574, 0.19328701496124268, 0.8016234636306763, 0.3449065387248993, 0.3244363069534302, 0.23633679747581482, 0.9996370077133179, 0.44631198048591614], "token_confidences_second": null, "final_mean_entropy": 2.592091827121164, "final_min_margin": 0.1732196807861328, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.75, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Lemon Tea (L). 25.000 1 Mike & Ike Original 28.000 1 Mike & Berry 28.000 1 Roti Keju Manis. 7.000 TOTAL 88,000 CASH 88.000 0 CHANGED"], "experiment": "entropy_routing_default", "routed": {"answer": "25 0 0", "used_ocr": true, "answer_first": "receipt for a purchase of 10 items", "answer_second": "25 0 0", "raw_answer": "25 0 0", "raw_answer_first": "receipt for a purchase of 10 items", "raw_answer_second": "25 0 0", "mean_entropy_first": 3.362151428312063, "normalized_entropy_first": 2.233291615421863, "min_margin_first": 0.04404926300048828, "mean_entropy_second": 2.12468476912805, "normalized_entropy_second": -0.3708825610187705, "min_margin_second": 0.2795448303222656, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 300, "latency_ms_ocr": 129, "latency_ms_second": 268, "total_latency_ms": 700, "total_latency_s": 0.7, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.0156850814819336, 0.052436552941799164, 3.2408437728881836, 4.773440361022949, 5.511808395385742, 2.333052635192871, 4.631841659545898, 2.1777913570404053, 3.4071717262268066, 4.477442741394043], "entropies_second": [3.792914390563965, 1.8102742433547974, 1.273762583732605, 3.739327907562256, 0.11010930687189102, 3.9951088428497314, 0.15129610896110535], "final_normalized_entropy": -0.3708825610187705, "sequence_confidence_first": 0.23746270279010345, "sequence_confidence_second": 0.515282645657983, "sequence_confidence_final": 0.515282645657983, "token_confidences_first": [0.5031020641326904, 0.992117702960968, 0.2783321440219879, 0.16813135147094727, 0.05355281010270119, 0.29746994376182556, 0.13227730989456177, 0.2577824294567108, 0.19318655133247375, 0.24786856770515442, 0.22282080352306366], "token_confidences_second": [0.3710191547870636, 0.4555397629737854, 0.7227360606193542, 0.21998938918113708, 0.9864169359207153, 0.38469430804252625, 0.9797695875167847, 0.49746188521385193], "final_mean_entropy": 2.12468476912805, "final_min_margin": 0.2795448303222656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9552238805970149, "wer": 0.9629629629629629, "precision": 0.3333333333333333, "recall": 0.037037037037037035, "f1": 0.06666666666666667, "rouge_l": 0.06666666666666667, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1X S-Bubble Milk Tea @20,000 20,000 100% 1X S-Caramel Milk Tea @20,000 20,000 100% Total: 40,000 Cash: 40,000 CHANGE 0"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.7576616406440735, "normalized_entropy_first": -1.1766600434167394, "min_margin_first": 0.5643396377563477, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 114, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 115, "total_latency_s": 0.115, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.4287772178649902, 0.08654606342315674], "entropies_second": null, "final_normalized_entropy": -1.1766600434167394, "sequence_confidence_first": 0.4118370117130715, "sequence_confidence_second": null, "sequence_confidence_final": 0.4118370117130715, "token_confidences_first": [0.3112104535102844, 0.985370397567749, 0.22778359055519104], "token_confidences_second": null, "final_mean_entropy": 1.7576616406440735, "final_min_margin": 0.5643396377563477, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9576271186440678, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["COPIA 1 /GB 1 45,000.00 2100252000358 45,000.00 PLASTIC BAG RED CENTRAL SI 1 0.00 9100544260074 0.00 COPIA 1 /GB 1 18,000.00 2100252000358 18,000.00 Total 63,000.00 Total discount 0.00 Total quantity 3 Card Payment DEBIT CARD 63,000.00"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for payment of 10,000 dollars", "used_ocr": false, "answer_first": "receipt for payment of 10,000 dollars", "answer_second": null, "raw_answer": "receipt for payment of 10,000 dollars", "raw_answer_first": "receipt for payment of 10,000 dollars", "raw_answer_second": null, "mean_entropy_first": 2.59964403624718, "normalized_entropy_first": 0.4610092800646991, "min_margin_first": 0.023710250854492188, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 368, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 369, "total_latency_s": 0.369, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.5085198879241943, 0.09286563098430634, 3.210519790649414, 4.510697364807129, 2.865004539489746, 4.0246171951293945, 1.943834662437439, 2.3183908462524414, 3.140997886657715, 2.1023130416870117, 0.7370173335075378, 0.6373114585876465, 4.703282833099365], "entropies_second": null, "final_normalized_entropy": 0.4610092800646991, "sequence_confidence_first": 0.35292710017951096, "sequence_confidence_second": null, "sequence_confidence_final": 0.35292710017951096, "token_confidences_first": [0.3535189926624298, 0.9836872220039368, 0.31061339378356934, 0.16554464399814606, 0.35142749547958374, 0.2916589081287384, 0.27418777346611023, 0.400795042514801, 0.27779102325439453, 0.40232613682746887, 0.8573367595672607, 0.9193140268325806, 0.07597216963768005, 0.34509390592575073], "token_confidences_second": null, "final_mean_entropy": 2.59964403624718, "final_min_margin": 0.023710250854492188, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.902127659574468, "wer": 0.9722222222222222, "precision": 0.16666666666666666, "recall": 0.027777777777777776, "f1": 0.04761904761904762, "rouge_l": 0.04761904761904762, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1X S-Hazelnut KOI Cafe 25,000 @25,000 25% Less Ice PB1: 2,272 Subtotal: 22,728 Total: 25,000 Cash: 100,000 CHANGE: 75,000"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for a meal at a restaurant that cost $25 0 0", "used_ocr": true, "answer_first": "receipt for coffee and food", "answer_second": "a receipt for a meal at a restaurant that cost $25 0 0", "raw_answer": "a receipt for a meal at a restaurant that cost $25 0 0", "raw_answer_first": "receipt for coffee and food", "raw_answer_second": "a receipt for a meal at a restaurant that cost $25 0 0", "mean_entropy_first": 3.051994562149048, "normalized_entropy_first": 1.2773900438832024, "min_margin_first": 0.13058853149414062, "mean_entropy_second": 2.0500939813883683, "normalized_entropy_second": -0.5933234043384643, "min_margin_second": 0.08605194091796875, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 214, "latency_ms_ocr": 112, "latency_ms_second": 549, "total_latency_ms": 878, "total_latency_s": 0.878, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.089862108230591, 0.0765535831451416, 3.2278008460998535, 4.3888654708862305, 2.8801016807556152, 4.6487836837768555], "entropies_second": [1.6162357330322266, 1.4382424354553223, 0.007024195045232773, 2.849307060241699, 3.5875840187072754, 3.9372737407684326, 0.008381601423025131, 2.5424532890319824, 3.0676066875457764, 3.03853702545166, 3.3097965717315674, 2.661539316177368, 1.844582200050354, 0.9021597504615784, 1.1401530504226685, 2.307997941970825, 0.6167813539505005, 3.759962558746338, 0.31616711616516113], "final_normalized_entropy": -0.5933234043384643, "sequence_confidence_first": 0.30490927518033545, "sequence_confidence_second": 0.43309971324757385, "sequence_confidence_final": 0.43309971324757385, "token_confidences_first": [0.4566454589366913, 0.987481951713562, 0.2798973023891449, 0.1579173058271408, 0.35578110814094543, 0.11001929640769958, 0.3140551745891571], "token_confidences_second": [0.6498206853866577, 0.7955771684646606, 0.9993380904197693, 0.23434877395629883, 0.19428104162216187, 0.2032453715801239, 0.9992966651916504, 0.42891639471054077, 0.21914318203926086, 0.3298253118991852, 0.16883446276187897, 0.24609927833080292, 0.5399630069732666, 0.8187192678451538, 0.7096350193023682, 0.5655360817909241, 0.8805615305900574, 0.12665918469429016, 0.9469770789146423, 0.4676007032394409], "final_mean_entropy": 2.0500939813883683, "final_min_margin": 0.08605194091796875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7933884297520661, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Ptgs Eggtart 12,000 1 Choco Melt 11,000 SUBTOTAL 23,000 DUE 23,000 CASH 50,000 CHANGE 27,000 TOTAL QTY 2 PCS 2 ITEM"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for a charge of $2000", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for a charge of $2000", "raw_answer_second": "receipt", "mean_entropy_first": 2.840908582237634, "normalized_entropy_first": 0.7384173908926976, "min_margin_first": 0.024990081787109375, "mean_entropy_second": 1.741376481950283, "normalized_entropy_second": -1.2681198710819177, "min_margin_second": 1.5114221572875977, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 327, "latency_ms_ocr": 110, "latency_ms_second": 127, "total_latency_ms": 566, "total_latency_s": 0.566, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.522318124771118, 0.08355642110109329, 3.2883148193359375, 4.713707447052002, 4.421013832092285, 2.7509469985961914, 1.3027492761611938, 1.7858128547668457, 2.729611873626709, 3.2690558433532715, 3.382906913757324], "entropies_second": [3.395073413848877, 0.08767955005168915], "final_normalized_entropy": -1.2681198710819177, "sequence_confidence_first": 0.3036485962624322, "sequence_confidence_second": 0.504039852106625, "sequence_confidence_final": 0.504039852106625, "token_confidences_first": [0.34511566162109375, 0.9860497117042542, 0.23811006546020508, 0.15302997827529907, 0.26128092408180237, 0.34359419345855713, 0.5090193748474121, 0.418658047914505, 0.21795004606246948, 0.2062174677848816, 0.24639081954956055, 0.23387476801872253], "token_confidences_second": [0.424002081155777, 0.9848684072494507, 0.30665385723114014], "final_mean_entropy": 1.741376481950283, "final_min_margin": 1.5114221572875977, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9487179487179487, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TRAD KY TOAST CARTE 28.182 ITEMS 1.00 SUBTTL 28.182 PB-1 10% 2.818 TOTAL 31.000 CASH 31.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 2.078344449400902, "normalized_entropy_first": -0.7462794485510322, "min_margin_first": 0.3050727844238281, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 126, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 130, "total_latency_s": 0.13, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.102441787719727, 0.054247111082077026], "entropies_second": null, "final_normalized_entropy": -0.7462794485510322, "sequence_confidence_first": 0.3617570969798526, "sequence_confidence_second": null, "sequence_confidence_final": 0.3617570969798526, "token_confidences_first": [0.20282047986984253, 0.9920744895935059, 0.2352854609489441], "token_confidences_second": null, "final_mean_entropy": 2.078344449400902, "final_min_margin": 0.3050727844238281, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9340659340659341, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Superice Cauburry 17,727 SubTulal: 17,727 PB1: 1,773 Total: 19,500 Lash: 100,000 Change: 80,500"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for a total of $1 7 73 dollars", "used_ocr": true, "answer_first": "receipt for a total of 19000 dollars", "answer_second": "a receipt for a total of $1 7 73 dollars", "raw_answer": "a receipt for a total of $1 7 73 dollars", "raw_answer_first": "receipt for a total of 19000 dollars", "raw_answer_second": "a receipt for a total of $1 7 73 dollars", "mean_entropy_first": 2.964507261147866, "normalized_entropy_first": 1.013937783267483, "min_margin_first": 0.016557693481445312, "mean_entropy_second": 2.0152354230483374, "normalized_entropy_second": -0.8103353817659078, "min_margin_second": 0.4057655334472656, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 370, "latency_ms_ocr": 122, "latency_ms_second": 424, "total_latency_ms": 918, "total_latency_s": 0.918, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.78631591796875, 0.07946619391441345, 3.378565788269043, 5.045768737792969, 5.280778408050537, 0.8820821046829224, 0.9891072511672974, 0.8229182362556458, 2.3988993167877197, 2.64298152923584, 3.7784361839294434, 4.6422319412231445, 4.811042785644531], "entropies_second": [1.4839824438095093, 1.5930907726287842, 0.021109506487846375, 2.764030933380127, 4.719983100891113, 4.954228401184082, 1.0830532312393188, 1.723576307296753, 1.3961536884307861, 1.5843071937561035, 0.5232477188110352, 2.80087947845459, 0.6625595688819885, 0.9936516284942627, 3.9246773719787598], "final_normalized_entropy": -0.8103353817659078, "sequence_confidence_first": 0.28788425858100936, "sequence_confidence_second": 0.4555419826272833, "sequence_confidence_final": 0.4555419826272833, "token_confidences_first": [0.3111797571182251, 0.9869741201400757, 0.2503519058227539, 0.1324928104877472, 0.09783175587654114, 0.857793927192688, 0.5978745222091675, 0.8312428593635559, 0.3222695589065552, 0.2259482443332672, 0.2649317979812622, 0.11828745156526566, 0.09206416457891464, 0.30088332295417786], "token_confidences_second": [0.7102404832839966, 0.776295006275177, 0.9978101849555969, 0.27335891127586365, 0.18316227197647095, 0.13461604714393616, 0.7667284607887268, 0.530856728553772, 0.6343457102775574, 0.4519869387149811, 0.9002886414527893, 0.334389328956604, 0.8546556830406189, 0.8737382292747498, 0.16838499903678894, 0.20995555818080902], "final_mean_entropy": 2.0152354230483374, "final_min_margin": 0.4057655334472656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7835051546391752, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["(TA) NASI GRG TERI MEDAN 4 165,460 (TA) BIHUN GORENG SEAFOOD 1 40,456 (TA) KWETIAW SEAFOOD SIRAM 1 42,274 (TA) NASI GORENG 2 55,456 ITEMS: 8 303,646 Pb1 10% 30,365 Rounding 334,011 Rounding -11 Total 334,000 DEBIT BCA 334,000"], "experiment": "entropy_routing_default", "routed": {"answer": "solaria", "used_ocr": true, "answer_first": "receipt for solaria", "answer_second": "solaria", "raw_answer": "solaria", "raw_answer_first": "receipt for solaria", "raw_answer_second": "solaria", "mean_entropy_first": 2.8537660241127014, "normalized_entropy_first": 0.7023553893469275, "min_margin_first": 0.12811279296875, "mean_entropy_second": 2.872860908508301, "normalized_entropy_second": 0.7391890852128983, "min_margin_second": 0.9415426254272461, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 179, "latency_ms_ocr": 202, "latency_ms_second": 159, "total_latency_ms": 542, "total_latency_s": 0.542, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.692028045654297, 0.0520365834236145, 2.823657512664795, 2.3916616439819336, 5.309446334838867], "entropies_second": [4.548503875732422, 1.1972179412841797], "final_normalized_entropy": 0.7391890852128983, "sequence_confidence_first": 0.33899231664445373, "sequence_confidence_second": 0.5449289908833423, "sequence_confidence_final": 0.5449289908833423, "token_confidences_first": [0.2496701031923294, 0.9924048781394958, 0.34374502301216125, 0.6030714511871338, 0.14583727717399597, 0.20258624851703644], "token_confidences_second": [0.26365429162979126, 0.822387158870697, 0.7462916374206543], "final_mean_entropy": 2.872860908508301, "final_min_margin": 0.9415426254272461, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9733333333333334, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["THAI ICED TEA 1 @20.000 20.000 THAI ICED TEA 1 @20.000 20.000 SUB-TOTAL 40.000 GRANDTOTAL 40.000 CASH 100.000 CHANGED 60.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.4855209663510323, "normalized_entropy_first": -2.0654441389394886, "min_margin_first": 1.5124645233154297, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 110, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 111, "total_latency_s": 0.111, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.883784294128418, 0.08725763857364655], "entropies_second": null, "final_normalized_entropy": -2.0654441389394886, "sequence_confidence_first": 0.4998531456065189, "sequence_confidence_second": null, "sequence_confidence_final": 0.4998531456065189, "token_confidences_first": [0.4963975250720978, 0.9853805899620056, 0.25532519817352295], "token_confidences_second": null, "final_mean_entropy": 1.4855209663510323, "final_min_margin": 1.5124645233154297, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.967741935483871, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Pecel Komplit + Nasi 42.000 1 SOTO KUDUS 47.000 2 Mineral Water 18.000 Subtotal 107.000 Servi Charge 57 5.350 Pajak Rest 10% 11.235 Total 123.585 4"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for kroger's grocery store", "used_ocr": false, "answer_first": "receipt for kroger's grocery store", "answer_second": null, "raw_answer": "receipt for kroger's grocery store", "raw_answer_first": "receipt for kroger's grocery store", "raw_answer_second": null, "mean_entropy_first": 2.2203538063913584, "normalized_entropy_first": -0.35326465229516274, "min_margin_first": 0.09324169158935547, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 344, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 345, "total_latency_s": 0.345, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.5191612243652344, 0.06947565078735352, 3.2797770500183105, 4.675752639770508, 4.842842102050781, 2.514371633529663, 3.817988872528076, 0.04603710025548935, 3.786994457244873, 0.49741700291633606, 0.005625307559967041, 0.5888026356697083], "entropies_second": null, "final_normalized_entropy": -0.35326465229516274, "sequence_confidence_first": 0.42367470651202666, "sequence_confidence_second": null, "sequence_confidence_final": 0.42367470651202666, "token_confidences_first": [0.5941328406333923, 0.9892353415489197, 0.26565468311309814, 0.14813871681690216, 0.08659195899963379, 0.3485545814037323, 0.27051448822021484, 0.9964770674705505, 0.1969183087348938, 0.8246152400970459, 0.9995854496955872, 0.9123138189315796, 0.5085643529891968], "token_confidences_second": null, "final_mean_entropy": 2.2203538063913584, "final_min_margin": 0.09324169158935547, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8590604026845637, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["KACANG MERAH 10,000 SUBTOTAL 10,000 TOTAL 10,000 CASH 10,000"], "experiment": "entropy_routing_default", "routed": {"answer": "dj kacan herah", "used_ocr": true, "answer_first": "receipt for a total of 100 dollars", "answer_second": "dj kacan herah", "raw_answer": "dj kacan herah", "raw_answer_first": "receipt for a total of 100 dollars", "raw_answer_second": "dj kacan herah", "mean_entropy_first": 2.809504936364564, "normalized_entropy_first": 0.7480954917525268, "min_margin_first": 0.03783607482910156, "mean_entropy_second": 2.1893137650830403, "normalized_entropy_second": -0.39002650412227097, "min_margin_second": 0.5896272659301758, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 327, "latency_ms_ocr": 77, "latency_ms_second": 251, "total_latency_ms": 657, "total_latency_s": 0.657, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.034237384796143, 0.07042675465345383, 3.258457660675049, 4.795604705810547, 4.443109512329102, 2.1618313789367676, 1.2857885360717773, 1.7438799142837524, 1.5808634757995605, 3.686702251434326, 3.8436527252197266], "entropies_second": [4.296505928039551, 0.24246132373809814, 2.0398101806640625, 0.2862188518047333, 3.437145233154297, 3.3262410163879395, 1.6968138217926025], "final_normalized_entropy": -0.39002650412227097, "sequence_confidence_first": 0.34746666218638633, "sequence_confidence_second": 0.5276939339829032, "sequence_confidence_final": 0.5276939339829032, "token_confidences_first": [0.26411592960357666, 0.9893677830696106, 0.25946375727653503, 0.12879595160484314, 0.24097265303134918, 0.573867917060852, 0.5766723155975342, 0.5009447336196899, 0.6521852612495422, 0.20377551019191742, 0.19870387017726898, 0.33620062470436096], "token_confidences_second": [0.1960630863904953, 0.9735378623008728, 0.6712950468063354, 0.9684337377548218, 0.24465470016002655, 0.4263874590396881, 0.6792581677436829, 0.683804452419281], "final_mean_entropy": 2.1893137650830403, "final_min_margin": 0.5896272659301758, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8833333333333333, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 APPLE CINNAMON PASTRY 22,000 2 ROYAL CHEESE TART 32,000 TOTAL 54,000 CARD 54,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for 3 cinnamon rolls and a total of $800", "used_ocr": false, "answer_first": "receipt for 3 cinnamon rolls and a total of $800", "answer_second": null, "raw_answer": "receipt for 3 cinnamon rolls and a total of $800", "raw_answer_first": "receipt for 3 cinnamon rolls and a total of $800", "raw_answer_second": null, "mean_entropy_first": 2.0557694742946246, "normalized_entropy_first": -0.728206211751404, "min_margin_first": 0.08086585998535156, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 500, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 501, "total_latency_s": 0.501, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.241734027862549, 0.07868216186761856, 3.3434958457946777, 4.159972190856934, 1.4935108423233032, 4.6876444816589355, 0.5699872970581055, 0.1781047284603119, 0.028742652386426926, 2.7200140953063965, 0.3906136155128479, 1.7896349430084229, 3.108680486679077, 4.705207347869873, 1.4491667747497559, 0.7092175483703613, 1.9570436477661133, 1.9538564682006836, 2.4943108558654785], "entropies_second": null, "final_normalized_entropy": -0.728206211751404, "sequence_confidence_first": 0.4286513452859679, "sequence_confidence_second": null, "sequence_confidence_final": 0.4286513452859679, "token_confidences_first": [0.3655516803264618, 0.9868805408477783, 0.2167116105556488, 0.14820389449596405, 0.4079802632331848, 0.20277415215969086, 0.9177694320678711, 0.9740656018257141, 0.9972838163375854, 0.2975103259086609, 0.9521889090538025, 0.6462480425834656, 0.32215508818626404, 0.10297911614179611, 0.5690594911575317, 0.8560150861740112, 0.2939015328884125, 0.4814866781234741, 0.327644020318985, 0.3741711676120758], "token_confidences_second": null, "final_mean_entropy": 2.0557694742946246, "final_min_margin": 0.08086585998535156, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7195121951219512, "wer": 0.9285714285714286, "precision": 0.2, "recall": 0.14285714285714285, "f1": 0.16666666666666666, "rouge_l": 0.16666666666666666, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["AIR MINERAL 8,181 SUBTOTAL 8,181 TAX 818 TL 8,999 CASH 10,000 CG 1,001"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for air mineral and a total of 8181", "used_ocr": true, "answer_first": "receipt for air mirage hotel", "answer_second": "receipt for air mineral and a total of 8181", "raw_answer": "receipt for air mineral and a total of 8181", "raw_answer_first": "receipt for air mirage hotel", "raw_answer_second": "receipt for air mineral and a total of 8181", "mean_entropy_first": 3.4737757705152035, "normalized_entropy_first": 2.0686981800816313, "min_margin_first": 0.021495819091796875, "mean_entropy_second": 2.4097897122303644, "normalized_entropy_second": 0.011330468513039324, "min_margin_second": 0.061873435974121094, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 258, "latency_ms_ocr": 141, "latency_ms_second": 430, "total_latency_ms": 832, "total_latency_s": 0.832, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.9264798164367676, 0.0686785876750946, 3.363248348236084, 4.209333896636963, 4.62651252746582, 3.0595030784606934, 4.344501495361328, 5.191948413848877], "entropies_second": [2.6925768852233887, 0.08786027133464813, 2.786548614501953, 2.6579365730285645, 2.150648593902588, 0.4379270076751709, 4.2942795753479, 3.8915696144104004, 4.619562149047852, 0.9750799536705017, 1.6845036745071411, 1.8332710266113281, 4.0377516746521, 1.5366495847702026, 2.4606804847717285], "final_normalized_entropy": 0.011330468513039324, "sequence_confidence_first": 0.27439633308761135, "sequence_confidence_second": 0.38757192174758975, "sequence_confidence_final": 0.38757192174758975, "token_confidences_first": [0.47778865694999695, 0.9890502691268921, 0.20144379138946533, 0.214962437748909, 0.16256369650363922, 0.4095301032066345, 0.27625125646591187, 0.11278954893350601, 0.20775502920150757], "token_confidences_second": [0.49253055453300476, 0.9855641722679138, 0.2863613963127136, 0.30547502636909485, 0.7140809893608093, 0.9168751239776611, 0.08998500555753708, 0.22381778061389923, 0.14718453586101532, 0.8168140053749084, 0.4953066110610962, 0.36190369725227356, 0.18468043208122253, 0.6869275569915771, 0.6062936186790466, 0.2792794108390808], "final_mean_entropy": 2.4097897122303644, "final_min_margin": 0.061873435974121094, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8, "wer": 1.0, "precision": 0.2222222222222222, "recall": 0.15384615384615385, "f1": 0.18181818181818185, "rouge_l": 0.18181818181818185, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["ICED TT 20,000 ICED GT 22,000 CASH 42,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.5702224355190992, "normalized_entropy_first": -1.604521655808243, "min_margin_first": 0.3362283706665039, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 113, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 113, "total_latency_s": 0.113, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.079044818878174, 0.06140005216002464], "entropies_second": null, "final_normalized_entropy": -1.604521655808243, "sequence_confidence_first": 0.4235681207675768, "sequence_confidence_second": null, "sequence_confidence_final": 0.4235681207675768, "token_confidences_first": [0.3101941645145416, 0.9901366233825684, 0.24742355942726135], "token_confidences_second": null, "final_mean_entropy": 1.5702224355190992, "final_min_margin": 0.3362283706665039, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9024390243902439, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 PHO BO TAI 55,000 CASH 100,000 Sub Total: 55,000 PB1 5,500 Total: 60,500 Pay: 100,000 Change Due: 39,500"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.8046688735485077, "normalized_entropy_first": -0.9815406328008308, "min_margin_first": 0.6851968765258789, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 123, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 126, "total_latency_s": 0.126, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.5432822704315186, 0.06605547666549683], "entropies_second": null, "final_normalized_entropy": -0.9815406328008308, "sequence_confidence_first": 0.5062510629049457, "sequence_confidence_second": null, "sequence_confidence_final": 0.5062510629049457, "token_confidences_first": [0.3238699734210968, 0.9892577528953552, 0.40496519207954407], "token_confidences_second": null, "final_mean_entropy": 1.8046688735485077, "final_min_margin": 0.6851968765258789, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9716981132075472, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Tahu Isi 2 78,000 Tea 5 30,000 Kepiting 7-8.4ons - Chilly 0.7 1 1 297,490 Udang Telur Asin - Regular 1 47,500 Kailan 2 Rasa 1 45,000 Mantau - 2 pcs 1 25,000 Sweet Tea 2 16,000 Nasi Putih 7 42,000 Mantau - 3 pcs 1 37,500 Total Item 9 Total Qty 21 Subtotal 618,490 Tax 61,849 Total 680,500"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt for food", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt for food", "raw_answer_second": "yes", "mean_entropy_first": 2.6729650273919106, "normalized_entropy_first": 0.5122221597932013, "min_margin_first": 0.10496044158935547, "mean_entropy_second": 2.5725159645080566, "normalized_entropy_second": 0.3500847722771285, "min_margin_second": 0.8394718170166016, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 178, "latency_ms_ocr": 809, "latency_ms_second": 154, "total_latency_ms": 1148, "total_latency_s": 1.148, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.913323163986206, 0.08272948861122131, 3.1757521629333496, 4.520055294036865], "entropies_second": [2.5725159645080566], "final_normalized_entropy": 0.3500847722771285, "sequence_confidence_first": 0.3422810648950849, "sequence_confidence_second": 0.6112418602773293, "sequence_confidence_final": 0.6112418602773293, "token_confidences_first": [0.48791396617889404, 0.9860088229179382, 0.25311776995658875, 0.1682482808828354, 0.22930686175823212], "token_confidences_second": [0.37582460045814514, 0.9941249489784241], "final_mean_entropy": 2.5725159645080566, "final_min_margin": 0.8394718170166016, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9895470383275261, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 EGG TART 13,000 2 CHOCO CUS ARD PASTRY 24,000 1 REDBEAN BREAD 9,000 TOTAL 46,000 CASH 50,000 CHANGE 4,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a meal at a restaurant that cost $46 07", "used_ocr": true, "answer_first": "receipt for 6000 yen", "answer_second": "receipt for a meal at a restaurant that cost $46 07", "raw_answer": "receipt for a meal at a restaurant that cost $46 07", "raw_answer_first": "receipt for 6000 yen", "raw_answer_second": "receipt for a meal at a restaurant that cost $46 07", "mean_entropy_first": 3.0623403869569303, "normalized_entropy_first": 1.133658786874412, "min_margin_first": 0.026968002319335938, "mean_entropy_second": 2.408757862251471, "normalized_entropy_second": 0.03593622230149755, "min_margin_second": 0.05008506774902344, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 307, "latency_ms_ocr": 114, "latency_ms_second": 503, "total_latency_ms": 928, "total_latency_s": 0.928, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7368969917297363, 0.10008420795202255, 3.5165061950683594, 4.564146518707275, 1.9008897542953491, 3.890471935272217, 3.8517956733703613, 3.888288974761963, 4.47438907623291, 0.6999345421791077], "entropies_second": [3.55692982673645, 0.10860085487365723, 2.8385226726531982, 3.2898128032684326, 4.39699649810791, 0.013405924662947655, 2.7814478874206543, 3.9339475631713867, 1.6991631984710693, 3.206435203552246, 2.4456992149353027, 1.8635914325714111, 1.5003728866577148, 1.5000004768371582, 3.08524227142334, 1.7565739154815674, 2.9721410274505615], "final_normalized_entropy": 0.03593622230149755, "sequence_confidence_first": 0.29478976050213684, "sequence_confidence_second": 0.3867713198887789, "sequence_confidence_final": 0.3867713198887789, "token_confidences_first": [0.3419730067253113, 0.9825415015220642, 0.266424298286438, 0.12386912107467651, 0.25136077404022217, 0.20367443561553955, 0.2607937157154083, 0.2885848879814148, 0.23096108436584473, 0.8328890800476074, 0.17775671184062958], "token_confidences_second": [0.41038206219673157, 0.9811962842941284, 0.2915147542953491, 0.35741686820983887, 0.1893956959247589, 0.998691976070404, 0.3109823167324066, 0.20070606470108032, 0.7486889958381653, 0.16471557319164276, 0.4417419135570526, 0.5634968280792236, 0.5708614587783813, 0.6218847036361694, 0.3809857666492462, 0.48409929871559143, 0.1674470603466034, 0.2250305563211441], "final_mean_entropy": 2.408757862251471, "final_min_margin": 0.05008506774902344, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7663551401869159, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Topping Milo Sparkle (untuk 1 Po rsi) 1x 1.250 1.250 Bola Ubi Mini Original (14 Pcs ) 2x 12.500 25.000 Subtotal 26.250 Pajak - Total 26.250 Pembayaran GO-PAY"], "experiment": "entropy_routing_default", "routed": {"answer": "topping mi", "used_ocr": true, "answer_first": "receipt for a purchase of 100 ringgit", "answer_second": "topping mi", "raw_answer": "topping mi", "raw_answer_first": "receipt for a purchase of 100 ringgit", "raw_answer_second": "topping mi", "mean_entropy_first": 3.237162491927544, "normalized_entropy_first": 1.3037420632717962, "min_margin_first": 0.17803955078125, "mean_entropy_second": 2.3385983308156333, "normalized_entropy_second": -0.19375407008485648, "min_margin_second": 0.4867277145385742, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 352, "latency_ms_ocr": 138, "latency_ms_second": 174, "total_latency_ms": 667, "total_latency_s": 0.667, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.531909942626953, 0.06369759142398834, 3.201101541519165, 4.860895156860352, 5.100465297698975, 2.345195770263672, 4.593581199645996, 1.9940674304962158, 3.602281093597412, 4.57217264175415, 3.7672884464263916, 1.2132937908172607], "entropies_second": [4.109076499938965, 0.7434184551239014, 2.163300037384033], "final_normalized_entropy": -0.19375407008485648, "sequence_confidence_first": 0.29115646393210115, "sequence_confidence_second": 0.4290161691269138, "sequence_confidence_final": 0.4290161691269138, "token_confidences_first": [0.4210469722747803, 0.9902665019035339, 0.2473311871290207, 0.12830422818660736, 0.12244988977909088, 0.26955461502075195, 0.16050726175308228, 0.2864963710308075, 0.2809429168701172, 0.226930633187294, 0.36976855993270874, 0.6794044375419617, 0.33593297004699707], "token_confidences_second": [0.22461946308612823, 0.881973147392273, 0.4835553467273712, 0.3536272346973419], "final_mean_entropy": 2.3385983308156333, "final_min_margin": 0.4867277145385742, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9363057324840764, "wer": 0.9642857142857143, "precision": 0.5, "recall": 0.03571428571428571, "f1": 0.06666666666666667, "rouge_l": 0.06666666666666667, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1x 6500 TALAM UNGU 6,500 DISC ITEM -40.000% AMOUNT -2 600 1X 8000 AREM - AREM 8,000 DISC ITEM -40.000% AMOUNT -3,200 2X 9000 LEMPER 18,000 DISC ITEM -40.000% AMOUNT -7.200 1X 0 MIKA SEDANG 0 1X 0 PLASTIK KECIL 0 1X 5000 TEH KOTAK 5,000 7.00 ITEMs SUBTOTAL 24,500 TOTAL 24,500 CARD 24,500"], "experiment": "entropy_routing_default", "routed": {"answer": "5", "used_ocr": true, "answer_first": "receipt for a drink", "answer_second": "5", "raw_answer": "5", "raw_answer_first": "receipt for a drink", "raw_answer_second": "5", "mean_entropy_first": 3.331491105258465, "normalized_entropy_first": 1.296667107757442, "min_margin_first": 0.04019737243652344, "mean_entropy_second": 2.5995471477508545, "normalized_entropy_second": 0.10793217835020924, "min_margin_second": 0.19874286651611328, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 185, "latency_ms_ocr": 195, "latency_ms_second": 148, "total_latency_ms": 530, "total_latency_s": 0.53, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.371657609939575, 0.0790918692946434, 3.0484609603881836, 4.981942176818848, 5.176302909851074], "entropies_second": [3.6002511978149414, 1.5988430976867676], "final_normalized_entropy": 0.10793217835020924, "sequence_confidence_first": 0.272027266430775, "sequence_confidence_second": 0.40888309926260297, "sequence_confidence_final": 0.40888309926260297, "token_confidences_first": [0.3986409306526184, 0.9868020415306091, 0.27199456095695496, 0.14247503876686096, 0.08972086012363434, 0.2962581217288971], "token_confidences_second": [0.2597322165966034, 0.5614537000656128, 0.4687677323818207], "final_mean_entropy": 2.5995471477508545, "final_min_margin": 0.19874286651611328, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9965156794425087, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 XXI Java Tea (M) 18.000 1 Combo 2 30.000 TOTAL 48.000 CASH 50.000 CHANGED 2,000"], "experiment": "entropy_routing_default", "routed": {"answer": "200", "used_ocr": true, "answer_first": "1000", "answer_second": "200", "raw_answer": "200", "raw_answer_first": "1000", "raw_answer_second": "200", "mean_entropy_first": 2.914711356163025, "normalized_entropy_first": 0.47800468841971505, "min_margin_first": 0.12104606628417969, "mean_entropy_second": 2.961156815290451, "normalized_entropy_second": 0.5515716405366267, "min_margin_second": 0.16807174682617188, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 186, "latency_ms_ocr": 117, "latency_ms_second": 174, "total_latency_ms": 479, "total_latency_s": 0.479, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.4711556434631348, 1.9900480508804321, 2.180555582046509, 3.5109190940856934, 3.4208784103393555], "entropies_second": [4.133651256561279, 1.8257020711898804, 4.413410186767578, 1.4718637466430664], "final_normalized_entropy": 0.5515716405366267, "sequence_confidence_first": 0.27063912213917035, "sequence_confidence_second": 0.31972436517349145, "sequence_confidence_final": 0.31972436517349145, "token_confidences_first": [0.23089414834976196, 0.2605268061161041, 0.4648912847042084, 0.2973010241985321, 0.41695502400398254, 0.1133551076054573], "token_confidences_second": [0.20785070955753326, 0.2931961417198181, 0.11901962757110596, 0.6452417969703674, 0.7138842940330505], "final_mean_entropy": 2.961156815290451, "final_min_margin": 0.16807174682617188, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9629629629629629, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Kopi Susu Kampung. x1 19.000 Ice Kopi Susu Kampung Less Ice 0 Kopi Susu Kampung. x2 38.000 Ice Subtotal 57.000 Total 57.000 Cash 60.000 Change 3.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 2.4350117221474648, "normalized_entropy_first": -0.3435395882249966, "min_margin_first": 0.8361196517944336, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 113, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 114, "total_latency_s": 0.114, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.741063117980957, 0.12896032631397247], "entropies_second": null, "final_normalized_entropy": -0.3435395882249966, "sequence_confidence_first": 0.44374600482811616, "sequence_confidence_second": null, "sequence_confidence_final": 0.44374600482811616, "token_confidences_first": [0.22137333452701569, 0.9787248969078064, 0.4032899737358093], "token_confidences_second": null, "final_mean_entropy": 2.4350117221474648, "final_min_margin": 0.8361196517944336, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9594594594594594, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["SINGLE SCOOP 16.000 TOTAL 16.000 CATEND 50.000 CHANGE 34.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.7191548682749271, "normalized_entropy_first": -1.5624288980256773, "min_margin_first": 0.4591989517211914, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 115, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 117, "total_latency_s": 0.117, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.3493881225585938, 0.08892161399126053], "entropies_second": null, "final_normalized_entropy": -1.5624288980256773, "sequence_confidence_first": 0.41993732689190605, "sequence_confidence_second": null, "sequence_confidence_final": 0.41993732689190605, "token_confidences_first": [0.2908744513988495, 0.9848268032073975, 0.2585163414478302], "token_confidences_second": null, "final_mean_entropy": 1.7191548682749271, "final_min_margin": 0.4591989517211914, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9333333333333333, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Bubur Polos + Telur 1 13.000 13.000 Subtotal 13.000 Pajak - Total 13.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for a hotel room", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for a hotel room", "raw_answer_second": "receipt", "mean_entropy_first": 3.143878942976395, "normalized_entropy_first": 1.0003874979914724, "min_margin_first": 0.00806427001953125, "mean_entropy_second": 2.208934172987938, "normalized_entropy_second": -0.5281544188038723, "min_margin_second": 0.46627235412597656, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 207, "latency_ms_ocr": 116, "latency_ms_second": 127, "total_latency_ms": 453, "total_latency_s": 0.453, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.772670269012451, 0.059739746153354645, 3.2492880821228027, 4.963318824768066, 5.3011369705200195, 1.5171197652816772], "entropies_second": [4.340802192687988, 0.07706615328788757], "final_normalized_entropy": -0.5281544188038723, "sequence_confidence_first": 0.29384971019181627, "sequence_confidence_second": 0.48693815288752296, "sequence_confidence_final": 0.48693815288752296, "token_confidences_first": [0.35800766944885254, 0.991098940372467, 0.22050859034061432, 0.14624015986919403, 0.09599054604768753, 0.7055385708808899, 0.24413280189037323], "token_confidences_second": [0.21591529250144958, 0.9885864853858948, 0.5409079194068909], "final_mean_entropy": 2.208934172987938, "final_min_margin": 0.46627235412597656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9444444444444444, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["PILLOW DURIA 36,364 PLASTIK 25 0 SUBTOTAL 36,364 PD1 10% 10.000Z AMOUNT 3,636 TOTAL 40,000 CASH 50,000 CHANGE 10,000"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt with a total of $36 and a subtotal of $25", "used_ocr": true, "answer_first": "receipt for a purchase of 304.95", "answer_second": "a receipt with a total of $36 and a subtotal of $25", "raw_answer": "a receipt with a total of $36 and a subtotal of $25", "raw_answer_first": "receipt for a purchase of 304.95", "raw_answer_second": "a receipt with a total of $36 and a subtotal of $25", "mean_entropy_first": 3.2185783518048434, "normalized_entropy_first": 1.0275897027243914, "min_margin_first": 0.025770187377929688, "mean_entropy_second": 2.1302686005106404, "normalized_entropy_second": -0.7605894114993729, "min_margin_second": 0.11216926574707031, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 357, "latency_ms_ocr": 124, "latency_ms_second": 523, "total_latency_ms": 1006, "total_latency_s": 1.006, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.4572925567626953, 0.08262806385755539, 3.3808507919311523, 4.806249618530273, 5.341147422790527, 2.3433802127838135, 3.981471061706543, 1.976569652557373, 3.693953037261963, 4.2934980392456055, 4.261203765869141, 2.4415640830993652, 1.7817102670669556], "entropies_second": [2.8773250579833984, 1.4174787998199463, 0.015448485501110554, 2.725722074508667, 3.7182397842407227, 3.872783660888672, 1.2627919912338257, 1.6381909847259521, 1.5814119577407837, 2.235562562942505, 3.636766195297241, 3.7078170776367188, 4.950560092926025, 0.6421687006950378, 0.4554206430912018, 0.5160336494445801, 1.9826502799987793, 1.1084628105163574], "final_normalized_entropy": -0.7605894114993729, "sequence_confidence_first": 0.24871873225575516, "sequence_confidence_second": 0.4612035583823934, "sequence_confidence_final": 0.4612035583823934, "token_confidences_first": [0.331514835357666, 0.9862610697746277, 0.26340270042419434, 0.14118169248104095, 0.09259830415248871, 0.25688642263412476, 0.27322691679000854, 0.2874935269355774, 0.26661819219589233, 0.12116756290197372, 0.15936104953289032, 0.2203880399465561, 0.5285573601722717, 0.2544434368610382], "token_confidences_second": [0.3819657862186432, 0.809814989566803, 0.9982280135154724, 0.24879181385040283, 0.18751811981201172, 0.38904258608818054, 0.7764898538589478, 0.5411862134933472, 0.5767093300819397, 0.30802473425865173, 0.18005762994289398, 0.28347644209861755, 0.14795580506324768, 0.8617050051689148, 0.9427639245986938, 0.9234291911125183, 0.4146358072757721, 0.737200915813446, 0.5674667358398438], "final_mean_entropy": 2.1302686005106404, "final_min_margin": 0.11216926574707031, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7844827586206896, "wer": 1.0, "precision": 0.16666666666666666, "recall": 0.10526315789473684, "f1": 0.12903225806451615, "rouge_l": 0.06451612903225808, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["2005- CHEESE JOHN 9.500,00 x1 9.500,00 Total Item: 1 Total. 9.500,00 Cash Tendered: 9.500,00"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.505078410729766, "normalized_entropy_first": -1.8952966354680458, "min_margin_first": 1.3456230163574219, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 108, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 109, "total_latency_s": 0.109, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.953449249267578, 0.05670757219195366], "entropies_second": null, "final_normalized_entropy": -1.8952966354680458, "sequence_confidence_first": 0.5135924072567728, "sequence_confidence_second": null, "sequence_confidence_final": 0.5135924072567728, "token_confidences_first": [0.46840181946754456, 0.9909923076629639, 0.2918548583984375], "token_confidences_second": null, "final_mean_entropy": 1.505078410729766, "final_min_margin": 1.3456230163574219, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9565217391304348, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["ICED TT 20,000 TOTAL 20,000 CASH 50,000 CHANGE 30,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 2.056933518499136, "normalized_entropy_first": -0.720386126472215, "min_margin_first": 0.19692134857177734, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 110, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 111, "total_latency_s": 0.111, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.033567428588867, 0.08029960840940475], "entropies_second": null, "final_normalized_entropy": -0.720386126472215, "sequence_confidence_first": 0.3526162035978319, "sequence_confidence_second": null, "sequence_confidence_final": 0.3526162035978319, "token_confidences_first": [0.18994206190109253, 0.9870163798332214, 0.23386287689208984], "token_confidences_second": null, "final_mean_entropy": 2.056933518499136, "final_min_margin": 0.19692134857177734, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9433962264150944, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 [MD] SOFT MORNING ROLL 18,000 2 REAL HONEY PANCAKE BREAD 20,000 4 CUSTARD BRIOCHE 36,000 TOTAL 74,000 CASH 100,000 CHANGE 26,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a total of 7,000 dollars", "used_ocr": false, "answer_first": "receipt for a total of 7,000 dollars", "answer_second": null, "raw_answer": "receipt for a total of 7,000 dollars", "raw_answer_first": "receipt for a total of 7,000 dollars", "raw_answer_second": null, "mean_entropy_first": 2.3460802484590273, "normalized_entropy_first": -0.2237738716454335, "min_margin_first": 0.006350517272949219, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 377, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 381, "total_latency_s": 0.381, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.0493597984313965, 0.062410954385995865, 3.543849468231201, 4.466230869293213, 4.706387996673584, 1.7396693229675293, 0.9749689102172852, 0.8446413278579712, 2.5289597511291504, 2.2459826469421387, 1.308609962463379, 1.0058307647705078, 4.022141456604004], "entropies_second": null, "final_normalized_entropy": -0.2237738716454335, "sequence_confidence_first": 0.4066766731803705, "sequence_confidence_second": null, "sequence_confidence_final": 0.4066766731803705, "token_confidences_first": [0.45379507541656494, 0.9905067682266235, 0.2194294035434723, 0.12961962819099426, 0.1691887229681015, 0.6937939524650574, 0.5520570278167725, 0.8088473677635193, 0.3355277478694916, 0.26069748401641846, 0.6819320917129517, 0.8334002494812012, 0.2593696117401123, 0.3917195796966553], "token_confidences_second": null, "final_mean_entropy": 2.3460802484590273, "final_min_margin": 0.006350517272949219, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8384615384615385, "wer": 0.9545454545454546, "precision": 0.14285714285714285, "recall": 0.045454545454545456, "f1": 0.06896551724137931, "rouge_l": 0.06896551724137931, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Kupon 15 100,000 ADD CHICKEN BOX 909 Subtotal 100,909 PB1 (10%) 10,091 Total 111,000 Cash Rp. 111,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a car rental", "used_ocr": false, "answer_first": "receipt for a car rental", "answer_second": null, "raw_answer": "receipt for a car rental", "raw_answer_first": "receipt for a car rental", "raw_answer_second": null, "mean_entropy_first": 2.885970551786678, "normalized_entropy_first": 0.6571316410555242, "min_margin_first": 0.09847259521484375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 229, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 230, "total_latency_s": 0.23, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.3662846088409424, 0.08957333862781525, 3.2633655071258545, 4.934457302093506, 5.338482856750488, 3.1866557598114014, 0.022974489256739616], "entropies_second": null, "final_normalized_entropy": 0.6571316410555242, "sequence_confidence_first": 0.3261905853192259, "sequence_confidence_second": null, "sequence_confidence_final": 0.3261905853192259, "token_confidences_first": [0.44322460889816284, 0.9849135279655457, 0.22904033958911896, 0.1630464792251587, 0.06774719059467316, 0.3910059630870819, 0.9976160526275635, 0.2975006401538849], "token_confidences_second": null, "final_mean_entropy": 2.885970551786678, "final_min_margin": 0.09847259521484375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8910891089108911, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["2 UDANG RE 216,000 432,000 2 =*LARGE*== 1 AYM GR JUN NJAN 108,000 =*MEDIUM*= 1 SAPO TH SEAFOOD 172,000 =*LARGE*== 2 POCAI 3 111,000 222.000 2 =*MEDIUM*= 1 GURAME FILLET M 163,000 ASAM MANIS 1 BIHUN GORENG JJ 116,000 =*LARGE*== 5 ICED TEA 12,000 60,000 7 NASI PUTIH 10,000 70,000 FOOD 1,213,000 BEVERAGES 60,000 OTHERS 70,000 SUBTOTAL 1,343,000 SERVICE CHARGE 80,580 Tax 10% 142,358 DU 1,565,938"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a car wash", "used_ocr": false, "answer_first": "receipt for a car wash", "answer_second": null, "raw_answer": "receipt for a car wash", "raw_answer_first": "receipt for a car wash", "raw_answer_second": null, "mean_entropy_first": 2.734827216182436, "normalized_entropy_first": 0.3593274390114726, "min_margin_first": 0.44655799865722656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 238, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 239, "total_latency_s": 0.239, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.5696935653686523, 0.06348828226327896, 3.1148650646209717, 4.530412197113037, 5.064935207366943, 2.7285590171813965, 0.0718371793627739], "entropies_second": null, "final_normalized_entropy": 0.3593274390114726, "sequence_confidence_first": 0.3713617369945567, "sequence_confidence_second": null, "sequence_confidence_final": 0.3713617369945567, "token_confidences_first": [0.304898738861084, 0.9896962642669678, 0.29101425409317017, 0.14648430049419403, 0.1265145242214203, 0.501178503036499, 0.9933104515075684, 0.4464743435382843], "token_confidences_second": null, "final_mean_entropy": 2.734827216182436, "final_min_margin": 0.44655799865722656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.949238578680203, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Cuka Apel Tetes 1 198000 198000 Sub Total 198000 Tunai 200200 Kembalian 22000"], "experiment": "entropy_routing_default", "routed": {"answer": "cuka", "used_ocr": true, "answer_first": "receipt for a purchase of 1000 ringgit", "answer_second": "cuka", "raw_answer": "cuka", "raw_answer_first": "receipt for a purchase of 1000 ringgit", "raw_answer_second": "cuka", "mean_entropy_first": 3.246703715278552, "normalized_entropy_first": 1.2291744640447995, "min_margin_first": 0.1764049530029297, "mean_entropy_second": 2.7832238376140594, "normalized_entropy_second": 0.42289962636159006, "min_margin_second": 0.18770313262939453, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 369, "latency_ms_ocr": 66, "latency_ms_second": 127, "total_latency_ms": 564, "total_latency_s": 0.564, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.999544858932495, 0.10423921048641205, 3.16864013671875, 5.477258682250977, 5.85440731048584, 2.3105247020721436, 4.684016227722168, 1.5333034992218018, 2.770533800125122, 3.005093574523926, 3.0513768196105957, 4.830483436584473, 1.4177260398864746], "entropies_second": [5.23526668548584, 0.33118098974227905], "final_normalized_entropy": 0.42289962636159006, "sequence_confidence_first": 0.3059311609345654, "sequence_confidence_second": 0.3632262111793046, "sequence_confidence_final": 0.3632262111793046, "token_confidences_first": [0.3154377043247223, 0.9823250770568848, 0.27670764923095703, 0.10704211890697479, 0.06494539231061935, 0.361954003572464, 0.2330709844827652, 0.5301097631454468, 0.42562970519065857, 0.3515397608280182, 0.5137348771095276, 0.10805653780698776, 0.6404274106025696, 0.4436752200126648], "token_confidences_second": [0.10896633565425873, 0.9518002867698669, 0.46205466985702515], "final_mean_entropy": 2.7832238376140594, "final_min_margin": 0.18770313262939453, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.948051948051948, "wer": 0.9230769230769231, "precision": 1.0, "recall": 0.07692307692307693, "f1": 0.14285714285714288, "rouge_l": 0.14285714285714288, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Choco Devil 15,909 SubTotal: 15,909 PB1: 1,591 Total: 17,500 cash: 20,000 Change: 2,500"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a chocolate cake", "used_ocr": false, "answer_first": "receipt for a chocolate cake", "answer_second": null, "raw_answer": "receipt for a chocolate cake", "raw_answer_first": "receipt for a chocolate cake", "raw_answer_second": null, "mean_entropy_first": 2.5095554085241423, "normalized_entropy_first": -0.17300971930965572, "min_margin_first": 0.16032981872558594, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 269, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 270, "total_latency_s": 0.27, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8208656311035156, 0.07691139727830887, 3.5527184009552, 4.303071022033691, 4.82663631439209, 1.161258339881897, 0.37998488545417786, 4.379895210266113, 0.08465747535228729], "entropies_second": null, "final_normalized_entropy": -0.17300971930965572, "sequence_confidence_first": 0.32725765133150936, "sequence_confidence_second": null, "sequence_confidence_final": 0.32725765133150936, "token_confidences_first": [0.22913500666618347, 0.9875118732452393, 0.2425539493560791, 0.14796428382396698, 0.11462971568107605, 0.7396458983421326, 0.954728364944458, 0.09396658837795258, 0.9885257482528687, 0.23074735701084137], "token_confidences_second": null, "final_mean_entropy": 2.5095554085241423, "final_min_margin": 0.16032981872558594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8426966292134831, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1001-Choco Bun 22.000 x1 22.000 6001-Plastic Bag Small 0 x1 0 Total Item: 2 22.000 Total. Cash 25.000 Tendered: 3.000 Change:"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a meal at a restaurant", "used_ocr": false, "answer_first": "receipt for a meal at a restaurant", "answer_second": null, "raw_answer": "receipt for a meal at a restaurant", "raw_answer_first": "receipt for a meal at a restaurant", "raw_answer_second": null, "mean_entropy_first": 2.9135332217233048, "normalized_entropy_first": 0.5628287088910644, "min_margin_first": 0.18383121490478516, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 273, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 274, "total_latency_s": 0.274, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6925601959228516, 0.08542606979608536, 3.4372036457061768, 4.394845485687256, 5.013245582580566, 0.01142132468521595, 2.896742343902588, 4.386387825012207, 2.303966522216797], "entropies_second": null, "final_normalized_entropy": 0.5628287088910644, "sequence_confidence_first": 0.3382890870099579, "sequence_confidence_second": null, "sequence_confidence_final": 0.3382890870099579, "token_confidences_first": [0.295806884765625, 0.9856280088424683, 0.26648223400115967, 0.15648266673088074, 0.09185390919446945, 0.9990440011024475, 0.28834035992622375, 0.2024962157011032, 0.5251941084861755, 0.5737195014953613], "token_confidences_second": null, "final_mean_entropy": 2.9135332217233048, "final_min_margin": 0.18383121490478516, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.848, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 BLACKCURRANT 32,000 1 SPRITE 32,000 BEVERAGE 64,000 1 GRILLED CALAMARI 85,000 1 DINE FOR 2 129,000 * DANISH FISH & CHIPS DF * NEW YORK FISH & CHIPS FOOD 214,000 SUBTTL 278,000 Service Charge 22,240 TAX 30,024 TOTAL 330,264"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.6592129990458488, "normalized_entropy_first": -1.8159641522049452, "min_margin_first": 1.2939786911010742, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 123, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 127, "total_latency_s": 0.127, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.2619099617004395, 0.05651603639125824], "entropies_second": null, "final_normalized_entropy": -1.8159641522049452, "sequence_confidence_first": 0.5030440267254663, "sequence_confidence_second": null, "sequence_confidence_final": 0.5030440267254663, "token_confidences_first": [0.39757341146469116, 0.9911412000656128, 0.32304656505584717], "token_confidences_second": null, "final_mean_entropy": 1.6592129990458488, "final_min_margin": 1.2939786911010742, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.96875, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 CHOCO PUFF 29,091 1 CREAMY BEEF CLS FTC 42,727 1 NEW ORIENTAL CHK RICE 34,545 1 LIPTON PITCHER 54,545 1 SC/P SUPER SUPREME 47,273 1 CB/P BLACK PEPP BEEF 48,182 SUBTOTAL 256,363 TAX 25,637 TOTAL 282,000"], "experiment": "entropy_routing_default", "routed": {"answer": "total 2,800", "used_ocr": false, "answer_first": "total 2,800", "answer_second": null, "raw_answer": "total 2,800", "raw_answer_first": "total 2,800", "raw_answer_second": null, "mean_entropy_first": 2.5742506810597012, "normalized_entropy_first": 0.0675385538334368, "min_margin_first": 0.3604593276977539, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 227, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 227, "total_latency_s": 0.227, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.976990222930908, 3.311659336090088, 1.8367806673049927, 2.3339030742645264, 2.292977809906006, 2.233447551727295, 2.033996105194092], "entropies_second": null, "final_normalized_entropy": 0.0675385538334368, "sequence_confidence_first": 0.28520651154639254, "sequence_confidence_second": null, "sequence_confidence_final": 0.28520651154639254, "token_confidences_first": [0.16765505075454712, 0.2876691222190857, 0.46617579460144043, 0.333076149225235, 0.2364465445280075, 0.2077959179878235, 0.41996800899505615, 0.28332582116127014], "token_confidences_second": null, "final_mean_entropy": 2.5742506810597012, "final_min_margin": 0.3604593276977539, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9458128078817734, "wer": 0.972972972972973, "precision": 0.5, "recall": 0.02702702702702703, "f1": 0.05128205128205129, "rouge_l": 0.05128205128205129, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["BASO TAHU *46000 NASI PUTIH *6000 BASO TAHU *46000 2x 6000 NASI PUTIH *12000 TEMS 50 - ASH *110000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for a car wash", "used_ocr": false, "answer_first": "receipt for a car wash", "answer_second": null, "raw_answer": "receipt for a car wash", "raw_answer_first": "receipt for a car wash", "raw_answer_second": null, "mean_entropy_first": 2.827286577650479, "normalized_entropy_first": 0.5191145585163258, "min_margin_first": 0.006875038146972656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 226, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 228, "total_latency_s": 0.228, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7224574089050293, 0.09518439322710037, 3.4265010356903076, 4.472089767456055, 5.018651962280273, 2.9676010608673096, 0.08852041512727737], "entropies_second": null, "final_normalized_entropy": 0.5191145585163258, "sequence_confidence_first": 0.3285756542272271, "sequence_confidence_second": null, "sequence_confidence_final": 0.3285756542272271, "token_confidences_first": [0.26944446563720703, 0.9834012985229492, 0.2818041741847992, 0.13368311524391174, 0.07743528485298157, 0.44970566034317017, 0.9914104342460632, 0.39421966671943665], "token_confidences_second": null, "final_mean_entropy": 2.827286577650479, "final_min_margin": 0.006875038146972656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8775510204081632, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TRIPPLE CHEESE 1 x 17,000 17,000 SUB TOTAL 17,000 GRAND TOTAL 17,000 CASH IDR 22,000 CHANGE DUE 5,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for triple cheese sub total $10 95", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for triple cheese sub total $10 95", "raw_answer_second": "receipt", "mean_entropy_first": 2.3316226809152534, "normalized_entropy_first": -0.44123241753407133, "min_margin_first": 0.053905487060546875, "mean_entropy_second": 1.9621541313827038, "normalized_entropy_second": -1.1323710224177603, "min_margin_second": 0.2710084915161133, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 386, "latency_ms_ocr": 180, "latency_ms_second": 135, "total_latency_ms": 706, "total_latency_s": 0.706, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.4798097610473633, 0.0632786676287651, 3.028884172439575, 3.6320786476135254, 0.5100528597831726, 0.1714458465576172, 2.720411539077759, 1.6117830276489258, 3.6141695976257324, 2.1501376628875732, 2.454317808151245, 3.993415117263794, 2.243384599685669, 2.969548225402832], "entropies_second": [3.8655166625976562, 0.05879160016775131], "final_normalized_entropy": -1.1323710224177603, "sequence_confidence_first": 0.35418724987814587, "sequence_confidence_second": 0.4331733676077916, "sequence_confidence_final": 0.4331733676077916, "token_confidences_first": [0.37193986773490906, 0.9897488951683044, 0.30011269450187683, 0.2540454566478729, 0.9338638186454773, 0.9624486565589905, 0.37831956148147583, 0.5031479001045227, 0.2366800159215927, 0.37785834074020386, 0.2759145200252533, 0.17172254621982574, 0.1472095102071762, 0.23736128211021423, 0.24358272552490234], "token_confidences_second": [0.22028644382953644, 0.9914005398750305, 0.3721759617328644], "final_mean_entropy": 1.9621541313827038, "final_min_margin": 0.2710084915161133, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9504950495049505, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Lemon Tea (L) 25.000 1 Extra Jelly Lychee 5.000 TOTAL 30.000 CASH 30.000 CHANGED 0"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.5797808077186346, "normalized_entropy_first": -1.8828439565565962, "min_margin_first": 0.7230014801025391, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 121, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 125, "total_latency_s": 0.125, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.1100144386291504, 0.04954717680811882], "entropies_second": null, "final_normalized_entropy": -1.8828439565565962, "sequence_confidence_first": 0.5049704751048857, "sequence_confidence_second": null, "sequence_confidence_final": 0.5049704751048857, "token_confidences_first": [0.37885966897010803, 0.9925931096076965, 0.34241148829460144], "token_confidences_second": null, "final_mean_entropy": 1.5797808077186346, "final_min_margin": 0.7230014801025391, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9404761904761905, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1001-Choco Bun 22.000 x1 22.000 6001-Plastic Bag Small 0 x1 0 Total Item: 2 22.000 22.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for a purchase at a store", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for a purchase at a store", "raw_answer_second": "receipt", "mean_entropy_first": 3.269126361235976, "normalized_entropy_first": 1.4532603922282303, "min_margin_first": 0.0028362274169921875, "mean_entropy_second": 1.8909384328871965, "normalized_entropy_second": -0.9844131905357709, "min_margin_second": 0.7329912185668945, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 241, "latency_ms_ocr": 78, "latency_ms_second": 122, "total_latency_ms": 444, "total_latency_s": 0.444, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.0777077674865723, 0.0999942272901535, 3.448159694671631, 4.5177812576293945, 4.786134719848633, 2.318873882293701, 4.407464027404785, 3.4968953132629395], "entropies_second": [3.730726480484009, 0.05115038529038429], "final_normalized_entropy": -0.9844131905357709, "sequence_confidence_first": 0.3026850871358865, "sequence_confidence_second": 0.6230165889654008, "sequence_confidence_final": 0.6230165889654008, "token_confidences_first": [0.44764450192451477, 0.982606828212738, 0.24338679015636444, 0.16222669184207916, 0.1241597905755043, 0.26787233352661133, 0.19778738915920258, 0.32836097478866577, 0.5684966444969177], "token_confidences_second": [0.3279377520084381, 0.993782103061676, 0.7420210838317871], "final_mean_entropy": 1.8909384328871965, "final_min_margin": 0.7329912185668945, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9662921348314607, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 [REG] BLACK SAKURA 45,455 1 COOKIE DOH SAUCES 0 1 NATA DE COCO 0 Sub Total 45,455 PB1 (10%) 4,545 Rounding 0 Total 50,000 Card Payment 50,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for food", "used_ocr": false, "answer_first": "receipt for food", "answer_second": null, "raw_answer": "receipt for food", "raw_answer_first": "receipt for food", "raw_answer_second": null, "mean_entropy_first": 2.853390818461776, "normalized_entropy_first": 0.5484329384554633, "min_margin_first": 0.5097513198852539, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 152, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 153, "total_latency_s": 0.153, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8038291931152344, 0.07088281959295273, 3.270728588104248, 4.268122673034668], "entropies_second": null, "final_normalized_entropy": 0.5484329384554633, "sequence_confidence_first": 0.35442992757743963, "sequence_confidence_second": null, "sequence_confidence_final": 0.35442992757743963, "token_confidences_first": [0.3347186744213104, 0.988501787185669, 0.3341984748840332, 0.22759269177913666, 0.22224487364292145], "token_confidences_second": null, "final_mean_entropy": 2.853390818461776, "final_min_margin": 0.5097513198852539, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9230769230769231, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Viet Milk Coffee 25,000 +Ice +M Subtotal 25.000 Total 25.000 CASH 25.000 Kembalian 0"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.648952730000019, "normalized_entropy_first": -1.606537803230142, "min_margin_first": 0.5378627777099609, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 107, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 108, "total_latency_s": 0.108, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.2428174018859863, 0.05508805811405182], "entropies_second": null, "final_normalized_entropy": -1.606537803230142, "sequence_confidence_first": 0.4249006317441595, "sequence_confidence_second": null, "sequence_confidence_final": 0.4249006317441595, "token_confidences_first": [0.3003551959991455, 0.9914278388023376, 0.25761187076568604], "token_confidences_second": null, "final_mean_entropy": 1.648952730000019, "final_min_margin": 0.5378627777099609, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9418604651162791, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["3002-Kyoto Choco Mochi x2 14.000 28.000 1001-Choco Bun x1 22.000 22.000 6001-Plastic Bag Small x1 0 0 Total Item: 4 Total. 50.000"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt for 3000 yen and 1500yen", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt for 3000 yen and 1500yen", "raw_answer_second": "yes", "mean_entropy_first": 2.416130355614073, "normalized_entropy_first": -0.09027134325790293, "min_margin_first": 0.055869102478027344, "mean_entropy_second": 3.4942195415496826, "normalized_entropy_second": 1.6923484912726217, "min_margin_second": 1.0364093780517578, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 454, "latency_ms_ocr": 197, "latency_ms_second": 132, "total_latency_ms": 788, "total_latency_s": 0.788, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.0364303588867188, 0.07656279951334, 3.3066375255584717, 4.081396579742432, 1.1883151531219482, 1.6781980991363525, 1.4893076419830322, 1.588159203529358, 3.3129162788391113, 1.0054478645324707, 3.813380002975464, 3.5802865028381348, 1.9513733386993408, 2.4074554443359375, 2.0037107467651367, 1.2388001680374146, 5.31583833694458], "entropies_second": [3.4942195415496826], "final_normalized_entropy": 1.6923484912726217, "sequence_confidence_first": 0.4286415829019638, "sequence_confidence_second": 0.5523079758268081, "sequence_confidence_final": 0.5523079758268081, "token_confidences_first": [0.39722850918769836, 0.9873003363609314, 0.26672112941741943, 0.20705758035182953, 0.6835513710975647, 0.6344488263130188, 0.6446875929832458, 0.7705326676368713, 0.5391620397567749, 0.7627127766609192, 0.18279854953289032, 0.2941434383392334, 0.27721163630485535, 0.3044789433479309, 0.6327455043792725, 0.8149486780166626, 0.1342996060848236, 0.39567261934280396], "token_confidences_second": [0.3328382670879364, 0.9164934754371643], "final_mean_entropy": 3.4942195415496826, "final_min_margin": 1.0364093780517578, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9844961240310077, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Chocolate Log Cake 1x 115,000 115,000 Snowman Cake Chocolate 1x 60,000 60,000 Strawberry Log Cake 2x 105,000 210,000 Sub Total 385,000 GRAND TOTAL 385,000 VISA MASTER 385,000 8213 CHANGE 0"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for a purchase of 40 pieces of choclate cake and 6 pieces of strawbery log cakes with a total cost of $38 500", "used_ocr": true, "answer_first": "receipt for a meal at a restaurant", "answer_second": "a receipt for a purchase of 40 pieces of choclate cake and 6 pieces of strawbery log cakes with a total cost of $38 500", "raw_answer": "a receipt for a purchase of 40 pieces of choclate cake and 6 pieces of strawbery log cakes with a total cost of $38 500", "raw_answer_first": "receipt for a meal at a restaurant", "raw_answer_second": "a receipt for a purchase of 40 pieces of choclate cake and 6 pieces of strawbery log cakes with a total cost of $38 500", "mean_entropy_first": 2.993370222962565, "normalized_entropy_first": 0.9200815495570122, "min_margin_first": 0.037311553955078125, "mean_entropy_second": 1.6807344040220105, "normalized_entropy_second": -1.3668341799749784, "min_margin_second": 0.013326644897460938, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 261, "latency_ms_ocr": 175, "latency_ms_second": 1033, "total_latency_ms": 1471, "total_latency_s": 1.471, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.378967046737671, 0.09591759741306305, 3.645481824874878, 5.079524517059326, 5.412725448608398, 0.02550428733229637, 2.9125866889953613, 4.187952995300293, 2.201671600341797], "entropies_second": [1.4044201374053955, 1.644827127456665, 0.012906478717923164, 3.0743045806884766, 3.4675586223602295, 4.404699802398682, 2.245713710784912, 3.2494149208068848, 1.4817090034484863, 0.6086906790733337, 2.993746280670166, 0.6404244303703308, 1.4643782377243042, 0.44115257263183594, 2.7704029083251953, 1.2038640975952148, 0.3630739450454712, 2.1756038665771484, 2.5080394744873047, 1.6052889823913574, 4.2269792556762695, 0.1951296180486679, 2.1888675689697266, 0.25216537714004517, 1.695665717124939, 0.9771833419799805, 1.6598691940307617, 0.9614888429641724, 0.3803027868270874, 3.5315592288970947, 2.2991628646850586, 2.812436580657959, 1.8558508157730103, 0.5037029385566711, 1.4228122234344482, 1.3706316947937012, 0.5574130415916443, 1.9284559488296509, 0.5232272148132324, 1.1812450885772705, 0.6257413625717163], "final_normalized_entropy": -1.3668341799749784, "sequence_confidence_first": 0.34569677350676586, "sequence_confidence_second": 0.5551427196914865, "sequence_confidence_final": 0.5551427196914865, "token_confidences_first": [0.42049333453178406, 0.9829656481742859, 0.19787903130054474, 0.17205172777175903, 0.0901331752538681, 0.9976381063461304, 0.3297840356826782, 0.193205788731575, 0.6434058547019958, 0.4698989987373352], "token_confidences_second": [0.7851088643074036, 0.7679566740989685, 0.9984979629516602, 0.18979300558567047, 0.2549576163291931, 0.12420172244310379, 0.5224674344062805, 0.20123866200447083, 0.5421234965324402, 0.9224903583526611, 0.5287836790084839, 0.894508421421051, 0.7746473550796509, 0.9403324723243713, 0.486884206533432, 0.7503470182418823, 0.9164279699325562, 0.5474473237991333, 0.3858884871006012, 0.3687240183353424, 0.26883819699287415, 0.977644681930542, 0.5226492285728455, 0.9507002234458923, 0.732414960861206, 0.7815977931022644, 0.6620327830314636, 0.8520013093948364, 0.9404168128967285, 0.1399899125099182, 0.5783408880233765, 0.28937676548957825, 0.5021357536315918, 0.9371513724327087, 0.5446732640266418, 0.4567281901836395, 0.8977206349372864, 0.4255233705043793, 0.8960570096969604, 0.7818944454193115, 0.9116589426994324, 0.40576890110969543], "final_mean_entropy": 1.6807344040220105, "final_min_margin": 0.013326644897460938, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.7127659574468085, "wer": 0.9666666666666667, "precision": 0.12, "recall": 0.1, "f1": 0.1090909090909091, "rouge_l": 0.1090909090909091, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 COOKIES AND CREAM 20,909 Subtotal 20,909 PAJAK 10% 2,091 Total 23,000 1 Tendered 25.000 Kembali 2.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for food", "used_ocr": false, "answer_first": "receipt for food", "answer_second": null, "raw_answer": "receipt for food", "raw_answer_first": "receipt for food", "raw_answer_second": null, "mean_entropy_first": 2.8355843517929316, "normalized_entropy_first": 0.5598795094385484, "min_margin_first": 0.00044155120849609375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 157, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 158, "total_latency_s": 0.158, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.2618229389190674, 0.08907727152109146, 3.318373441696167, 4.6730637550354], "entropies_second": null, "final_normalized_entropy": 0.5598795094385484, "sequence_confidence_first": 0.3367896182900853, "sequence_confidence_second": null, "sequence_confidence_final": 0.3367896182900853, "token_confidences_first": [0.4052320718765259, 0.9850531220436096, 0.2983376681804657, 0.12715177237987518, 0.28615379333496094], "token_confidences_second": null, "final_mean_entropy": 2.8355843517929316, "final_min_margin": 0.00044155120849609375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9223300970873787, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Kroket @ 12.000 1x 12.000 Arem Arem @ 12.000 2x 24.000 Subtotal Rp 36.000 Tax (10.0%) Rp 3.600 Total Rp 39.600 Other Rp 39.600"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.5694137066602707, "normalized_entropy_first": -1.7944205653137606, "min_margin_first": 1.0520000457763672, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 109, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 110, "total_latency_s": 0.11, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.0782365798950195, 0.06059083342552185], "entropies_second": null, "final_normalized_entropy": -1.7944205653137606, "sequence_confidence_first": 0.46729448230282483, "sequence_confidence_second": null, "sequence_confidence_final": 0.46729448230282483, "token_confidences_first": [0.4370128810405731, 0.9904796481132507, 0.23573939502239227], "token_confidences_second": null, "final_mean_entropy": 1.5694137066602707, "final_min_margin": 1.0520000457763672, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9603174603174603, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["3 Nasi Putih 30.000 1 Nasi Tambah 7.000 2 Ayam Pop 40.000 1 Samabal SP 11.000 1 Sambal Gabus Asin Cb 18.000 1 Kerupuk Kuah 15.000 1 Ikan Bawal Besa 28.500 1 Telur Dadar 10.000 1 Teh Es 7.000 1 Teh Manis 9.000 1 Es Batu 4.000 Subtotal 179.500 Pajak Rest. 10% 17.950 Total 197.450 14 Ttl Makanan 159.500 Ttl Minuman 20.000 Cash 197.450"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "receipt for a purchase at a store", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "receipt for a purchase at a store", "raw_answer_second": "yes", "mean_entropy_first": 3.374565163627267, "normalized_entropy_first": 1.5483793518706017, "min_margin_first": 0.12387561798095703, "mean_entropy_second": 4.180794715881348, "normalized_entropy_second": 2.901192823140426, "min_margin_second": 0.3310670852661133, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 245, "latency_ms_ocr": 609, "latency_ms_second": 142, "total_latency_ms": 999, "total_latency_s": 0.999, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.469466209411621, 0.08699400722980499, 3.3361926078796387, 4.546144485473633, 5.059096336364746, 2.320763349533081, 4.544948577880859, 3.632915735244751], "entropies_second": [4.180794715881348], "final_normalized_entropy": 2.901192823140426, "sequence_confidence_first": 0.29517670908322485, "sequence_confidence_second": 0.4695812489685544, "sequence_confidence_final": 0.4695812489685544, "token_confidences_first": [0.3761446475982666, 0.9854373931884766, 0.26689663529396057, 0.17346744239330292, 0.1141924187541008, 0.3063121736049652, 0.18017619848251343, 0.23891320824623108, 0.6583467125892639], "token_confidences_second": [0.2232280820608139, 0.9878082871437073], "final_mean_entropy": 4.180794715881348, "final_min_margin": 0.3310670852661133, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.990990990990991, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 Cheezemania 9,500 1 Mamamia 12,500 SUBTOTAL 22,000 DUE 22,000 CASH 52,000 CHANGE 30,000 2 ITEM TOTAL QTY 2 PCS"], "experiment": "entropy_routing_default", "routed": {"answer": "bread life receipt", "used_ocr": true, "answer_first": "receipt for bread life", "answer_second": "bread life receipt", "raw_answer": "bread life receipt", "raw_answer_first": "receipt for bread life", "raw_answer_second": "bread life receipt", "mean_entropy_first": 2.525623232126236, "normalized_entropy_first": -0.029292129010550946, "min_margin_first": 0.329345703125, "mean_entropy_second": 1.9805222488939762, "normalized_entropy_second": -0.8951931124585847, "min_margin_second": 0.14346599578857422, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 183, "latency_ms_ocr": 111, "latency_ms_second": 191, "total_latency_ms": 487, "total_latency_s": 0.487, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.1351356506347656, 0.10427001118659973, 3.257568597793579, 2.998689889907837, 3.1324520111083984], "entropies_second": [2.507328987121582, 2.5807864665985107, 2.732440948486328, 0.10153259336948395], "final_normalized_entropy": -0.8951931124585847, "sequence_confidence_first": 0.3991123512420596, "sequence_confidence_second": 0.4288265426404427, "sequence_confidence_final": 0.4288265426404427, "token_confidences_first": [0.34220606088638306, 0.9816911816596985, 0.2845667004585266, 0.48117512464523315, 0.3551347553730011, 0.24741612374782562], "token_confidences_second": [0.4859633445739746, 0.3720768690109253, 0.3560284674167633, 0.9827782511711121, 0.22920909523963928], "final_mean_entropy": 1.9805222488939762, "final_min_margin": 0.14346599578857422, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9107142857142857, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 PHOTAI CHIN 36,500 Sub Total 36,500 : PB1 10.0% 3,650 : Grand Total 40,150 5183230101 CREDIT CARD 40,150"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.9274949803948402, "normalized_entropy_first": -1.0292756415962314, "min_margin_first": 0.3791646957397461, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 113, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 115, "total_latency_s": 0.115, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7535600662231445, 0.10142989456653595], "entropies_second": null, "final_normalized_entropy": -1.0292756415962314, "sequence_confidence_first": 0.3821218497415036, "sequence_confidence_second": null, "sequence_confidence_final": 0.3821218497415036, "token_confidences_first": [0.23828889429569244, 0.9822229146957397, 0.23839204013347626], "token_confidences_second": null, "final_mean_entropy": 1.9274949803948402, "final_min_margin": 0.3791646957397461, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9622641509433962, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["STIX ECLAIRS 1 x 19,000 19,000 ALMOND CREAM CHEESE 1 x 28,000 28,000 SUB TOTAL 47,000 GRAND TOTAL 47,000 VISA 8945 47,000 CHANGE DUE 0"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for almond cheese", "used_ocr": false, "answer_first": "receipt for almond cheese", "answer_second": null, "raw_answer": "receipt for almond cheese", "raw_answer_first": "receipt for almond cheese", "raw_answer_second": null, "mean_entropy_first": 1.9029731872890676, "normalized_entropy_first": -0.9696653047919335, "min_margin_first": 0.10067176818847656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 233, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 234, "total_latency_s": 0.234, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.056736946105957, 0.06185800954699516, 3.066304922103882, 3.8141021728515625, 0.3017216622829437, 1.8341426849365234, 0.18594591319561005], "entropies_second": null, "final_normalized_entropy": -0.9696653047919335, "sequence_confidence_first": 0.4438683317699557, "sequence_confidence_second": null, "sequence_confidence_final": 0.4438683317699557, "token_confidences_first": [0.20649798214435577, 0.9904332160949707, 0.352289617061615, 0.16529308259487152, 0.9678164124488831, 0.6871496438980103, 0.9601194858551025, 0.19813817739486694], "token_confidences_second": null, "final_mean_entropy": 1.9029731872890676, "final_min_margin": 0.10067176818847656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8656716417910447, "wer": 0.92, "precision": 0.5, "recall": 0.08, "f1": 0.13793103448275865, "rouge_l": 0.13793103448275865, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 XXL Crispy Chicken 40,000 1 Pedas sedikit 0 ITEMS: 1 40,000 Total 40,000 Pay Cash 50,000 Change : 10,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for chicken", "used_ocr": true, "answer_first": "receipt for chicken", "answer_second": "receipt for kal chicken with a total of $40 and $50", "raw_answer": "receipt for chicken", "raw_answer_first": "receipt for chicken", "raw_answer_second": "receipt for kal chicken with a total of $40 and $50", "mean_entropy_first": 2.1415446430444716, "normalized_entropy_first": -0.475983168713663, "min_margin_first": 0.5282554626464844, "mean_entropy_second": 2.4534413402571396, "normalized_entropy_second": 0.0515382066989241, "min_margin_second": 0.01578998565673828, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 183, "latency_ms_ocr": 188, "latency_ms_second": 477, "total_latency_ms": 851, "total_latency_s": 0.851, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.1566996574401855, 0.06392790377140045, 3.0973000526428223, 3.9576821327209473, 0.4321134686470032], "entropies_second": [4.2375383377075195, 0.08513782918453217, 2.5624356269836426, 3.4424805641174316, 1.9856266975402832, 0.592228889465332, 3.7970476150512695, 3.625274419784546, 4.930667400360107, 1.5584511756896973, 1.3005839586257935, 2.125763416290283, 2.1513209342956543, 3.5513534545898438, 3.770965337753296, 1.5730340480804443, 0.41859307885169983], "final_normalized_entropy": -0.475983168713663, "sequence_confidence_first": 0.39773030250256775, "sequence_confidence_second": 0.3917958763870138, "sequence_confidence_final": 0.39773030250256775, "token_confidences_first": [0.4606792628765106, 0.990071177482605, 0.3023079037666321, 0.2558894753456116, 0.910205602645874, 0.1232609674334526], "token_confidences_second": [0.2638230621814728, 0.9863733053207397, 0.3060946464538574, 0.23255787789821625, 0.7213208675384521, 0.9042483568191528, 0.154415100812912, 0.38414886593818665, 0.1960582286119461, 0.6292709112167358, 0.6597989797592163, 0.28384488821029663, 0.41609472036361694, 0.3035023808479309, 0.1782153844833374, 0.5831254720687866, 0.950093150138855, 0.22918592393398285], "final_mean_entropy": 2.1415446430444716, "final_min_margin": 0.5282554626464844, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8867924528301887, "wer": 0.95, "precision": 0.3333333333333333, "recall": 0.05, "f1": 0.08695652173913045, "rouge_l": 0.08695652173913045, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Bumbu Kaldu Ayam 1 36000 36000 Sub Total 36000 Discount (0%) Tunai 50000 Kembalian 14000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.9268425963819027, "normalized_entropy_first": -0.8250391579412806, "min_margin_first": 0.5115175247192383, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 112, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 113, "total_latency_s": 0.113, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.749552011489868, 0.10413318127393723], "entropies_second": null, "final_normalized_entropy": -0.8250391579412806, "sequence_confidence_first": 0.5155780905607011, "sequence_confidence_second": null, "sequence_confidence_final": 0.5155780905607011, "token_confidences_first": [0.32452407479286194, 0.9835445284843445, 0.4293805956840515], "token_confidences_second": null, "final_mean_entropy": 1.9268425963819027, "final_min_margin": 0.5115175247192383, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9659090909090909, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 CIRENG PANDAWA 26,818 Subtotal 26,818 Pb1 2,681 Total 29,500 CASH 29,500 Total Item 1 Total Qty 1"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": true, "answer_first": "receipt for a meal at a restaurant", "answer_second": "receipt", "raw_answer": "receipt", "raw_answer_first": "receipt for a meal at a restaurant", "raw_answer_second": "receipt", "mean_entropy_first": 2.7378420560724206, "normalized_entropy_first": 0.7009374856983416, "min_margin_first": 0.10921478271484375, "mean_entropy_second": 1.2456897348165512, "normalized_entropy_second": -1.9821541390656925, "min_margin_second": 1.7217111587524414, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 275, "latency_ms_ocr": 149, "latency_ms_second": 127, "total_latency_ms": 554, "total_latency_s": 0.554, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.8698575496673584, 0.07399723678827286, 3.2015323638916016, 4.646265506744385, 4.981797218322754, 0.015315551310777664, 2.857790470123291, 4.303289413452148, 1.6907331943511963], "entropies_second": [2.442413806915283, 0.048965662717819214], "final_normalized_entropy": -1.9821541390656925, "sequence_confidence_first": 0.3648057730523697, "sequence_confidence_second": 0.5799882414057399, "sequence_confidence_final": 0.5799882414057399, "token_confidences_first": [0.5161735415458679, 0.9878623485565186, 0.24076297879219055, 0.14700543880462646, 0.1086714118719101, 0.9987377524375916, 0.2972775101661682, 0.23443742096424103, 0.7503557205200195, 0.4075480103492737], "token_confidences_second": [0.6002438068389893, 0.9924829602241516, 0.32749661803245544], "final_mean_entropy": 1.2456897348165512, "final_min_margin": 1.7217111587524414, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9494949494949495, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 BAKSO BNGKS 15.000 6 GORENGAN 6.000 TL 21.000 CASH 30.000 CG 9.000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.7098688185214996, "normalized_entropy_first": -1.25304103322771, "min_margin_first": 1.455946922302246, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 110, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 111, "total_latency_s": 0.111, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.254495143890381, 0.1652424931526184], "entropies_second": null, "final_normalized_entropy": -1.25304103322771, "sequence_confidence_first": 0.5935790183279096, "sequence_confidence_second": null, "sequence_confidence_final": 0.5935790183279096, "token_confidences_first": [0.4654870927333832, 0.967180073261261, 0.4645373523235321], "token_confidences_second": null, "final_mean_entropy": 1.7098688185214996, "final_min_margin": 1.455946922302246, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9558823529411765, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["901016 - TICKET CP 4 60.000 240,000 (Qty=4.00) TOTAL 240.000 CASH 250.000 CHANGE 10,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 2.1269952952861786, "normalized_entropy_first": -0.34871966354622375, "min_margin_first": 0.09518814086914062, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 112, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 113, "total_latency_s": 0.113, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.157914638519287, 0.09607595205307007], "entropies_second": null, "final_normalized_entropy": -0.34871966354622375, "sequence_confidence_first": 0.4223963988392034, "sequence_confidence_second": null, "sequence_confidence_final": 0.4223963988392034, "token_confidences_first": [0.17997319996356964, 0.9830799102783203, 0.42595523595809937], "token_confidences_second": null, "final_mean_entropy": 2.1269952952861786, "final_min_margin": 0.09518814086914062, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9540229885057471, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["THAI ICED TEA (L) 1 X 16,363 16,363 Jumlah Item 1 Sub Total 16,363 Pajak Resto 1,636 Grand Total 17,999"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.402572426944971, "normalized_entropy_first": -1.705223761654386, "min_margin_first": 1.698918342590332, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 112, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 114, "total_latency_s": 0.114, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.7371296882629395, 0.06801516562700272], "entropies_second": null, "final_normalized_entropy": -1.705223761654386, "sequence_confidence_first": 0.5035244053473055, "sequence_confidence_second": null, "sequence_confidence_final": 0.5035244053473055, "token_confidences_first": [0.5335402488708496, 0.9891758561134338, 0.24189165234565735], "token_confidences_second": null, "final_mean_entropy": 1.402572426944971, "final_min_margin": 1.698918342590332, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9514563106796117, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 TAHU GORENG 28,000 1 CAKWE 17,000 1 PHO TAI CHIN(R) 63,000 1 TEA 11,000 Sub Total 119,000 Serv. 7.0% 8,330 PB1 10.0% 12,733 Grand Total 140,063 CREDIT CAR: 140,063"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for food at a restaurant in vietnam", "used_ocr": true, "answer_first": "receipt for a movie ticket and food", "answer_second": "a receipt for food at a restaurant in vietnam", "raw_answer": "a receipt for food at a restaurant in vietnam", "raw_answer_first": "receipt for a movie ticket and food", "raw_answer_second": "a receipt for food at a restaurant in vietnam", "mean_entropy_first": 3.1081631425768137, "normalized_entropy_first": 1.5827241413410136, "min_margin_first": 0.05752754211425781, "mean_entropy_second": 2.0689377998933196, "normalized_entropy_second": -0.24922213241551835, "min_margin_second": 0.13088703155517578, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 253, "latency_ms_ocr": 294, "latency_ms_second": 369, "total_latency_ms": 919, "total_latency_s": 0.919, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.012463569641113, 0.08760614693164825, 3.3477635383605957, 4.272819995880127, 4.60360050201416, 2.056117057800293, 2.7263739109039307, 3.7585604190826416], "entropies_second": [2.6178929805755615, 1.3235137462615967, 0.011847791261970997, 2.591301441192627, 3.591451644897461, 3.0530896186828613, 3.2694668769836426, 1.4438138008117676, 2.8828911781311035, 1.8067786693572998, 0.16626805067062378], "final_normalized_entropy": -0.24922213241551835, "sequence_confidence_first": 0.30131266045011684, "sequence_confidence_second": 0.4331806544277567, "sequence_confidence_final": 0.4331806544277567, "token_confidences_first": [0.20953476428985596, 0.9858990907669067, 0.2943727672100067, 0.15422965586185455, 0.10801311582326889, 0.6006816625595093, 0.30909407138824463, 0.22179192304611206, 0.4907327890396118], "token_confidences_second": [0.4072268009185791, 0.7898170351982117, 0.998623251914978, 0.259043425321579, 0.186149001121521, 0.20585274696350098, 0.3607357144355774, 0.7313939929008484, 0.32045629620552063, 0.6950556039810181, 0.9705316424369812, 0.240068718791008], "final_mean_entropy": 2.0689377998933196, "final_min_margin": 0.13088703155517578, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8363636363636363, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["BASO TAHU 1 43,181 43,181 ES JERUK 1 13,000 13,000 TOTAL 56,181 TAX 10.00 % 5,618 GRAND TOTAL 61,799 TUNAI 62,000 KEMBALI 201"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt for food", "used_ocr": false, "answer_first": "receipt for food", "answer_second": null, "raw_answer": "receipt for food", "raw_answer_first": "receipt for food", "raw_answer_second": null, "mean_entropy_first": 2.47171239182353, "normalized_entropy_first": 0.2851580316796554, "min_margin_first": 0.1296234130859375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 159, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 159, "total_latency_s": 0.159, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.0026745796203613, 0.0737113207578659, 3.0826733112335205, 3.727790355682373], "entropies_second": null, "final_normalized_entropy": 0.2851580316796554, "sequence_confidence_first": 0.39370277965237216, "sequence_confidence_second": null, "sequence_confidence_final": 0.39370277965237216, "token_confidences_first": [0.4691530764102936, 0.9879348278045654, 0.23888874053955078, 0.25500088930130005, 0.33501338958740234], "token_confidences_second": null, "final_mean_entropy": 2.47171239182353, "final_min_margin": 0.1296234130859375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.944, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 BBQ Chicken 41,000 0 1 - Tidak Pedas ITEMS: 1 41,000 Total. 41,000 Pay Cash 50,000 Change: 9,000"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 2.0715601053088903, "normalized_entropy_first": -0.42861623235792, "min_margin_first": 0.6996231079101562, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 112, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 113, "total_latency_s": 0.113, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.083652496337891, 0.05946771427989006], "entropies_second": null, "final_normalized_entropy": -0.42861623235792, "sequence_confidence_first": 0.39219671383724836, "sequence_confidence_second": null, "sequence_confidence_final": 0.39219671383724836, "token_confidences_first": [0.21371932327747345, 0.9905744194984436, 0.2849580645561218], "token_confidences_second": null, "final_mean_entropy": 2.0715601053088903, "final_min_margin": 0.6996231079101562, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9489795918367347, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["2 20.000 BUBUR GO 40.000 PUYUH GO 6.000 3 3.000 SATE ATI GO 9.000 6.00xITEMS TOTAL 55.000 CASH 55.000"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt for a meal that cost $55 0 0", "used_ocr": true, "answer_first": "receipt for a meal", "answer_second": "a receipt for a meal that cost $55 0 0", "raw_answer": "a receipt for a meal that cost $55 0 0", "raw_answer_first": "receipt for a meal", "raw_answer_second": "a receipt for a meal that cost $55 0 0", "mean_entropy_first": 2.5762705582504473, "normalized_entropy_first": 0.5167243117967703, "min_margin_first": 0.2263927459716797, "mean_entropy_second": 1.9374721363419667, "normalized_entropy_second": -0.6472658432251146, "min_margin_second": 0.09783649444580078, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 208, "latency_ms_ocr": 105, "latency_ms_second": 476, "total_latency_ms": 792, "total_latency_s": 0.792, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.21726131439209, 0.12279347330331802, 2.786860942840576, 4.567898750305176, 4.749021053314209, 0.013787815347313881], "entropies_second": [1.6490541696548462, 1.0721325874328613, 0.01482086069881916, 2.734839916229248, 3.7521562576293945, 3.5924887657165527, 0.00975627452135086, 3.1373534202575684, 2.1825876235961914, 2.233409881591797, 1.5536739826202393, 0.9065279364585876, 3.4253787994384766, 0.5131901502609253, 4.055112838745117, 0.16707071661949158], "final_normalized_entropy": -0.6472658432251146, "sequence_confidence_first": 0.3742628840452055, "sequence_confidence_second": 0.46108534638588117, "sequence_confidence_final": 0.46108534638588117, "token_confidences_first": [0.4914814829826355, 0.9767458438873291, 0.30962973833084106, 0.17903150618076324, 0.15699683129787445, 0.9988200068473816, 0.24648945033550262], "token_confidences_second": [0.45329007506370544, 0.8609156608581543, 0.9982826709747314, 0.2638411819934845, 0.176215261220932, 0.3116782605648041, 0.9991163611412048, 0.21718436479568481, 0.4791245758533478, 0.4176303744316101, 0.5234687328338623, 0.827688992023468, 0.25883615016937256, 0.902098536491394, 0.17402835190296173, 0.9734967947006226, 0.458060622215271], "final_mean_entropy": 1.9374721363419667, "final_min_margin": 0.09783649444580078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.801980198019802, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 BLACK PAPPER MEATBALL PAS 79,000 1 TRUFFLE CREAM 77,000 1 EARL GREY MILK TEA 59,000 SUBTTL 215,000 Service Charge 6% 12,900 TAX 10% 22,790 TOTAL 250,690"], "experiment": "entropy_routing_default", "routed": {"answer": "receipt", "used_ocr": false, "answer_first": "receipt", "answer_second": null, "raw_answer": "receipt", "raw_answer_first": "receipt", "raw_answer_second": null, "mean_entropy_first": 1.742641907185316, "normalized_entropy_first": -1.0964190934448061, "min_margin_first": 1.3298301696777344, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 118, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 120, "total_latency_s": 0.12, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.4193239212036133, 0.06595989316701889], "entropies_second": null, "final_normalized_entropy": -1.0964190934448061, "sequence_confidence_first": 0.39823012002905905, "sequence_confidence_second": null, "sequence_confidence_final": 0.39823012002905905, "token_confidences_first": [0.3682798743247986, 0.9894786477088928, 0.17330771684646606], "token_confidences_second": null, "final_mean_entropy": 1.742641907185316, "final_min_margin": 1.3298301696777344, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.961038961038961, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1 FL-Xmas 30 Off 68,180 1 PAKET SLICES 0 1  FL Cake - French Vanilla SLC 0 1 PAKET SLICES 0 1 FL Cake - Green Tea SLC 0 1 PAKET SLICES 0 1 FL Cake - Belgium Choco SLC 0 SUBTOTAL 68,180 DISKON 0 BIAYA TAMBAHAN 0 PAJAK PPN 10 % 6,818 PAJAK 0% 0 BIAYA CC 0 PEMBULATAN 2 TOTAL 75,000 TUNAI 0 NON TUNAI 75,000 KEMBALI 0"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes there is a receipt on the table", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes there is a receipt on the table", "raw_answer_second": "yes", "mean_entropy_first": 2.285266054380271, "normalized_entropy_first": 0.04164063608388096, "min_margin_first": 0.1649036407470703, "mean_entropy_second": 3.1700263023376465, "normalized_entropy_second": 1.7119476355950052, "min_margin_second": 1.832437515258789, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 274, "latency_ms_ocr": 207, "latency_ms_second": 125, "total_latency_ms": 609, "total_latency_s": 0.609, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.275583267211914, 4.051427841186523, 0.8437440395355225, 2.5167500972747803, 3.7059552669525146, 0.02926015295088291, 2.2557287216186523, 1.92193603515625, 0.9670090675354004], "entropies_second": [3.1700263023376465], "final_normalized_entropy": 1.7119476355950052, "sequence_confidence_first": 0.4690610409026486, "sequence_confidence_second": 0.7094798243056748, "sequence_confidence_final": 0.7094798243056748, "token_confidences_first": [0.16764751076698303, 0.1965649276971817, 0.7990706562995911, 0.5971463918685913, 0.36552754044532776, 0.9966668486595154, 0.5405802130699158, 0.3277176320552826, 0.7966881990432739, 0.6376847624778748], "token_confidences_second": [0.508290708065033, 0.9903026223182678], "final_mean_entropy": 3.1700263023376465, "final_min_margin": 1.832437515258789, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9936305732484076, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["ATT. GEN. ADMIN. OFFICE Fax: 614 -466 -5087 Dec 10 '98 17 :46 P. 01 Attorney General Betty D. Montgomery CONFIDENTIAL FACSIMILE TRANSMISSION COVER SHEET FAX NO. (614) 466- 5087 TO: George Baroody FAX NUMBER: (336) 335- 7392 PHONE NUMBER: (336) 335- 7363 DATE: 12 /10 /98 NUMBER OF PAGES INCLUDING COVER SHEET: 3 SENDER /PHONE NUMBER: June Flynn for Eric Brown/ (614) 466- 8980 SPECIAL INSTRUCTIONS: IF YOU DO NOT RECEIVE ANY OF THE PAGES PROPERLY, PLEASE CONTACT SENDER AS SOON AS POSSIBLE NOTE: THIS MESSAGE IS INTENDED ONLY FOR THE USE OF THE INDIVIDUAL OR ENTITY TO WHOM IT IS ADDRESSED AND MAY CONTAIN INFORMATION THAT IS PRIVILEGED. CONFIDENTIAL, AND EXEMPT FROM DISCLOSURE UNDER APPLICABLE LAW. If the reader of this message is not the intended recipient of the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any dissemination, distribution, copying, or conveying of this communication in any manner is strictly prohibited. If you have received this comunication in error, please notify us immediately by telephone and return the original message to us at the address below via the U. S. Postal Service. Thank you for your cooperation. 82092117 State Office Tower / 30 East Broad Street/ Columbus, Ohio 43215 -3428 www ag state oh us An Equal Opportunity Employer Primed an"], "experiment": "entropy_routing_default", "routed": {"answer": "No", "used_ocr": true, "answer_first": "1000", "answer_second": "No", "raw_answer": "No", "raw_answer_first": "1000", "raw_answer_second": "No", "mean_entropy_first": 3.7074472427368166, "normalized_entropy_first": 2.8693719186315554, "min_margin_first": 0.11601734161376953, "mean_entropy_second": 1.7583026885986328, "normalized_entropy_second": -1.0090570741278257, "min_margin_second": 0.5608043670654297, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 184, "latency_ms_ocr": 637, "latency_ms_second": 211, "total_latency_ms": 1034, "total_latency_s": 1.034, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.653182029724121, 2.106588125228882, 2.518768310546875, 3.806671380996704, 4.4520263671875], "entropies_second": [1.7583026885986328], "final_normalized_entropy": -1.0090570741278257, "sequence_confidence_first": 0.16671323854405898, "sequence_confidence_second": 0.7173642528992369, "sequence_confidence_final": 0.7173642528992369, "token_confidences_first": [0.09339866042137146, 0.30313900113105774, 0.3788696825504303, 0.16911228001117706, 0.12967638671398163, 0.09126666188240051], "token_confidences_second": [0.5150166153907776, 0.9992133378982544], "final_mean_entropy": 1.7583026885986328, "final_min_margin": 0.5608043670654297, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9985130111524163, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["09/ 17/ 97 10: 55 603 841 1898 LORILLARD PTLD  001 TO: K. A. Sparrow FROM: T. D. Blachly MAY 12 AUG 4 JUN 23 SEP 15 x SUBJECT: OLD GOLD MENTHOL LIGHTS & ULTRA LIGHTS 100'S PROGRESS REPORT REGION: (ONLY IF PARTIAL REGION CONTINUE WITH DIVISION (S) SCOPE) DIVISION: DIVISION: Portland # REPS: 6 DIVISION: Seattle South # REPS: 7 DIVISION: Boise # REPS: 2. 5 DIVISION: Seattle North # REPS: 4 DIVISION: Eugene # REPS: 5 DIVISION: Helena # REPS: 4 DIRECT ACCOUNTS AND CHAINS HEADQUARTERED WITHIN THE REGION (15 + STORES) STOCKING NO OLD GOLD MENTHOL LIGHTS OR ULTRA LIGHTS 100'S VOLUME NO. OF STORES VOLUME NAME OF ACCOUNT NAME OF ACCOUNT NO. OF STORES Texaco Seattle 105 / 5 225 Texaco Portland 61 / 3 27 Maid -O Clover 20 / 2 15 Dari Mart 125 / 5 31 Zip Trip 106 / 4 18 Maverick 77 / 1 19 Astro Gas 600 / 7 20 82200067 Page 1 of 3 Pages"], "experiment": "entropy_routing_default", "routed": {"answer": "No", "used_ocr": true, "answer_first": "1000", "answer_second": "No", "raw_answer": "No", "raw_answer_first": "1000", "raw_answer_second": "No", "mean_entropy_first": 3.761227750778198, "normalized_entropy_first": 2.0994680861665644, "min_margin_first": 0.2791023254394531, "mean_entropy_second": 2.504176139831543, "normalized_entropy_second": 0.1468780522864865, "min_margin_second": 0.6471366882324219, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 189, "latency_ms_ocr": 413, "latency_ms_second": 179, "total_latency_ms": 784, "total_latency_s": 0.784, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.6302103996276855, 2.10627818107605, 2.49998140335083, 4.041703224182129, 4.527965545654297], "entropies_second": [2.504176139831543], "final_normalized_entropy": 0.1468780522864865, "sequence_confidence_first": 0.1725246449762569, "sequence_confidence_second": 0.638945143410458, "sequence_confidence_final": 0.638945143410458, "token_confidences_first": [0.0790427103638649, 0.28995761275291443, 0.40212389826774597, 0.1584981232881546, 0.15976925194263458, 0.11298825591802597], "token_confidences_second": [0.4084025025367737, 0.9996287822723389], "final_mean_entropy": 2.504176139831543, "final_min_margin": 0.6471366882324219, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9976047904191617, "wer": 0.9940119760479041, "precision": 1.0, "recall": 0.005988023952095809, "f1": 0.011904761904761906, "rouge_l": 0.011904761904761906, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["COMPETITIVE PRODUCT INTRODUCTION PROGRESS REPORT B&W TO: Sam Zolot MANUFACTURER: FROM: D. J. Landro BRAND: Kool Waterfall DATE: 2- Dec- 97 TYPE OF PACKINGS: All Packings Oct. REPORTING PERIODS: Nov. X Dec. Jan. TEST MARKET GEOGRAPHY: Divisions 621 and 627 wisconsin (Indicate Distributor's Cost Per Carton) PRICE POINT: FULLS $ P/ V $ SALES FORCE INVOLVEMENT: They have crew- worked distribution, and it is reported that they may crew- work it again Sales force has been busy promoting old style backs to clean up inventory. All POS is being converted to \"B\" Kool. DISTRIBUTORS ACCEPTANCE INTRO TERMS INTRO DEALS INVOLVEMENT: All accounts have the new packaging. It was not a problem obtaining new distribution. All accounts appear to have 100% distribution of new packings. CHAINS ACCEPTANCE/ MERCHANDISING: This has not been a problem. New packaging is just following on the old \"packaging\". INDEPENDENTS ACCEPTANCE/ MERCHANDISING: Very well received. The packs are peing consolidated and promoted in select retail locations at 40 off $4 00 off cartons. ADVERTISING EFFECTIVENESS OF P. O. S.: The theme \"B\" Kool has replaced all previous POS. They have effectively replaced all old POS. New door signage, hour signs, poster mats, and clocks have the new design. \"B\" Kool also appears on billboards in llinois. 82250337 PAGE 1 OF 2"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "100% correct", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "100% correct", "raw_answer_second": "Yes", "mean_entropy_first": 3.523988922437032, "normalized_entropy_first": 1.33571621026455, "min_margin_first": 0.4317493438720703, "mean_entropy_second": 0.7606871724128723, "normalized_entropy_second": -2.43363573778391, "min_margin_second": 1.632822036743164, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 220, "latency_ms_ocr": 645, "latency_ms_second": 215, "total_latency_ms": 1081, "total_latency_s": 1.081, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.900925636291504, 2.1344516277313232, 2.445939540863037, 3.657100200653076, 4.232357501983643, 3.7731590270996094], "entropies_second": [0.7606871724128723], "final_normalized_entropy": -2.43363573778391, "sequence_confidence_first": 0.2751975685322079, "sequence_confidence_second": 0.887217185697165, "sequence_confidence_final": 0.887217185697165, "token_confidences_first": [0.15121188759803772, 0.3000548481941223, 0.3874724507331848, 0.228447824716568, 0.21978986263275146, 0.27207279205322266, 0.49774274230003357], "token_confidences_second": [0.7883864045143127, 0.998437225818634], "final_mean_entropy": 0.7606871724128723, "final_min_margin": 1.632822036743164, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9977477477477478, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["11/05/97 11: 03 813 384 0683 LORILLARD TAMPA GREENSBOR 0002/ 003 Retail Excel Progress Report Submission for: Distribution by/ to: July 31 August 29 : R. W. Caldarella DM to RSM 1st of Month RSM to R W. C. 10th September 30 cc: D. O. S. October 31 X From: Kent B. Mills November 28 December 30 Area: 5 Region: 17 Acceptance/ Response: What is the retailers response to Lorillard's Excel Merchandising plan? Chains: This program has been successful to date with chains where our \"Flex Payment\". was not place. The chains where were using the \"Flex Payment\" system we have not been las successful. The P. O. S. requirements of the P- 1 Plan with Oil Companies is difficult to obtain. Independents: Additional P. V. merchandising is being secured quickly, Additional monies have assisted Region 17 in fighting PM Exclusives and PM/ RJR co-existence situations. Hardware Evaluation/ Effectiveness: Comment on the assembly of displays and application of shields: The displays are easily assembled and durable. Some questions have been raised conceming the inability to be flush with the counter and/ or against the register. As well as the ability to place this or the Back Bar if the settlement goes through Pemanent Advertising Evaluation/ Effectiveness/ Acceptance: (P- 1/ P- 5 & C 5 Plans Only: Not available at this time 82251504"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "100% yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "100% yes", "raw_answer_second": "Yes", "mean_entropy_first": 3.7892328898111978, "normalized_entropy_first": 1.5186396955298729, "min_margin_first": 0.03259754180908203, "mean_entropy_second": 1.990139126777649, "normalized_entropy_second": -0.8643491800712036, "min_margin_second": 0.6589565277099609, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 221, "latency_ms_ocr": 537, "latency_ms_second": 214, "total_latency_ms": 975, "total_latency_s": 0.975, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.747218608856201, 2.139871120452881, 2.6993894577026367, 3.9714195728302, 4.4070024490356445, 3.770496129989624], "entropies_second": [1.990139126777649], "final_normalized_entropy": -0.8643491800712036, "sequence_confidence_first": 0.22403838917990843, "sequence_confidence_second": 0.6897757853219804, "sequence_confidence_final": 0.6897757853219804, "token_confidences_first": [0.12046612799167633, 0.28097018599510193, 0.34370994567871094, 0.17598435282707214, 0.18356993794441223, 0.18616414070129395, 0.40491899847984314], "token_confidences_second": [0.4778090715408325, 0.9957756400108337], "final_mean_entropy": 1.990139126777649, "final_min_margin": 0.6589565277099609, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9977426636568849, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TO: K. A. Sparrow SUBMISSION DATE FROM: D. J. Landro MAY 12 AUG 4 SEP 15 JUN 23 SUBJECT: OLD GOLD MENTHOL LIGHTS & ULTRA LIGHTS 100'S PROGRESS REPORT GEOGRAPHY REGION: (ONLY IF PARTIAL REGION CONTINUE WITH DIVISION (S) SCOPE) DIVISION: DIVISION NAME: Milw. South DIVISION NAME: # REP 7 DIVISION NAME: Milw. North DIVISION NAME: # REP 7 DIVISION NAME: DIVISION NAME: # REPS DISTRIBUTION DIRECT ACCOUNTS AND CHAINS HEADQUARTERED WITHIN THE REGION (15 + STORES) STOCKING NO OLD GOLD MENTHOL LIGHTS OR ULTRA LIGHTS 100'S NO. OF STORES NAME OF ACCOUNT IND/LOR VOLUME NAME OF ACCOUNT IND/LOR VOLUME NO. OF TORES Walgreen Drug 144/14 93 82252956 OLOGOLD.XLS Page1 of 3 Pages"], "experiment": "entropy_routing_default", "routed": {"answer": "No", "used_ocr": true, "answer_first": "1000", "answer_second": "No", "raw_answer": "No", "raw_answer_first": "1000", "raw_answer_second": "No", "mean_entropy_first": 3.740516471862793, "normalized_entropy_first": 1.2373980423394773, "min_margin_first": 0.15954017639160156, "mean_entropy_second": 2.3183445930480957, "normalized_entropy_second": -0.552531313766038, "min_margin_second": 0.47231578826904297, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 185, "latency_ms_ocr": 390, "latency_ms_second": 142, "total_latency_ms": 719, "total_latency_s": 0.719, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.665318489074707, 2.157621145248413, 2.357947826385498, 3.883521318435669, 4.638173580169678], "entropies_second": [2.3183445930480957], "final_normalized_entropy": -0.552531313766038, "sequence_confidence_first": 0.17022508121022947, "sequence_confidence_second": 0.66739129158648, "sequence_confidence_final": 0.66739129158648, "token_confidences_first": [0.07012823224067688, 0.27187806367874146, 0.42868131399154663, 0.18898269534111023, 0.1667068898677826, 0.09448526799678802], "token_confidences_second": [0.44582900404930115, 0.999062716960907], "final_mean_entropy": 2.3183445930480957, "final_min_margin": 0.47231578826904297, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9970014992503748, "wer": 0.9911504424778761, "precision": 1.0, "recall": 0.008849557522123894, "f1": 0.017543859649122806, "rouge_l": 0.017543859649122806, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["12/ 10/ 36 09: 51 317 8450977 LORILLARD 001/ 002 COMPETITIVE PRODUCT INTRODUCTION PROGRESS REPORT TO: MRS. K. A. SPARROW MANUFACTURER R. J. Reynolds FROM: R. G. Ryan BRAND: Camel Menthol DATE: 12/ 10/ 96 TYPE OF PACKINGS: Full Flavor Box and Light Box REPORTING PERIODS: AUG SEPT OCT NOV X (Forward by the 10th of the following month.) TEST MARKET GEOGRAPHY All of Region 7. PRICE POINT: FULL $ 11.89 P/ V $ (Indicate Distributor's Cost Per Carton) SALES FORCE INVOLVEMENT: Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays. DISTRIBUTORS - ACCEPTANCE/ INTRO TERMS/ INTRO DEALS: Product is being introduced to all Direct: Accounts in the Region. Acceptance is spotty at this time. DISTRIBUTOR INVOLVEMENT: Assembly of promotional products and shipment to retail Indianapolis Direct Accounts are reported to be receiving B1G1F product. CHAINS - ACCEPTANCE/ MERCHANDISING ALLOWANCE Chain acceptance has been very good. INDEPENDENTS - ACCEPTANCE/ MERCHANDISING ALLOWANCE Acceptance is better at high volume locations than at lower volume retail calls. 82253058 CAMEL WK1/ FMT PAGE 1 OF 2"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "100% yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "100% yes", "raw_answer_second": "Yes", "mean_entropy_first": 3.6120530366897583, "normalized_entropy_first": 0.9344760748246005, "min_margin_first": 0.12297248840332031, "mean_entropy_second": 1.1477956771850586, "normalized_entropy_second": -2.109997626776605, "min_margin_second": 0.6369514465332031, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 215, "latency_ms_ocr": 482, "latency_ms_second": 203, "total_latency_ms": 902, "total_latency_s": 0.902, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.996657371520996, 2.1178154945373535, 2.5415520668029785, 3.825808525085449, 4.477410316467285, 3.7130744457244873], "entropies_second": [1.1477956771850586], "final_normalized_entropy": -2.109997626776605, "sequence_confidence_first": 0.22857275663692286, "sequence_confidence_second": 0.7815325533032748, "sequence_confidence_final": 0.7815325533032748, "token_confidences_first": [0.11518537253141403, 0.29983600974082947, 0.36774733662605286, 0.19457215070724487, 0.14840199053287506, 0.19520963728427887, 0.4553223252296448], "token_confidences_second": [0.6109477877616882, 0.9997468590736389], "final_mean_entropy": 1.1477956771850586, "final_min_margin": 0.6369514465332031, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9974937343358395, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TO: K. A. Sparrow SUBMISSION DATE R. E. Lane FROM: JUNE 30 X SEP 22 AUG 11 NOV 10 SUBJECT: STYLE LOW PRICE PROGRESS REPORT EFFECTIVENESS OF: Transition Plan (Report on June 30 only) PRE- SELL Overall pre- sell efforts were successful Retail accounts that previously stocked Style Full Price accepted the introduction of the low price BIGIF 2 FOR 1: Proved to be an excellent tool for pulling the balance of Style Full Price packs through the system. This aided the field greatly during the transition $ 7.00 CARTON COUPON/ BUYDOWN: Effective in those retail calls that we could not exchange product out of. Those situations were limited. DISTRIBUTION DIRECT ACCOUNTS AND CHAINS HEADQUARTERED WITHIN THE REGION (15+ STORES) STOCKING NO LOW PRICE STYLE NAME OF ACCOUNT IND/ LOR VOLUME NO. OF STORES NAME OF ACCOUNT IND/ LOR VOLUME NO. OF STORES M. Maskos & Sons Pollock Candy and Cigar McKeesport Candy Co. Sicc Serva 104/ 22 18 521/ 42 150 Sheetz Thrift/ Eckerd 137/ 20 183 DIRECT ACCOUNTS AND CHAINS HEADQUARTERED OUTSIDE THE REGION (15+ STORES) STOCKING NO LOW PRICE STYLE IND/ LOR VOLUME NAME OF ACCOUNT NO OF STORES NAME OF ACCOUNT IND/ LOR VOLUME NO OF STORES 21 Kroger Rich Oil 82 Super America 106 cvs 87 W H Smith 5 7- 11 318 Zon 23 Dairy Marts 35 Widman Drugs 43 82253245 STYLE XLS Page 1 of 3 Pages"], "experiment": "entropy_routing_default", "routed": {"answer": "No", "used_ocr": true, "answer_first": "1000", "answer_second": "No", "raw_answer": "No", "raw_answer_first": "1000", "raw_answer_second": "No", "mean_entropy_first": 3.712704563140869, "normalized_entropy_first": 0.975880973619614, "min_margin_first": 0.21990013122558594, "mean_entropy_second": 2.2124290466308594, "normalized_entropy_second": -0.8978029663697128, "min_margin_second": 1.0002412796020508, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 180, "latency_ms_ocr": 599, "latency_ms_second": 207, "total_latency_ms": 988, "total_latency_s": 0.988, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.317116737365723, 2.1388401985168457, 2.477908134460449, 3.989835739135742, 4.639822006225586], "entropies_second": [2.2124290466308594], "final_normalized_entropy": -0.8978029663697128, "sequence_confidence_first": 0.1962191157962275, "sequence_confidence_second": 0.7119860036051766, "sequence_confidence_final": 0.7119860036051766, "token_confidences_first": [0.11108380556106567, 0.27870506048202515, 0.40655261278152466, 0.2000698298215866, 0.1554509401321411, 0.14580102264881134], "token_confidences_second": [0.5076980590820312, 0.9984754920005798], "final_mean_entropy": 2.2124290466308594, "final_min_margin": 1.0002412796020508, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9984697781178271, "wer": 0.9957264957264957, "precision": 1.0, "recall": 0.004273504273504274, "f1": 0.00851063829787234, "rouge_l": 0.00851063829787234, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TO: K. A. Sparrow SUBMISSION DATE FROM: J. L. McGinnis MAY 19  AUG 11  JUN 30  SEP 22  SUBJECT: MAVERICK SPECIALS MENTHOL - PROGRESS REPORT GEOGRAPHY X REGION: FULL PARTIAL (ONLY IF PARTIAL REGION CONTINUE WITH DIVISION (S) SCOPE) DIVISION: PARTIAL FULL DIVISION NAME: DIVISION NAME: # REPS DIVISION NAME: DIVISION NAME: # REPS DIVISION NAME: DIVISION NAME: # REPS DISTRIBUTION DIRECT ACCOUNTS AND CHAINS HEADQUARTERED WITHIN THE REGION (15+ STORES) STOCKING NO MAVERICK SPECIALS MENTHOL NAME OF ACCOUNT IND/ LOR VOLUME NO. OF STORES NAME OF ACCOUNT IND/ LOR VOLUME NO. OF STORES Don & Bens 26/ 2 20 Sac N Pac 75/ 2 27 Western Beverage 42/ 2 15 ACO Texaco 95/ 3 15 Speedy Stop 106 /4 29 Lone Star 76/ 3 37 Get Go 62/ 2 44 Valley Shamrock 78/ 4 17 Albertson's -Houston 319/ 16 34 Mini Mart 65/ 3 15 Neal One Stop 69/ 3 20 Shopper Mart 80/ 4 22 DIRECT ACCOUNTS AND CHAINS HEADQUARTERED OUTSIDE THE REGION (15+ STORES) STOCKING NO MAVERICK SPECIALS MENTHOL NAME OF ACCOUNT IND/ LOR VOLUME NO. OF STORES NAME OF ACCOUNTS IND/ LOR VOLUME NO. OF STORES Chevron ? 115 Brookshire Bro's ? 38 Eckerd Drugs S. Texas ? 217 Exxon ? 38 Philip's 66 ? 27 Star Enterprise ? 70 Walgreen's ? 177 82253362 MAVPROGO Page 1 of 3 Pages"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "1000", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "1000", "raw_answer_second": "Yes", "mean_entropy_first": 3.696725845336914, "normalized_entropy_first": 0.8645360957233856, "min_margin_first": 0.09257888793945312, "mean_entropy_second": 3.189115285873413, "normalized_entropy_second": 0.22600629061192107, "min_margin_second": 0.11549568176269531, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 179, "latency_ms_ocr": 618, "latency_ms_second": 171, "total_latency_ms": 971, "total_latency_s": 0.971, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.469682693481445, 2.1303131580352783, 2.4204301834106445, 3.932047128677368, 4.531156063079834], "entropies_second": [3.189115285873413], "final_normalized_entropy": 0.22600629061192107, "sequence_confidence_first": 0.1906512886558604, "sequence_confidence_second": 0.5558363957439809, "sequence_confidence_final": 0.5558363957439809, "token_confidences_first": [0.10731703042984009, 0.28224366903305054, 0.4077708423137665, 0.19212467968463898, 0.1447063833475113, 0.1398487538099289], "token_confidences_second": [0.3090308904647827, 0.9997515082359314], "final_mean_entropy": 3.189115285873413, "final_min_margin": 0.11549568176269531, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9975328947368421, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TO: K. A. SPARROW DATE TO NYO: 1/24/97 FROM: S. Reindel DIV. NAME/ NO: Nassau/ 107 1997 SPECIAL EVENT REQUEST FORM NAME OF EVENT: H. Levinson Tradeshow \"DATE OF EVENT: 3/18/97 SAMPLES/ ITEMS REQUIRED: SAMPLE 10'S (400 PACKS PER CASE) # CASES NEWPORT K. S. 2 KENT III K. S. KENT GL LTS K. S. KENT III 100 NEWPORT 100's GL 100 NEWPORT LTS K. S. 1 TRUE K. S. 1 NEWPORT LTS. 100 KENT K. S. 1 KENT 100 ITEMS QUANTITY REQUIRED BASEBALL CAP 1500 500 WATER BOTTLES SHIP TO: CUSTOMER SHIPPING NUMBER 198- 1160006 NYO ONLY: DATE FORWARDED TO PROMOTION SERVICES: zbulan 82254765 PLEASE ALLOW 6 WEEKS FOR PROCESSING OF YOUR REQUEST REQFORM 01/17/97"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "1000", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "1000", "raw_answer_second": "Yes", "mean_entropy_first": 3.636458969116211, "normalized_entropy_first": 0.7140554564524485, "min_margin_first": 0.20647907257080078, "mean_entropy_second": 1.4385368824005127, "normalized_entropy_second": -2.097129371901609, "min_margin_second": 0.10853958129882812, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 176, "latency_ms_ocr": 319, "latency_ms_second": 159, "total_latency_ms": 656, "total_latency_s": 0.656, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.641967296600342, 2.0828826427459717, 2.2604169845581055, 3.802685499191284, 4.394342422485352], "entropies_second": [1.4385368824005127], "final_normalized_entropy": -2.097129371901609, "sequence_confidence_first": 0.19826985622006474, "sequence_confidence_second": 0.6770117376437204, "sequence_confidence_final": 0.6770117376437204, "token_confidences_first": [0.09355795383453369, 0.2992537319660187, 0.4432082176208496, 0.2006184607744217, 0.19890646636486053, 0.12268522381782532], "token_confidences_second": [0.4583808481693268, 0.9999215602874756], "final_mean_entropy": 1.4385368824005127, "final_min_margin": 0.10853958129882812, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9952830188679245, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["CASE FORM CASE NAME: Wanda G. Robinson and Carroll Robinson v Raybestos- Manhattan, et al. COURT: San Francisco Superior Court - No. 996378 LORILLARD ENTITIES: Lorillard Tobacco Company DATE FILED: July 23, 1998 DATE SERVED: August 3, 1998 CASE TYPE: Asbestos PLAINTIFF COUNSEL: Wartnick, Chaber, Harowitz, Smith & Tigerman Madelyn J. Chaber 101 California Street, Suite 2200 San Francisco, California 94111 415 986- 5566 LORILLARD COUNSEL: JUDGE: TRIAL DATE: 82491256 94624999"], "experiment": "entropy_routing_default", "routed": {"answer": "10 pages", "used_ocr": false, "answer_first": "10 pages", "answer_second": null, "raw_answer": "10 pages", "raw_answer_first": "10 pages", "raw_answer_second": null, "mean_entropy_first": 3.6296799182891846, "normalized_entropy_first": 0.6518611439220037, "min_margin_first": 0.03206443786621094, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 155, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 156, "total_latency_s": 0.156, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.93100643157959, 2.1136715412139893, 2.4099881649017334, 4.064053535461426], "entropies_second": null, "final_normalized_entropy": 0.6518611439220037, "sequence_confidence_first": 0.2234337828863866, "sequence_confidence_second": null, "sequence_confidence_final": 0.2234337828863866, "token_confidences_first": [0.06586666405200958, 0.27915292978286743, 0.37609270215034485, 0.15649457275867462, 0.5145672559738159], "token_confidences_second": null, "final_mean_entropy": 3.6296799182891846, "final_min_margin": 0.03206443786621094, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9853249475890985, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["CASE FORM CASE NAME: Donald D. Sellers and Robin J. Sellers v. Raybestos Manhattan et al. COURT: San Francisco Superior Court- No. 996382 LORILLARD ENTITIES Lorillard Tobacco Company DATE FILED DATE SERVED August 3, 1998 CASE TYPE: Asbestos PLAINTIEE'S COUNSEL: Wartnick Chaber, Harowitz, Smith& Tigerman StephenM. Tigerman 101 California Street Suite 2200 San Francisco California 94111 LORILLARD COUNSEL: JUDGE: TRIAL DATE: 82504862 946225115"], "experiment": "entropy_routing_default", "routed": {"answer": "10 pages", "used_ocr": false, "answer_first": "10 pages", "answer_second": null, "raw_answer": "10 pages", "raw_answer_first": "10 pages", "raw_answer_second": null, "mean_entropy_first": 3.5505192279815674, "normalized_entropy_first": 0.4982000087088503, "min_margin_first": 0.07154369354248047, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 154, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 155, "total_latency_s": 0.155, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.720981597900391, 2.134533405303955, 2.3794660568237305, 3.9670958518981934], "entropies_second": null, "final_normalized_entropy": 0.4982000087088503, "sequence_confidence_first": 0.23337858715357532, "sequence_confidence_second": null, "sequence_confidence_final": 0.23337858715357532, "token_confidences_first": [0.06737206876277924, 0.27107587456703186, 0.3800923526287079, 0.19010025262832642, 0.5246412754058838], "token_confidences_second": null, "final_mean_entropy": 3.5505192279815674, "final_min_margin": 0.07154369354248047, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9842342342342343, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["001/004 LORILLARD RGNY 11 612 894 9690 05/01/00 10:21 LORILLARD TOBACCO COMPANY Fax To: Mr. Randy Spell From: Rick Redfield Fax: Date: May 1, 2000 CC: Mr. Fred Paternostro Fax: 952 894- 9690 Re: Legal- lowa Pages: 4 Urgent For Review Please Comment Please Reply please Recycle Comments: Attached is the Iowa Department of Revenue and Finance Minimum Legal Prices on Cigarettes as of April 3, 2000. I am attempting to obtain a copy of the actual Fair Trade Law and will forward as soon as obtained. Rick CONFIDENTIALITY NOTE This facsimile may contain privileged and confidential information intended only for the use of the individual entity named above. If the mader of the facsimile is not the intended recipient or employee or delivering. It to the intended recipient you are hereby notified that any dissemination for copying of this facsimile is strictly prohibited. If you have received his facsimile in error, please notify us immediately by telephone (number indicated below) and return the original facsimile to us at the address below via the U.S Postal Service. 82562350 205 River Ridge Circle P. O. Box 7589 Bumsville, MN 5337 Telephone: (952) 694-2238"], "experiment": "entropy_routing_default", "routed": {"answer": "fax", "used_ocr": false, "answer_first": "fax", "answer_second": null, "raw_answer": "fax", "raw_answer_first": "fax", "raw_answer_second": null, "mean_entropy_first": 2.1744279712438583, "normalized_entropy_first": -1.4784912934683154, "min_margin_first": 1.4610834121704102, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 109, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 110, "total_latency_s": 0.11, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.285260200500488, 0.0635957419872284], "entropies_second": null, "final_normalized_entropy": -1.4784912934683154, "sequence_confidence_first": 0.3831515165854529, "sequence_confidence_second": null, "sequence_confidence_final": 0.3831515165854529, "token_confidences_first": [0.277845174074173, 0.9940728545188904, 0.20365288853645325], "token_confidences_second": null, "final_mean_entropy": 2.1744279712438583, "final_min_margin": 1.4610834121704102, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9974226804123711, "wer": 0.9947916666666666, "precision": 1.0, "recall": 0.005208333333333333, "f1": 0.010362694300518135, "rouge_l": 0.010362694300518135, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["COVINGTON & BURLING xc: RB5 12- 9- 99 RECEIVED DEC -9 1999 R B. SPELL 1201 Pennsylvania Avenue, N W. P. O. Box 7566 Washington D. C. 20044- 7566 (202) 662- 6000 Fax Numbers (202) 662 6291 or (202) 737 0528 Fax Operator (202) 662- 6280 THIS FACSIMILE TRANSMISSION INTENDED ONLY FOR THE ADDRESSEE SHOWN BELOW LIT MAY CONTAIN INFORMATION THAT IS PRIVILEGED CONFIDENTIAL OR OTHERWISE PROTECTED FROM DISCLOSURE ANY REVIEW DISSEMINATION OR USE OF THIS TRANSMISSION OR ITS CONTENTS BY PERSONS OTHER THAN THE ADDRESSEE IS STRICTLY PROHIBITED YOU HAVE RECEIVED THIS TRANSMISSION ERROR PLEASE NOTIFY US IMMEDIATELY AND MAIL THE ORIGINALI TO AT THE ABOVE ADDRESS Date: December 9, 1999 To: Haney H. Bell, Esq. From: David H. Remes (202) 778 5212 - direct fax Room: 803E // Pages (including cover) MESSAGE: 82573104"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 5.520476341247559, "normalized_entropy_first": 3.2462460908653696, "min_margin_first": 0.044890403747558594, "mean_entropy_second": 1.087883710861206, "normalized_entropy_second": -2.7373377615652905, "min_margin_second": 0.9624767303466797, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 86, "latency_ms_ocr": 377, "latency_ms_second": 201, "total_latency_ms": 666, "total_latency_s": 0.666, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.520476341247559], "entropies_second": [1.087883710861206], "final_normalized_entropy": -2.7373377615652905, "sequence_confidence_first": 0.11818544107206248, "sequence_confidence_second": 0.8170588234944431, "sequence_confidence_final": 0.8170588234944431, "token_confidences_first": [0.07967051863670349, 0.17531953752040863], "token_confidences_second": [0.667803168296814, 0.9996734857559204], "final_mean_entropy": 1.087883710861206, "final_min_margin": 0.9624767303466797, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9962640099626401, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["NEW COMPETITIVE PRODUCTS MRA BOBBY MILLS, REGIONAL SALES MGR., INDIANAPOLIS, IN REPORTED BY: 8/ 10/ 90 DATE: TIME: SOURCE OF INFORMATION: HALL RODECAP, NOBLESVILLE, IN B & W MANUFACTURER: VICEROY KING BOX AND VICEROY LIGHTS KING BOX BRAND NAME: TYPE OF PRODUCT: SIZE OR SIZES: LIST PRICE: EXTENT OF DISTRIBUTION: OTHER INFORMATION: SEE ATTACHED INFORMATION SHEET cc: A. H. Tisch R. H. Orcutt M. A. Peterson T. H. Mau L. Gordon J. P. Mastandrea G. Telford F. J. Schultz A. W. Spears N. P. Ruffalo T. Achey P. J. McCann A. J. Giacolo J. J. Tatulli L. H. Kersh J. R. Slater S. T. Jones R S. Goldbrenner E. R. Harrow 82837252"], "experiment": "entropy_routing_default", "routed": {"answer": "Business & Money", "used_ocr": true, "answer_first": "yes", "answer_second": "Business & Money", "raw_answer": "Business & Money", "raw_answer_first": "yes", "raw_answer_second": "Business & Money", "mean_entropy_first": 5.659204959869385, "normalized_entropy_first": 2.2866732777603564, "min_margin_first": 0.09719657897949219, "mean_entropy_second": 0.8754513193562161, "normalized_entropy_second": -2.4630776444177402, "min_margin_second": 0.0902719497680664, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 88, "latency_ms_ocr": 325, "latency_ms_second": 199, "total_latency_ms": 615, "total_latency_s": 0.615, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.659204959869385], "entropies_second": [3.307441234588623, 0.042420580983161926, 0.15050484240055084, 0.0014386194525286555], "final_normalized_entropy": -2.4630776444177402, "sequence_confidence_first": 0.1328094639139442, "sequence_confidence_second": 0.6656875582983256, "sequence_confidence_final": 0.6656875582983256, "token_confidences_first": [0.07090640813112259, 0.24875542521476746], "token_confidences_second": [0.13595306873321533, 0.9955019354820251, 0.9680506587028503, 0.9998689889907837, 0.9978836178779602], "final_mean_entropy": 0.8754513193562161, "final_min_margin": 0.0902719497680664, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9758454106280193, "wer": 0.9910714285714286, "precision": 0.3333333333333333, "recall": 0.008928571428571428, "f1": 0.017391304347826087, "rouge_l": 0.017391304347826087, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TO 3212128557HC02N P. 01 JAN 11 '99 16: 29 FR 8220 FAX TRANSMISSION DICKSTEIN SHAPIRO MORING OSHINSKY DATE: January 11, 1999 CLIENT NO.: L8557 002 MESSAGE TO: Dewey Tedder COMPANY: Lorillard Tobacco Company FAX NUMBER: 336/ 373- 6917 PHONE: 336/ 373- 6750 FROM: Andy Zausner and Rob Mangas PHONE: 202/ 828- 2259 and 202/ 828 2241 PAGES (including Cover Sheet): 2 HARD COPY TO FOLLOW YES X NO MESSAGE: The following is for your review JAN 1 2 1999 If your receipt of this transmission is in error, please notify this firm immediately by collect call to our Facsimile Department at 202- 861- 9106, and send the original transmission to us by return mail at the address below. This transmission is intended for the sole use of the individual and entity to whom it is addressed, and may contain information that is privileged, confidential and exempt from disclosure under applicable law. You are hereby notified that any dissemination, distribution or duplication of this transmission by someone other than the intended addressee or its designated agent is strictly prohibited. 83443897 2101 L Street NW Washington, DC 20037- 1526 Tel 202- 785 9700 Fax 202- 887 0689"], "experiment": "entropy_routing_default", "routed": {"answer": "tax transaction form", "used_ocr": false, "answer_first": "tax transaction form", "answer_second": null, "raw_answer": "tax transaction form", "raw_answer_first": "tax transaction form", "raw_answer_second": null, "mean_entropy_first": 3.3477434317270913, "normalized_entropy_first": -0.20246057859454164, "min_margin_first": 0.1592578887939453, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 130, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 131, "total_latency_s": 0.131, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.036699295043945, 3.4550061225891113, 2.5515248775482178], "entropies_second": null, "final_normalized_entropy": -0.20246057859454164, "sequence_confidence_first": 0.40780917087191704, "sequence_confidence_second": null, "sequence_confidence_final": 0.40780917087191704, "token_confidences_first": [0.3564770519733429, 0.28088274598121643, 0.3672485649585724, 0.7521616816520691], "token_confidences_second": null, "final_mean_entropy": 3.3477434317270913, "final_min_margin": 0.1592578887939453, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9828030954428203, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["11/ 12/ 99 19: 32 FAA 212 450 4800 DPW 1048 UUZ/ DUS DAVIS POLK & WARDWELL Sender Fax Transmittal Charles Duggan 450 Lexington Avenue New York, NY 10017 212- 450- 4000 Date Number of Pages (this page included) 6 November 12, 1999 Sender Voice Number If problems receiving this fax, call 212- 450- 4785 212- 450- 4785 Reference Sender Fax Number 212- 450- 3785 17555 002 Recipient Phone Number To Fax Number Company 617- 330- 9000 Thomas M. Sobol 617- 439- 3278 Brown Rudnick Freed & Gesmer 843- 720 9000 843- 720- 9290 Joseph F. Rice Ness, Motley, Loadholt, Richardson & Poole Robert V. Costello Jeffrey D. Woolf 617- 722- 0286 Schneider, Reilly, Zabin & Costello 617- 227- 7500 Richard M. Heimann 415- 956- 1008 Lieff, Cabraser & Heimann 415- 956- 1000 Michael P. Thornton 617- 720- 2445 Thomton, Early & Naumes 617- 720- 1333 Message: 8355333 Confidentiality Note This only for the person or entity may besi pavilegedal of otherwis protected from disclosos. Disscnlation, distribution popying of the facile the information herein by anyone other than the poupil, waployee responsible for delivering the message the prohibited. You thisfacsimile in error please notify as immediately by telephone and return the facsimile by mail."], "experiment": "entropy_routing_default", "routed": {"answer": "1099-misc form", "used_ocr": false, "answer_first": "1099-misc form", "answer_second": null, "raw_answer": "1099-misc form", "raw_answer_first": "1099-misc form", "raw_answer_second": null, "mean_entropy_first": 2.538516086008814, "normalized_entropy_first": -0.9136298035682782, "min_margin_first": 0.058605194091796875, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 269, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 270, "total_latency_s": 0.27, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [6.008432388305664, 2.084604263305664, 2.4354310035705566, 2.9707884788513184, 1.584739089012146, 3.206348419189453, 1.83078134059906, 0.11508430540561676, 2.6104354858398438], "entropies_second": null, "final_normalized_entropy": -0.9136298035682782, "sequence_confidence_first": 0.3764771645857295, "sequence_confidence_second": null, "sequence_confidence_final": 0.3764771645857295, "token_confidences_first": [0.09448705613613129, 0.3034225404262543, 0.3991435170173645, 0.2866678833961487, 0.4765018820762634, 0.2233649492263794, 0.703245997428894, 0.986078143119812, 0.3721770644187927, 0.6347610354423523], "token_confidences_second": null, "final_mean_entropy": 2.538516086008814, "final_min_margin": 0.058605194091796875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9886271324126726, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["04/ 14/ 99 18: 36 FAX 206 623 0594 HAGENS BERMAN WA Fee Pay Agree XC: JAW HAGENS BERMAN Attorney Law 1301 FIFTH AVENUE, SUITE 2900 SEATTLE, WA 98101 TELEPHONE (206) 623 7293 FACSIMILE (206) 623- 0594 FACSIMILE COVER SHEET Date: January 14, 1999 No. of Pages 37 (including this page) File No.: From: Steve W. Berman 1129. 01 Re: Tobacco - Fee Payment Agreement and Release COMMENTS: Recipient(s): Company: Phone No.: Fax No.: Mr. Meyer G. Koplow Wachtell, Lipton, Rosen & Katz (212) 403- 1000 (212) 403- 2000 Mr. Arthur F. Golden Davis, Polk & Wardwell (212) 450- 4000 (212) 450- 4800 Mr. Martin Barrington Philip Morris Inc. (917) 663- 5399 Mr. F. Anthony Burke Brown & Williamson Tobacco Corp. (502) 568- 7297 Mr. Ronald Milstein Lorillard Tobacco Co. (336) 335- 7707 Mr. Charles A. Blixt (336) 741- 2998 R. J. Reynolds Tobacco Co Mr. Stephen R. Patton Kirkland & Ellis (312) 861- 2000 (312) 861- 2200 Urgent! Deliver Immediately Please call the Support Center at (206) 268- 9312 or at ext if you do not receive all of these pages or if there is a problem. The information contained in this facsimile is confidential and may also be attorney privileged. The information is intended only for the use of the individual or entity to whom it is addressed. If you are not the intended recipient, or the employee or agent responsible for delivering it to the intented recipient, you are hereby notified any use, dissemination, distribution or copying of this communication is strictly prohibited. If you have received this facsimile in error, please immcdiately notify us by a collect call to (206) 623- 7292, and return the original message to us at the address above via the US Postal Service. Thank you. 83573282 A PROFESSIONAL SERVICE CORPORATION"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.7500921726226806, "normalized_entropy_first": 0.261917588265571, "min_margin_first": 0.39963245391845703, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 179, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 180, "total_latency_s": 0.18, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.744218349456787, 2.0954816341400146, 2.537569522857666, 3.8847708702087402, 4.488420486450195], "entropies_second": null, "final_normalized_entropy": 0.261917588265571, "sequence_confidence_first": 0.1580942654929728, "sequence_confidence_second": null, "sequence_confidence_final": 0.1580942654929728, "token_confidences_first": [0.08590663224458694, 0.28599146008491516, 0.3511103093624115, 0.13663390278816223, 0.13142944872379303, 0.10079110413789749], "token_confidences_second": null, "final_mean_entropy": 3.7500921726226806, "final_min_margin": 0.39963245391845703, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9977077363896848, "wer": 0.9966555183946488, "precision": 1.0, "recall": 0.0033444816053511705, "f1": 0.006666666666666666, "rouge_l": 0.006666666666666666, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["ROPER STARCH WORLDWIDE 89/ 22/ 97 MON 15: 35 FAX 12124554900 001 ROPER STARCH TURNING DATA INTO INTELLIGENCE WORLDWIDE Fax Fax Fax Fax Fax Fax Fax Fax Fax Date: September 22, 1997 To: Ron Milstein From: \"JJ\" Klein Company: Lorillard Fax Number: (910) 335 7707 Pages (Including cover page): 3 83594639 Roper Starch Worldwide nc 205 East 42nd Street New York NY 0017 212 599 0700 212 887 7008 Fax Roper Marketing and Public Option Research Search Advertising and Media Research Frederen Marketing Services INRA World Headquarters"], "experiment": "entropy_routing_default", "routed": {"answer": "No", "used_ocr": true, "answer_first": "1000", "answer_second": "No", "raw_answer": "No", "raw_answer_first": "1000", "raw_answer_second": "No", "mean_entropy_first": 4.034442806243897, "normalized_entropy_first": 0.517499553586654, "min_margin_first": 0.3366279602050781, "mean_entropy_second": 1.7809364795684814, "normalized_entropy_second": -1.6212514028566922, "min_margin_second": 0.5164871215820312, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 177, "latency_ms_ocr": 294, "latency_ms_second": 136, "total_latency_ms": 608, "total_latency_s": 0.608, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [6.494104385375977, 2.1274237632751465, 2.60349178314209, 4.006180763244629, 4.941013336181641], "entropies_second": [1.7809364795684814], "final_normalized_entropy": -1.6212514028566922, "sequence_confidence_first": 0.1577297804025149, "sequence_confidence_second": 0.7173421168838633, "sequence_confidence_final": 0.7173421168838633, "token_confidences_first": [0.05324118584394455, 0.3052186667919159, 0.37031182646751404, 0.20067116618156433, 0.14551328122615814, 0.08763310313224792], "token_confidences_second": [0.5151873230934143, 0.9988206028938293], "final_mean_entropy": 1.7809364795684814, "final_min_margin": 0.5164871215820312, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9962121212121212, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["FEB 25 '98 18: 23 FR TO #1 28557 002# P. 2101 FAX TRANSMISSION DATE: February 25, 1998 CLIENT NO.: L8557 002 MESSAGE TO: Ronald S. Milstein COMPANY: Lorillard Tobacco Company FAX NUMBER: 910/ 335- 7707 PHONE: 910 /335 -7718 FROM: Andy Zausner PHONE: 202 /828 -2259 PAGES (including Cover Sheet): 12 HARD COPY TO FOLLOW: YES NO MESSAGE: See attached fax from the Committee on Commerce just received in my office. Call me discuss. If your receipt of this transmission is in error, please notify this firm immediately by collect call to our Facsimile Department at 202- 861 -9106 and send the original transmission to us by return mail at the address below. This transmission is intended for the sole use of the individual and entity to whom it is addressed, and may contain information that is privileged, confidential and exempt from disclosure under applicable law. You are hereby notified that any dissemination, distribution duplication of this transmission by somcong other than the intended addressee or its designated agent is strictly prohibited. 83624198 2101 L. Street NW Washington DC 20037 1528 Tel 202 785 9700 Fax 202 -887 -0589"], "experiment": "entropy_routing_default", "routed": {"answer": "tax transaction form", "used_ocr": false, "answer_first": "tax transaction form", "answer_second": null, "raw_answer": "tax transaction form", "raw_answer_first": "tax transaction form", "raw_answer_second": null, "mean_entropy_first": 3.5196659564971924, "normalized_entropy_first": -0.023731608172300318, "min_margin_first": 0.13080978393554688, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 134, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 135, "total_latency_s": 0.135, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.596501350402832, 3.4755656719207764, 2.4869308471679688], "entropies_second": null, "final_normalized_entropy": -0.023731608172300318, "sequence_confidence_first": 0.3777865540599876, "sequence_confidence_second": null, "sequence_confidence_final": 0.3777865540599876, "token_confidences_first": [0.24495358765125275, 0.2879267930984497, 0.37038654088974, 0.7797670960426331], "token_confidences_second": null, "final_mean_entropy": 3.5196659564971924, "final_min_margin": 0.13080978393554688, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9824561403508771, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["JUN 05 97 02:00 PM LOEWS CORP P. 1/ 6 LOEWS CORPORATION 667 Madison Avenue, New York, N. / 10021 8087 (212) 545 2920 Fax (212) 935 6801 BARRY HIRSCH Senior Vice President Secretary & General Counsel FAX CONFIDENTIAL DATE: June 4, 1997 TO: Dr. Spears/ A. J. Stevens/ R. Milstein FROM: Barry Hirsch TOTAL NUMBER OF PAGES INCLUDING THIS COVER SHEET- 6 IF YOU DO NOT RECEIVE ALL THE PAGES, PLEASE CALL CAROL DOKTORSKI AT (212) 545- 2934. OUR FAX NUMBER (212) 935 6801 THIS TRANSMISSION IS INTENDED ONLY FOR THE USE OF THIS INDIVIDUAL OR ENTITY TO FROM IT IS ADDRESSED. AND MAY CONTAIN INFORMATION THAT IS PRIVILEGED CONFIDENTIAL AND You YOU ARE THAT MY DIRAYDOTIG DISAISONICAR OF THIS COMKONICATION TA ATRICTLY PROHIBITED HAVE RECEIVED TINCOFMONTTIOS PYTHOND ROU ORIGDOL YILSON ATITE ABOVE ADDR359 VIA POSTAL SERVICE THANK YOU. 83635935"], "experiment": "entropy_routing_default", "routed": {"answer": "Business & Money", "used_ocr": true, "answer_first": "letter", "answer_second": "Business & Money", "raw_answer": "Business & Money", "raw_answer_first": "letter", "raw_answer_second": "Business & Money", "mean_entropy_first": 5.56243896484375, "normalized_entropy_first": 2.1033141757233977, "min_margin_first": 0.15961456298828125, "mean_entropy_second": 0.882352593660471, "normalized_entropy_second": -2.7670534260217687, "min_margin_second": 0.6365852355957031, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 85, "latency_ms_ocr": 595, "latency_ms_second": 233, "total_latency_ms": 915, "total_latency_s": 0.915, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.56243896484375], "entropies_second": [3.361396312713623, 0.001223745639435947, 0.16650384664535522, 0.0002864696434698999], "final_normalized_entropy": -2.7670534260217687, "sequence_confidence_first": 0.2080089784355326, "sequence_confidence_second": 0.7088921394534243, "sequence_confidence_final": 0.7088921394534243, "token_confidences_first": [0.1029457226395607, 0.4202965795993805], "token_confidences_second": [0.18466874957084656, 0.9998956918716431, 0.9695751667022705, 0.99997878074646, 0.9999549388885498], "final_mean_entropy": 0.882352593660471, "final_min_margin": 0.6365852355957031, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9819711538461539, "wer": 0.9929078014184397, "precision": 0.3333333333333333, "recall": 0.0070921985815602835, "f1": 0.013888888888888888, "rouge_l": 0.013888888888888888, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TO: S. P. ZOLOT SUBMISSION DATE FROM: R. W. RICHARDSON OCT 05 DEC 21 X NOV 16 SUBJECT: OLD GOLD- LIGHT BOX 100'S PROGRESS REPORT GEOGRAPHY REGION: PARTIAL FULL X (ONLY IF PARTIAL REGION, CONTINUE WITH DIVISION(S) SCOPE) DIVISION: FULL X PARTIAL DIVISION NAME: Detroit North DIVISION NAME: Detroit South # REPS: 13 DIVISION NAME: Detroit East DIVISION NAME: Detroit West # REPS: 12 DIVISION NAME: Grand Rapids DIVISION NAME: Flint # REPS: 13 DISTRIBUTION Direct Accounts and Chains Headquartered within the Region (15+ Stores) Stocking No Old Gold Light Box 100's Name of Account Ind/Lor Volume Number of Stores Name of Account Ind/Lor Volume Number of Stores Quality Dairy 151/15 31 Speedy Q 196/13 16 Bay Stations 81/9 1818 Schmuckal Dil 138/9 22 Wilson Oil 140/13 15 Quik Stop 117/9 24 Forwards 118/8 19 Phil Flint 166/15 15 Arbor Rx 209 115/13 Imperial Oil 163/11 32 Direct Accounts and Chains Headquartered Outside the Region. (15+ Stores) Stocking No Old Gold Light Box 100's Name of Account Ind/Lor Volume Number of Stores Name of Account Ind/Lor Volume Number of Stores Clark Gas 142 Emra 237 7- Eleven Southland 102 Walmart 39 Ultra Diamond 184 Dairy Mart 32 Mobil Oil 40 ACA Amoco 31 83641919 Page 1 of 3 GOD"], "experiment": "entropy_routing_default", "routed": {"answer": "100% correct", "used_ocr": false, "answer_first": "100% correct", "answer_second": null, "raw_answer": "100% correct", "raw_answer_first": "100% correct", "raw_answer_second": null, "mean_entropy_first": 3.725877285003662, "normalized_entropy_first": -0.01601695947036821, "min_margin_first": 0.14777183532714844, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 210, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 211, "total_latency_s": 0.211, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.392293930053711, 2.1268417835235596, 2.3783624172210693, 3.9535980224609375, 4.444486618041992, 4.059680938720703], "entropies_second": null, "final_normalized_entropy": -0.01601695947036821, "sequence_confidence_first": 0.2400373150589034, "sequence_confidence_second": null, "sequence_confidence_final": 0.2400373150589034, "token_confidences_first": [0.10624251514673233, 0.2866145074367523, 0.41216012835502625, 0.21794502437114716, 0.16274037957191467, 0.22656093537807465, 0.45526212453842163], "token_confidences_second": null, "final_mean_entropy": 3.725877285003662, "final_min_margin": 0.14777183532714844, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9909613804437141, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["NO. 1796 P. 1/ 3 JAN 31. 1997 11: 48 AM LAW OFFICES SHOOK HARDY & BACON L. L. P. FAX COVER FAX COVER One Kansas City Place 1200 Main Street Kansas City Missouri 64105- 2118 Telephone (816) 474 6550 Facsimile (816) 421- 5547 TO: JACK REILLY TELECOPY NO: 212/ 545- 3297 FROM: JIM DALEY #: 392 DATE: JANUARY 31, 1997 TIME: SHB Client Matter No: LORI 45048 Pages transmitted including cover sheet: ORIGINAL DOCUMENT WILL FOLLOW VIA FEDERAL EXPRESS Special Instructions: If you experience any problems, please call extension 21000 OPERATOR: COMMENTS/ MESSAGE: Jack Per your request, attached is a memo regarding the process of labeling reviewed diskettes for the purpose of later identification Please call me if you have any questions regret I cannot join you and the electronic document collection team for lunch today. I hope you agree they have done an outstanding job! I look forward to seeing you on February 5 for the Legal Edge presentation. Best Regards, Jim Daley CONFIDENTIALITY NOTICE The documents accompanying this transmission contain confidential information belonging to the sender 83772145 Legally privileged The information is intented only for the Individual or entity named above pol pre intended recipen you heret notified that copying distribuar dhe crion Islance content or lecoled normation och If you have received this telecopy in error, please immediately notify us by telephone to arrange for return of the origin documents to us."], "experiment": "entropy_routing_default", "routed": {"answer": "john bryant", "used_ocr": false, "answer_first": "john bryant", "answer_second": null, "raw_answer": "john bryant", "raw_answer_first": "john bryant", "raw_answer_second": null, "mean_entropy_first": 3.930737257003784, "normalized_entropy_first": 0.18203613438446303, "min_margin_first": 0.3428459167480469, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 185, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 186, "total_latency_s": 0.186, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.775001525878906, 2.0629384517669678, 5.244625091552734, 5.266150951385498, 1.3049702644348145], "entropies_second": null, "final_normalized_entropy": 0.18203613438446303, "sequence_confidence_first": 0.21085274159641132, "sequence_confidence_second": null, "sequence_confidence_final": 0.21085274159641132, "token_confidences_first": [0.09082171320915222, 0.6335117816925049, 0.08576112985610962, 0.11381877958774567, 0.5610550045967102, 0.2788825035095215], "token_confidences_second": null, "final_mean_entropy": 3.930737257003784, "final_min_margin": 0.3428459167480469, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9924346629986245, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["001 /97 TUE 18: 39 FAX 212 5578 DPW 30 -59 DAVIS POLK & WARDWELL Fax Transmittal To Date 450 Lexington Avenue New York NY 10017 212- 450 4000 Robert H. Shaw, Esq. November 11, 1997 Company Lorillard Tobacco Company Fax Number Voice Number 910 -335- 7077 910 -335- 7720 Sender Number of Pages (this page included) 2 Charles Duggan Sender Voice Number Main Fax Operator Voice Number 212 -450- 4785 Sender Fax Number Reference 212 -450 -5578 17560 -188 Message: Confidentiality Note: This facsimile intended only the person or entity to which it is addressed and may contain information that is privileged, confidential 83823750 or otherwise protected from disclosure distribution or copying of this facsimile or the information herein by anyone other than the intended recipient, or an employee or agent responsible for delivering the message to the intended recipient is prohibited. If you love received the facsimile in error, please notify us immediately by telephone and return the facsimile by mail."], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.708376407623291, "normalized_entropy_first": -0.05287806411872073, "min_margin_first": 0.06017780303955078, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 185, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 187, "total_latency_s": 0.187, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.752229690551758, 2.125274181365967, 2.5949206352233887, 3.6727705001831055, 4.396687030792236], "entropies_second": null, "final_normalized_entropy": -0.05287806411872073, "sequence_confidence_first": 0.17228462997302918, "sequence_confidence_second": null, "sequence_confidence_final": 0.17228462997302918, "token_confidences_first": [0.12055499106645584, 0.29749080538749695, 0.36834874749183655, 0.1378224641084671, 0.15210716426372528, 0.0944259986281395], "token_confidences_second": null, "final_mean_entropy": 3.708376407623291, "final_min_margin": 0.06017780303955078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9960079840319361, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["COUPON CODE REGISTRATION FORM TO: KELLI SCRUGGS FROM: LEONARD JONES CC: V. LOSITO M. TAHMASEB G. BAROODY L. STEVENS B. VON DER LIPPE D. Risling BRAND(S) APPLICABLE OLD GOLD MEDIA TYPE DIRECT MAIL MEDIA NAME ISSUE FREQUENCY YEAR SPACE/ COLOR COUPON ISSUE DATE 10/ 4/ 99 COUPON EXPIRATION DATE 3/ 31/ 00 CIRCULATION(#) 201, 500 CIRCULATION DATES OCTOBER 1999 GEOGRAPHICAL AREA(S) DISCOUNT SMOKERS OG GROUPS IANDII COUPON VALUE $1 00 OFF PACK PACK/CARTON PACK ADVERTISING CREATIVE TITLE SIGNATURE OF INITIATOR DATE INITIATED 4/ 14/ 99 REQUIREMENTS REDEMPTION RESULTS 30165 CODE ASSIGNED 07809 JOB# 594 EST. REDEMPTION 14% 83996357"], "experiment": "entropy_routing_default", "routed": {"answer": "Coupon Code Registration Form", "used_ocr": true, "answer_first": "yes", "answer_second": "Coupon Code Registration Form", "raw_answer": "Coupon Code Registration Form", "raw_answer_first": "yes", "raw_answer_second": "Coupon Code Registration Form", "mean_entropy_first": 5.914134502410889, "normalized_entropy_first": 2.3051860816209992, "min_margin_first": 0.020320892333984375, "mean_entropy_second": 1.583189606666565, "normalized_entropy_second": -2.319465820500648, "min_margin_second": 0.7171106338500977, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 87, "latency_ms_ocr": 324, "latency_ms_second": 280, "total_latency_ms": 694, "total_latency_s": 0.694, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.914134502410889], "entropies_second": [5.417502403259277, 0.08503733575344086, 2.6133008003234863, 1.0310134887695312, 0.059357061982154846, 0.292926549911499], "final_normalized_entropy": -2.319465820500648, "sequence_confidence_first": 0.12066689949847346, "sequence_confidence_second": 0.6224164038677078, "sequence_confidence_final": 0.6224164038677078, "token_confidences_first": [0.05298871174454689, 0.27478495240211487], "token_confidences_second": [0.1390453428030014, 0.9916125535964966, 0.5066545009613037, 0.8520424365997314, 0.9938166737556458, 0.9626939296722412, 0.6354788541793823], "final_mean_entropy": 1.583189606666565, "final_min_margin": 0.7171106338500977, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9537480063795853, "wer": 0.9591836734693877, "precision": 1.0, "recall": 0.04081632653061224, "f1": 0.07843137254901959, "rouge_l": 0.07843137254901959, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Marden - Kane, Inc. TRUE \"YOU FOUND IT\" SWEEPSTAKES SECOND PRIZE WINNER TRAVEL INFORMATION SHEET THE DESTINATION IN THE CONTINENTAL UNITED STATES I WISH TO TRAVEL TO IS: NAME ADDRESS CITY STATE ZIP HOME PHONE BUSINESS PHONE NAME OF GUEST AGE RELATIONSHIP TO WINNER PLEASE LIST THREE ALTERNATIVE DATES YOU WOULD LIKE TO TRAVEL 1. 2. 3. MAJOR AIRPORT NEAREST YOUR HOME AIRLINE: (CHECK ONE) SMOKING NON- SMOKING SPECIAL DIETARY REQUIREMENTS 85201976 ANY ADDITIONAL INFORMATION YOU WOULD LIKE TO PROVIDE"], "experiment": "entropy_routing_default", "routed": {"answer": "application form", "used_ocr": false, "answer_first": "application form", "answer_second": null, "raw_answer": "application form", "raw_answer_first": "application form", "raw_answer_second": null, "mean_entropy_first": 3.7224212884902954, "normalized_entropy_first": -0.22630438112799164, "min_margin_first": 0.5380430221557617, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 112, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 113, "total_latency_s": 0.113, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.48954963684082, 1.9552929401397705], "entropies_second": null, "final_normalized_entropy": -0.22630438112799164, "sequence_confidence_first": 0.3016473753951395, "sequence_confidence_second": null, "sequence_confidence_final": 0.3016473753951395, "token_confidences_first": [0.12006533890962601, 0.48815444111824036, 0.4682995676994324], "token_confidences_second": null, "final_mean_entropy": 3.7224212884902954, "final_min_margin": 0.5380430221557617, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9679358717434869, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["SHERATON- CARLTON HOTEL WASHINGTON, D. C. THE TOBACCO INSTITUTE FIFTH ANNUAL COLLEGE TOBACCO KNOWLEDGE REGISTRATION FORM FEBRUARY 19-21 1980 NAME: GEORGE R. TELFORD TITLE: Brand Manager COMPANY: Lorillard ADDRESS: 666 Fifth Avenue, New York, NY 10019 PHONE: (212) 841- 8787 CHECK ONE: Please reserve a room for me at the Sheraton- Carlton X I will my own housing arrangements. ARRIVAL DATE AND TIME: 2/18/80 7:00 P. M. DEPARTURE DATE AND TIME: 2/21/80 4:00 P. M. Please attach a brief (50 words or so) autobiographical sketch. Note your first name or nickname, your current professional re- sponsibilities, employment background and whatever personal in- formation you feel would be helpful in giving your fellow students an idea of your activities and interests. The sketches will be assembled and provided at the opening class session. Any questions? Call Connie Drath or Carol Musgrave at 800/424- 9876. **PLEASE RETURN IN SELF- ADDRESSED ENVELOPE BY FRIDAY, JANUARY 18, 1980**"], "experiment": "entropy_routing_default", "routed": {"answer": "Form", "used_ocr": true, "answer_first": "yes", "answer_second": "Form", "raw_answer": "Form", "raw_answer_first": "yes", "raw_answer_second": "Form", "mean_entropy_first": 5.436234474182129, "normalized_entropy_first": 1.4248054985864653, "min_margin_first": 0.15558433532714844, "mean_entropy_second": 5.607664108276367, "normalized_entropy_second": 1.5887466067225788, "min_margin_second": 0.19009685516357422, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 89, "latency_ms_ocr": 618, "latency_ms_second": 204, "total_latency_ms": 912, "total_latency_s": 0.912, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.436234474182129], "entropies_second": [5.607664108276367], "final_normalized_entropy": 1.5887466067225788, "sequence_confidence_first": 0.17983884580605075, "sequence_confidence_second": 0.25221699082534904, "sequence_confidence_final": 0.25221699082534904, "token_confidences_first": [0.08769185841083527, 0.36881428956985474], "token_confidences_second": [0.07727201282978058, 0.8232399821281433], "final_mean_entropy": 5.607664108276367, "final_min_margin": 0.19009685516357422, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9959183673469387, "wer": 0.9935064935064936, "precision": 1.0, "recall": 0.006493506493506494, "f1": 0.012903225806451613, "rouge_l": 0.012903225806451613, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["MEDIA CONTACT SHEET (Publication or station) (Location address) (Name) (Position) (Date) (Phone number) Reason for Contact Questions/ Responses Additional Comments 85540866 Inquiry handled by: (Name)"], "experiment": "entropy_routing_default", "routed": {"answer": "media contact sheet", "used_ocr": false, "answer_first": "media contact sheet", "answer_second": null, "raw_answer": "media contact sheet", "raw_answer_first": "media contact sheet", "raw_answer_second": null, "mean_entropy_first": 1.508745700120926, "normalized_entropy_first": -2.37724613633953, "min_margin_first": 0.15312767028808594, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 137, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 138, "total_latency_s": 0.138, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [2.810770034790039, 1.242799162864685, 0.4726679027080536], "entropies_second": null, "final_normalized_entropy": -2.37724613633953, "sequence_confidence_first": 0.6192248592268021, "sequence_confidence_second": null, "sequence_confidence_final": 0.6192248592268021, "token_confidences_first": [0.5485926866531372, 0.4795650839805603, 0.9090146422386169, 0.6147875785827637], "token_confidences_second": null, "final_mean_entropy": 1.508745700120926, "final_min_margin": 0.15312767028808594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9045226130653267, "wer": 0.88, "precision": 1.0, "recall": 0.12, "f1": 0.21428571428571425, "rouge_l": 0.21428571428571425, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["CIGARETTE REPORT FORM YEAR: NO. PER PACK BRAND NAME: VAR. DESC: (SEE EXPLANATION) VARIETY UNIT SALES: VARIETY DOLLAR SALES: CIG. LENGTH: FILTER LENGTH: FILTER TYPE: FLAVORING: OVERWRAP: PACK TYPE: IST MANUFACT. DATE: IST SALES DATE: LAST SOLD DATE: YEARLY SUMMARY: TAR: NICOTINE: CARBON MONO: ADVERTISING EXPENDITURES (SEE EXPLANATION) CAT- A- EXPENSES: CAT- B- EXPENSES: CAT- C- EXPENSES: CAT- D- EXPENSES: CAT- E- EXPENSES: CAT- F- EXPENSES: CAT- G- EXPENSES: CAT- H- EXPENSES: CAT- I- EXPENSES: CAT- J- EXPENSES: CAT- K- EXPENSES: CAT- L- EXPENSES: CAT- M- EXPENSES: CAT- N- EXPENSES: TOTAL ADVERTISING EXPENDITURES: 85629964"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.7036128997802735, "normalized_entropy_first": -0.10304072725166727, "min_margin_first": 0.20595550537109375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 184, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 185, "total_latency_s": 0.185, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.560135841369629, 2.0918383598327637, 2.2962594032287598, 3.863828659057617, 4.706002235412598], "entropies_second": null, "final_normalized_entropy": -0.10304072725166727, "sequence_confidence_first": 0.19208651352873451, "sequence_confidence_second": null, "sequence_confidence_final": 0.19208651352873451, "token_confidences_first": [0.0823715478181839, 0.3155031204223633, 0.4222968518733978, 0.2328641265630722, 0.15732687711715698, 0.12493295222520828], "token_confidences_second": null, "final_mean_entropy": 3.7036128997802735, "final_min_margin": 0.20595550537109375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["From: Lynnette Stevens To: Kelli Scruggs CC: Vincent Losito George Baroody Don Kisling S. Tesh C. Hill Brand(s) Applicable Newport Parent, Lights. & 120's Media Type Direct Mail Media Name Competitive 21- 34 years Issue Frequency/ Year *Space/ Color Coupon Issue Date 4/ 14/ 00 Coupon Expiration Date 9 /30 00 Circulation(#) APPROX 600. 000 AR. AZ.A K CA CO FL ID IA. CT, ME, MASS, MN, MT, NE, Geographical Area(s) Tiers II, & IV Coupon Value NV, NM, NY ND, DK, OR, RL, SD, WA, DC, WY $1. 50 OFF PACK Pack and/ or Carton? Advertising Creative Title. Signature of Initiator Date Initiated 21- Jan 00 Analytical Requirements FOR CONTROL USE ONLY Code Assigned 05787 Job Number Est. Redemption 13% * Where Applicable 86075409"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "james e floyd", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "james e floyd", "raw_answer_second": "Yes", "mean_entropy_first": 5.147576141357422, "normalized_entropy_first": 1.0803241514988655, "min_margin_first": 0.020952224731445312, "mean_entropy_second": 1.0641145706176758, "normalized_entropy_second": -2.2510772078217745, "min_margin_second": 0.7172603607177734, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 176, "latency_ms_ocr": 377, "latency_ms_second": 163, "total_latency_ms": 719, "total_latency_s": 0.719, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.433712959289551, 3.602079391479492, 5.5282745361328125, 5.926000595092773, 5.2478132247924805], "entropies_second": [1.0641145706176758], "final_normalized_entropy": -2.2510772078217745, "sequence_confidence_first": 0.11110516122026945, "sequence_confidence_second": 0.7981331857713744, "sequence_confidence_final": 0.7981331857713744, "token_confidences_first": [0.09294948726892471, 0.22643209993839264, 0.040398288518190384, 0.0608995221555233, 0.0844607949256897, 0.43011876940727234], "token_confidences_second": [0.6370432376861572, 0.9999581575393677], "final_mean_entropy": 1.0641145706176758, "final_min_margin": 0.7172603607177734, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9958448753462604, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["CREATIVE INPUT DOCUMENT SPECIFICS Date/ Time: 10/30/98 1:46 PM Client Name: Matter Number: Prepared By: Milestone Presentation Date: Project Title: Est. Production Budget: Estimated Creative Budget: Media: Concept: Execution: OBJECTIVE Why are we advertising? What do we plan to achieve?  Retention  Acquisition  Loyalty  Relationship-Building  Cross-Sell  Up-Sell  Lead Generation  Competitive Blocking  New Product/Package Intro.  Awareness  Trial  Direct Sale  Other  Change Image Perception TARGET To whom are we talking? Who is the primary target? Is there a secondary target? What is their relationship to the brand what do they currently think about it? COMMUNICATION PLATFORM What is the single most important message/idea we are trying to communicate? What is the unique selling position that will help us achieve our advertising goal? Are there any secondary messages? What is the key benefit to the target? What's in it for the reader? Is there an offer/call to action? What are we offering the target to persuade him/her to act now? (A premium, sweepstakes, limited-time offer, free information, or something else? What would we like our target to think? What would our target say after being exposed to our program? 1 of 2 c:\\my documents\\wp\\sample cid. doc 86079776 10/30/98 01:46 PM"], "experiment": "entropy_routing_default", "routed": {"answer": "creative inpt document", "used_ocr": false, "answer_first": "creative inpt document", "answer_second": null, "raw_answer": "creative inpt document", "raw_answer_first": "creative inpt document", "raw_answer_second": null, "mean_entropy_first": 2.5784849241375922, "normalized_entropy_first": -1.1208238490922064, "min_margin_first": 0.1269359588623047, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 185, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 186, "total_latency_s": 0.186, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.0628252029418945, 0.06224987655878067, 3.644186496734619, 3.454676866531372, 0.6684861779212952], "entropies_second": null, "final_normalized_entropy": -1.1208238490922064, "sequence_confidence_first": 0.3975432159938243, "sequence_confidence_second": null, "sequence_confidence_final": 0.3975432159938243, "token_confidences_first": [0.15317633748054504, 0.993736743927002, 0.2660430073738098, 0.1807023584842682, 0.9133259057998657, 0.5906111001968384], "token_confidences_second": null, "final_mean_entropy": 2.5784849241375922, "final_min_margin": 0.1269359588623047, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9832189168573608, "wer": 0.9904761904761905, "precision": 0.6666666666666666, "recall": 0.009523809523809525, "f1": 0.018779342723004695, "rouge_l": 0.018779342723004695, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["LORILLARD TOBACCO COMPANY Market Planning and Information Department To: Mike Mozina Firm: MSA FAX #: Autodial From: Susan Smith FAX #: 335- 7733 Phone #: 335- 7150 Date: 8/ 31/ 98 # Pages: 3 (including this cover page) Mike, As promised, here are: - Approval for AWS Quarterly Store Count Database to begin 3rd Quarter 1998 - Table showing significant jump in Convenience Store market importance in 2nd Quarter 1998 Talk to you soon! 8622042"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.9334410667419433, "normalized_entropy_first": 0.09328748275511942, "min_margin_first": 0.24154090881347656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 177, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 177, "total_latency_s": 0.177, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [6.066822528839111, 2.101855516433716, 2.739496946334839, 4.120450019836426, 4.638580322265625], "entropies_second": null, "final_normalized_entropy": 0.09328748275511942, "sequence_confidence_first": 0.15139986496585822, "sequence_confidence_second": null, "sequence_confidence_final": 0.15139986496585822, "token_confidences_first": [0.07600834220647812, 0.3009750545024872, 0.32223448157310486, 0.15072530508041382, 0.13358443975448608, 0.08114226162433624], "token_confidences_second": null, "final_mean_entropy": 3.9334410667419433, "final_min_margin": 0.24154090881347656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9932126696832579, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["12/12/96 08:33 204 7348616 LORILLARD TOB NYO 1 0001/ 004 SUBMISSION DATE TO: K. A. Sparrow FEB 24 DEC 13 X FROM: F. Strickland APR 4 JAN 25 SUBJECT: MAVERICK SPECIALS- PROGRESS REPORT GEOGRAPHY PARTIAL FULL x REGION: (ONLY IF PARTIAL REGION CONTINUE WITH DIVISION(S) SCOPE) PARTIAL DIVISION: FULL DIVISION NAME: # REPS DIVISION: # REPS DIVISION NAME: DIVISION NAME: DIVISION NAME: # REPS DIVISION NAME: DISTRIBUTION DIRECT ACCOUNTS AND CHAINS HEADQUARTERED WITHIN THE REGION (15+ STORES) STOCKING NO MAVERICK SPECIALS NO OF STORES NO. OF STORES NAME OF ACCOUNT NAME OF ACCOUNT Seyle 20 180 K&B 19 Dantzlen 130 Delchamps 18 85 Southeast Foods Winn Dixie 18 39 Compac Foods Schwegmann 17 Bayou Foods Aurry Greer 36 36 Econ 16 Double 23 Litco Huber Oil 23 22 Morris Corp 86230203 Page 1 of 4 MAVPROG 11-Dec-96"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.6245928764343263, "normalized_entropy_first": -0.1746400519030543, "min_margin_first": 0.09933853149414062, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 181, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 182, "total_latency_s": 0.182, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.367217540740967, 2.0758612155914307, 2.2622604370117188, 3.9342992305755615, 4.483325958251953], "entropies_second": null, "final_normalized_entropy": -0.1746400519030543, "sequence_confidence_first": 0.18955585254253007, "sequence_confidence_second": null, "sequence_confidence_final": 0.18955585254253007, "token_confidences_first": [0.10157134383916855, 0.2865322530269623, 0.4331185817718506, 0.1820416897535324, 0.16676412522792816, 0.12122666835784912], "token_confidences_second": null, "final_mean_entropy": 3.6245928764343263, "final_min_margin": 0.09933853149414062, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9950372208436724, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TO: Mrs. K. A. Sparrow SUBMISSION DATE: R. G. Ryan JUNE7  FROM: AUG.2 OCT.7 NEWPORT LIGHTS HEAVY UP PROGRESS REPORT EFFECTIVENESS OF DISTRIBUTION ALLOWANCE: DIRECT ACCOUNT/ WHOLESALERS: Distribution allowance was very effective in accomplishing our objectives. All accounts have purchased introductory products. DIRECT ACCOUNT CHAINS: Eagle Foods is the only Void. NON- DIRECT ACCOUNT CHAINS: Reception from these accounts is most positive with a solid incentitive to purchase. EFFECTIVENESS OF THE RETAIL (1 00 OFF CARTON) DISTRIBUTION ALLOWANCE: Has been most helpful in acquiring desireable distribution when needed by Sales Reps. PROMOTIONAL ACTIVITY 40c OFF PACK- GENERAL MARKET: The 40c off promotions continue to be well received at the retail stores and by consumers, as well. 8623474"], "experiment": "entropy_routing_default", "routed": {"answer": "100% correct", "used_ocr": false, "answer_first": "100% correct", "answer_second": null, "raw_answer": "100% correct", "raw_answer_first": "100% correct", "raw_answer_second": null, "mean_entropy_first": 3.775994062423706, "normalized_entropy_first": -0.029680480832705726, "min_margin_first": 0.11571216583251953, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 206, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 207, "total_latency_s": 0.207, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.987760066986084, 2.1582555770874023, 2.567808151245117, 3.8904666900634766, 4.188570976257324, 3.863102912902832], "entropies_second": null, "final_normalized_entropy": -0.029680480832705726, "sequence_confidence_first": 0.22477402424423448, "sequence_confidence_second": null, "sequence_confidence_final": 0.22477402424423448, "token_confidences_first": [0.06801365315914154, 0.28187865018844604, 0.38555192947387695, 0.2662595808506012, 0.23764757812023163, 0.17031356692314148, 0.36390984058380127], "token_confidences_second": null, "final_mean_entropy": 3.775994062423706, "final_min_margin": 0.11571216583251953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9861286254728878, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["DIVISION: DATES: ACCOUNT: INVENTORY FOR: (STATE) DIRECT ACCOUNT STATUS REPORT BRAND # OF CARTONS ON HAND AVERAGE WEEKLY MOVEMENT # OF WEEKS ON HAND STYLE LIGHT 100'S STYLE LIGHT MENTHOL 100'S STYLE LIGHT BOX 100'S STYLE MEN. LIGHT BOX 100'S STYLE SLIM LIGHT 100's STYLE SLIM MEN. LT. 100's NOTE: REPORT STYLE INVENTORY ONLY. SUBMIT REPORT ONLY IF STYLE IS STILL ON HAND IN THIS ACCOUNT. CC: REGIONAL SALES MANAGER, ALL DIVISIONS SERVICED BY THIS ACCOUNT. ACTION PLAN: 8624113 STYLEREP"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 5.187657356262207, "normalized_entropy_first": 1.3059397479401742, "min_margin_first": 0.28201866149902344, "mean_entropy_second": 1.3642492294311523, "normalized_entropy_second": -2.3073815504205157, "min_margin_second": 0.1099090576171875, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 88, "latency_ms_ocr": 244, "latency_ms_second": 136, "total_latency_ms": 470, "total_latency_s": 0.47, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.187657356262207], "entropies_second": [1.3642492294311523], "final_normalized_entropy": -2.3073815504205157, "sequence_confidence_first": 0.2212665390060284, "sequence_confidence_second": 0.686169021959981, "sequence_confidence_final": 0.686169021959981, "token_confidences_first": [0.08896933495998383, 0.5502893924713135], "token_confidences_second": [0.47088366746902466, 0.9998816251754761], "final_mean_entropy": 1.3642492294311523, "final_min_margin": 0.1099090576171875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.993801652892562, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["RECORDS RETENTION SCHEDULE RECONCILIATION RECORDS MANAGEMENT DEPARTMENT - M /C DEPARTMENT NAME SCIENCE & TECHNOLOGY 141 COST CENTER NUMBER INDEX BINDERS CONSOLIDATED BY: N /A DATE INDEX BINDER RE- LABELED BY: Mallery 2 /15 /90 DATE RETENTION & RECOMMENDATION FILE REORGANIZED AND RE- LABELED BY: N /A DATE RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY: Wayne Boughan DATE 4 /18 /90 BOXES CREATED FOR HARD COPY PERMANENT RETENTION RECORDS BY: N /A DATE RECORDS TRANSFER INVENTORY FORMS UPDATED BY: Wayne Baughan DATE 7 /25 /90 2051119008"], "experiment": "entropy_routing_default", "routed": {"answer": "No", "used_ocr": true, "answer_first": "yes", "answer_second": "No", "raw_answer": "No", "raw_answer_first": "yes", "raw_answer_second": "No", "mean_entropy_first": 5.619142532348633, "normalized_entropy_first": 1.5424053226460326, "min_margin_first": 0.09253501892089844, "mean_entropy_second": 1.7015483379364014, "normalized_entropy_second": -2.0647058412618406, "min_margin_second": 0.06911182403564453, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 85, "latency_ms_ocr": 371, "latency_ms_second": 124, "total_latency_ms": 583, "total_latency_s": 0.583, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.619142532348633], "entropies_second": [1.7015483379364014], "final_normalized_entropy": -2.0647058412618406, "sequence_confidence_first": 0.1583597952659564, "sequence_confidence_second": 0.6254103826216252, "sequence_confidence_final": 0.6254103826216252, "token_confidences_first": [0.07753980904817581, 0.3234187066555023], "token_confidences_second": [0.3912912607192993, 0.9996086955070496], "final_mean_entropy": 1.7015483379364014, "final_min_margin": 0.06911182403564453, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9963963963963964, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Feb-24-99 10:53 From- UNTON WILL 1426 T-122 P.01/04 F-066 TELECOPY INFORMATION HUNTON & WILLIAMS Riverfront Plaza 951 East Byrd Street Richmond, Virginia 23219 -4074 (804)788-8200 2nd Floor Telecopier Telecopier Nos. (804) 788- 8218 (804) 788- 8219 (804) 788- 8669 TO: Name: Ken Forrest FAX NO: 212- 403- 2211 Name: Tom Frederick FAX NO: 312- 558- 5700 Name: Tom Griffin FAX NO.: 617- 523- 1231 Name: Ever Hurwitz FAX NO.: 202- 342- 5999 Name: Barry Levin/ Curl Caton FAX NOc.: 415- 772- 6268 Name: Barbara Robbins FAX NOv 212- 403- 2033 Name: Greg Stone/Ron Olson FAX NOv 213- 687- 3702 Name: Bill Allinder/Jeff Nelson FAX NOv 816- 421- 2708 Name: Steve Krigbaum FAX NOv 917- 663- 5593 Name: Tom Stoever FAX NOv 303- 832- 0428 Name: Judy Bernstein- Gaeta FAX NOv 202- 942- 5999 Name: Dal Burton FAX NOv 404- 581- 8330 Name: Andy McGaan FAX NOv 312- 861- 2200 Name: James Wilson FAX NOv 336- 335- 7707 Name: Eric Sarner/ Doug Flemming/ Peter Mckenna FAX NOv 212- 735- 2000 Name: Thomas McKim FAX NOv 336- 741- 0671 Name: D. Scott Wise FAX NO.: 212- 450- 4800 4 Pages (Including Cover) Original to follow in mail: Yes  No 86328049"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.972324752807617, "normalized_entropy_first": -0.12139757543994825, "min_margin_first": 0.6758480072021484, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 180, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 181, "total_latency_s": 0.181, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [6.347310543060303, 2.0885190963745117, 2.348978042602539, 4.244525909423828, 4.832290172576904], "entropies_second": null, "final_normalized_entropy": -0.12139757543994825, "sequence_confidence_first": 0.17176100525527854, "sequence_confidence_second": null, "sequence_confidence_final": 0.17176100525527854, "token_confidences_first": [0.0943378433585167, 0.3039233088493347, 0.3720691204071045, 0.20063824951648712, 0.17205244302749634, 0.06972672790288925], "token_confidences_second": null, "final_mean_entropy": 3.972324752807617, "final_min_margin": 0.6758480072021484, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9964601769911504, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["DECISION TREE ESTIMATION OF TOXIC RISK DATE August 14, 1990 J. D. Ergle and R. F. Dufresne COMPOUND NAME Vanitrope STRUCTURE CH3CH2O OH LORILLARO COMPOUND CODE NUMBER ESTIMATED TOXICITY CLASS B134 III COMMENTS This ethoxy substitued aromatic falls into class III. J. D. Engle Research Chemist R. F. Dufresne Research Chemist 87086073 FORM LORILLARD RESEARCH CENTER"], "experiment": "entropy_routing_default", "routed": {"answer": "100 mg", "used_ocr": false, "answer_first": "100 mg", "answer_second": null, "raw_answer": "100 mg", "raw_answer_first": "100 mg", "raw_answer_second": null, "mean_entropy_first": 3.031323621670405, "normalized_entropy_first": -0.9797023366556628, "min_margin_first": 0.08824634552001953, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 207, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 208, "total_latency_s": 0.208, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.882699012756348, 2.092139720916748, 2.652332305908203, 3.773552656173706, 3.2310984134674072, 0.5561196208000183], "entropies_second": null, "final_normalized_entropy": -0.9797023366556628, "sequence_confidence_first": 0.25406275823839486, "sequence_confidence_second": null, "sequence_confidence_final": 0.25406275823839486, "token_confidences_first": [0.0834825336933136, 0.2978667616844177, 0.2884707748889923, 0.16629815101623535, 0.2997976839542389, 0.8919960260391235, 0.2141849547624588], "token_confidences_second": null, "final_mean_entropy": 3.031323621670405, "final_min_margin": 0.08824634552001953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9862637362637363, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Date: 3/14/90 90- B- 1 Sample No. 1194- 90 Type of Cigarette 100 mm Filter Batch Size 47.5 lbs. Original Request Made By J. H. Bell on 2/15/90 Purpose of Sample Cigarette Modification B- 451 Sample Specifications Written By C. W. Lassiter BLEND CASTING RECASING FINAL FLAVOR MENIHOL Attached None Attached None None Cigarettes Filters Maker MK 8 Section A Section B Length 99.0 mm 27 mm mm Filter Length 27 mm Kind 3.3/ 35,000 Circumference 24.8 mm OG Lt. Weight 78.0 g / 100 Rod Length 108 mm 81- 01- 07 Paper Pressure Drop 400 mm 25- 04- 07 Tip. Paper Circumference 24.45 mm 67 mm White Weight 75.3 30g / 100 Tip. Paper Por. 430 Plast. 7 % Kent Glue Roller G 84- 52- 28 Plug Wrap Air Dilution 13.0 % Plug Wrap Por. 655 Comb. Wrap Comb. Wrap Por. Wrapping Responsibility Labels White Tobacco Blend Lassiter/ Douglas Closures Filter Production MFG. Blue Tear Tape White Making & Packing James Cartons White Shipping Markings Sample No. on each Carton Sample Requistion (Form 02: 20: 06) James Requirements Laboratory Analysis: Laboratory Other 1 Tray Mainstream Smoke Analysis Special Requirements 87093315 Director, Product Development"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.660360860824585, "normalized_entropy_first": -0.30584375906089706, "min_margin_first": 0.2382984161376953, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 173, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 173, "total_latency_s": 0.173, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.67280912399292, 1.9920318126678467, 2.3963680267333984, 3.8662095069885254, 4.374385833740234], "entropies_second": null, "final_normalized_entropy": -0.30584375906089706, "sequence_confidence_first": 0.19734663927927223, "sequence_confidence_second": null, "sequence_confidence_final": 0.19734663927927223, "token_confidences_first": [0.0954880490899086, 0.32949209213256836, 0.34606364369392395, 0.1944969743490219, 0.20145834982395172, 0.1384619027376175], "token_confidences_second": null, "final_mean_entropy": 3.660360860824585, "final_min_margin": 0.2382984161376953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9964788732394366, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["FINAL REPORT AMENDMENT STUDY NAME Induction of Hepatic Enzymes in rats (B202) STUDY NUMBER I- 7016. 401 October 27, 1986 DATE OF FINAL REPORT February 26, 1987 INITIATION DATE PART OF FINAL REPORT TO BE AMENDED (EXACT LOCATION) Page 14 and Table 4 REASON FOR THE AMENDMENT Request from sponsor AMENDMENT (Attach additional sheets as necessary) see attached APPROVALS 8/ 7/ 87 STUDY DIRECTOR DATE 87125460 08/ 14/ 87 DATE QUALITY ASSURANCE"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document", "used_ocr": false, "answer_first": "yes this is a document", "answer_second": null, "raw_answer": "yes this is a document", "raw_answer_first": "yes this is a document", "raw_answer_second": null, "mean_entropy_first": 3.8653459787368774, "normalized_entropy_first": -0.08982964402001607, "min_margin_first": 0.3731832504272461, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 176, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 177, "total_latency_s": 0.177, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.827215194702148, 4.933193683624268, 1.5711904764175415, 2.2381839752197266, 4.756946563720703], "entropies_second": null, "final_normalized_entropy": -0.08982964402001607, "sequence_confidence_first": 0.22893760292988738, "sequence_confidence_second": null, "sequence_confidence_final": 0.22893760292988738, "token_confidences_first": [0.07142575085163116, 0.182947039604187, 0.7096049189567566, 0.6581947803497314, 0.13272085785865784, 0.17775112390518188], "token_confidences_second": null, "final_mean_entropy": 3.8653459787368774, "final_min_margin": 0.3731832504272461, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.952054794520548, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["TEST ARTICLE RECEIPT TA #: T07281A Lorillard SPONSOR'S NAME: B220 TEST ARTICLE IDENTIFICATION: 012590 CONDITION OF SHIPMENT: GOOD BROKEN LEAKED LOT #: SHIPPED VIA Direct Exress Clear brown liquid PHYSICAL DESCRIPTION: NO. OF CONTAINERS: One 100 g Not provided GROSS WEIGHT NET WEIGHT (if provided): Not provided EXPIRATION DATE: Store refrigerated in dark. SPECIAL HANDLING REQUIREMENTS: 03 /01 /90 DATES: RECEIVED BY: Ray David STUDY DIRECTOR /DEPARTMENT SIGATURE OF DEPARTMENT CONSIGNEE: DATE: 03 /02 /90 87137840"], "experiment": "entropy_routing_default", "routed": {"answer": "Christianity", "used_ocr": true, "answer_first": "yes", "answer_second": "Christianity", "raw_answer": "Christianity", "raw_answer_first": "yes", "raw_answer_second": "Christianity", "mean_entropy_first": 5.011066436767578, "normalized_entropy_first": 1.0866080210065805, "min_margin_first": 0.11343002319335938, "mean_entropy_second": 2.98457932472229, "normalized_entropy_second": -0.9859957215983416, "min_margin_second": 0.00704193115234375, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 86, "latency_ms_ocr": 311, "latency_ms_second": 159, "total_latency_ms": 558, "total_latency_s": 0.558, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.011066436767578], "entropies_second": [3.553241729736328, 2.415916919708252], "final_normalized_entropy": -0.9859957215983416, "sequence_confidence_first": 0.19644745800202518, "sequence_confidence_second": 0.40229507785040186, "sequence_confidence_final": 0.40229507785040186, "token_confidences_first": [0.10353313386440277, 0.37274640798568726], "token_confidences_second": [0.15200980007648468, 0.4293607473373413, 0.9975627660751343], "final_mean_entropy": 2.98457932472229, "final_min_margin": 0.00704193115234375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9766990291262136, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["DATE  PURCHASING P. O. 1534 LT-1979 PURCHASE REQUISITION  STATIONARY April 19, 1988 PLEASE INCLUDE ONLY ONE TYPE OF MATERIAL ON THIS REQUISITION VENDOR FOR PURCHASING DEPARTMENT USE ONLY ORDER NO Piedmont Research Laboratory 2748 Patterson Ave., Greensboro, NC 27407 NET 15 F. O. B. N/A VIA N/A Prev. or Recommended Supplier TERMS SHIP TO (DEPT BRANCH) DATE WANTED Lorillard Research Center N. A. Thaggard As required 420 English St., Greensboro, NC 27405 QUANTITY CODE DESCRIPTION UNIT PRICE This is your authorization to prepare cigarette smoke condensate according to the protocol \"Standard Operating Procedure fr the Preparation of Smoke Condensate for Mouse Skin Bioassay,\" for the period April 1, 1988 through December 31, 1988. Condensate will be prepared acording to a time schedule provided by Lorillard. The fixed price for condensate collection will be at a rate of $1, 750/10, 000 cigarettes smoked. Piedmont will pay the cost of consumable supplies. This work is to be conducted in accordance with the December 10, 1984 formal agreement between Piedmont Reseach Laboratories and Lorillard. All work is to be coordinated with our Mr. Neil Thaggard (919) 373-6628 FOLLOW UP DATE REQUISITION NO. ISSUED BY BUDGET NO. ACCT. NO. DEPT. NO. APPROVED BY 4111 8700 87147607"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 5.4424052238464355, "normalized_entropy_first": 1.4146777268062396, "min_margin_first": 0.33385658264160156, "mean_entropy_second": 1.33210027217865, "normalized_entropy_second": -2.776059154352178, "min_margin_second": 1.5572195053100586, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 87, "latency_ms_ocr": 846, "latency_ms_second": 203, "total_latency_ms": 1138, "total_latency_s": 1.138, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.4424052238464355], "entropies_second": [1.33210027217865], "final_normalized_entropy": -2.776059154352178, "sequence_confidence_first": 0.17046010956628246, "sequence_confidence_second": 0.8505544951364175, "sequence_confidence_final": 0.8505544951364175, "token_confidences_first": [0.10789177566766739, 0.26931291818618774], "token_confidences_second": [0.7237222194671631, 0.9996141195297241], "final_mean_entropy": 1.33210027217865, "final_min_margin": 1.5572195053100586, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.99765625, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["47th TCRC REGISTRATION FORM Please type or print Name: Title First Middle Last Institution: Address: Street P.O. Box# State ZIP Code Country City Telephone: FAX #: Name of guest: Continental Breakfast on Tuesday Breakfast on Wednesday Fall Foliage Tour on Tuesday Craftsman Village Tour Wednesday $135 00 Advance Registration Fee: (prior to September 1) $150 00 Late Registration Fee after September Extra banquet tickets tickets $40. 00 $ 30. 00 Ground Transportation (round trip) TOTAL Please complete this portion if you need transportation from and to the Knoxville Airport. No. in Party: DATE TIME CARRIER FLIGHT # Arrival: Departure: Send this registration form, along with payment to the address noted below. Enclose a check or international money order payable in U. S. funds to the University of Tennessee - 47th TCRC Mail to: Telephone: 87332450 Dr. Phil P. Hunter U. T. Tobacco Experiment Station Route 5 Box 113 Greeneville, TN 37743 (615) ) 638- 5532 FAX: (615) ) 638- 6458"], "experiment": "entropy_routing_default", "routed": {"answer": "4tcc registration form", "used_ocr": false, "answer_first": "4tcc registration form", "answer_second": null, "raw_answer": "4tcc registration form", "raw_answer_first": "4tcc registration form", "raw_answer_second": null, "mean_entropy_first": 2.5298793241381645, "normalized_entropy_first": -1.6321850910392373, "min_margin_first": 0.0972280502319336, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 196, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 197, "total_latency_s": 0.197, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.046921730041504, 1.5077446699142456, 3.5058975219726562, 4.49650764465332, 1.4068857431411743, 0.21531863510608673], "entropies_second": null, "final_normalized_entropy": -1.6321850910392373, "sequence_confidence_first": 0.39381938616399226, "sequence_confidence_second": null, "sequence_confidence_final": 0.39381938616399226, "token_confidences_first": [0.21956132352352142, 0.6024494767189026, 0.10936291515827179, 0.1857505440711975, 0.8321394324302673, 0.9753521680831909, 0.6736672520637512], "token_confidences_second": null, "final_mean_entropy": 2.5298793241381645, "final_min_margin": 0.0972280502319336, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9776876267748479, "wer": 0.9875, "precision": 0.6666666666666666, "recall": 0.0125, "f1": 0.0245398773006135, "rouge_l": 0.0245398773006135, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["COMPOUND PHYSICAL PARAMETERS LOT NUMBER LRC FILE NUMBER A221 PHYSICAL STATE A crystalline solid at room temperature which melts at > 56 C. pH The pH of a 50 % concentration of A221 in water was theoretically calculated to be 7.26 at 22 C from a 0.5 % solution in 79.5 % aqueous dioxane according to the extrapolation procedures of Dr. P. D. Schickedantz, Lozillard Accession Number 1662. Referenced 45- 10- 1. SPECIFIC GRAVITY Not Determined. SOLUBILITY MUTAGENICITY SOLVENTS A221 is soluble EtOH at 0.2 g/ ml, with stirring, at room temperature. Reference BC30- 88. A221 forms a solution in corn oil at 0.5 g/ 0.5 mL, with stirring at room temperature. Reference BC30- 8888. ORAL A221 forms a solution in corn oil at 0.5 g/ 0.5 mL, with stirring at room temperature. Reference BC30- 88. ACUTE CARDIOVASCULAR A221 is insoluble for this procedure. Reference BC30- 38 STORAGE RECOMMENDATIONS Refrigerate in an amber glass bottle at no more than 8 C. 87428306 COMPOUND SENSITIVE TO  MOISTURE  OTHER  AIR  HEAT SAFETY COMMENTS (SUGGESTED HANDLING PROCEDURE: DATE SIGNATURE A - 13 FORM RESEARCH CENTER LORILLARD"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.8234477043151855, "normalized_entropy_first": -0.18728215796122483, "min_margin_first": 0.03234577178955078, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 176, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 177, "total_latency_s": 0.177, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.794550895690918, 2.0872795581817627, 2.4944260120391846, 4.1156206130981445, 4.625361442565918], "entropies_second": null, "final_normalized_entropy": -0.18728215796122483, "sequence_confidence_first": 0.15871701782530429, "sequence_confidence_second": null, "sequence_confidence_final": 0.15871701782530429, "token_confidences_first": [0.0772760808467865, 0.28939732909202576, 0.36305609345436096, 0.16761451959609985, 0.1588689535856247, 0.07393957674503326], "token_confidences_second": null, "final_mean_entropy": 3.8234477043151855, "final_min_margin": 0.03234577178955078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9963963963963964, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["REQUEST FOR CHANGE RJRT F- 1001 7/ 88 RFC 880029 ORIGINATOR Name: Dan Straka Date Prepared Page Date 8-17-88 1 of 1 B-17-88 Received By D. Marsh Telephone No Position 5398 Change Order Number Department Name and Location 8410059 611- 13 3rd Floor Brand/ Assembly/ Affected Material Glass Glass Mat and Slit Mat Type of Change Emergency Design Spec Change Addition Urgent Deletion Compatibity Cost Reduction Other Routine X X Change Manufacturability X Description of Problem The current specifications for glass mat and slit glass mat can be made more accurate and complete with the following changes: Glass Mat: Delete C- glass from Iten description. Change glass softening point to 756 + / - 10 degrees from 750. Change rolls per pallet to 2 from 1. slit Glass Mat: Delete C- glass from item description Change bobbins per stack to 47 from 45. Add outside diameter specs of 30.0, 26.0 - 31.0 inches. Proposed Solution Change the current MSS specifications as outlined above. 51484 3791 Title Date Signature Accepted for Investigation DATE Final Disposition Approved Rejected SPEC HOLDER 8-17-88 Action Taken or Reason for Rejection PRODUCT REVIEW COMMITTEE KA PRODUCT ACCEPTANCE COMMITTEE Proposed Effective Date 9/8/88 habanisy Dhes"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": false, "answer_first": "1000", "answer_second": null, "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": null, "mean_entropy_first": 3.740383243560791, "normalized_entropy_first": -0.2576776363005846, "min_margin_first": 0.22786903381347656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 178, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 179, "total_latency_s": 0.179, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.782538414001465, 2.035384178161621, 2.510362148284912, 3.934345245361328, 4.439286231994629], "entropies_second": null, "final_normalized_entropy": -0.2576776363005846, "sequence_confidence_first": 0.1608191017858336, "sequence_confidence_second": null, "sequence_confidence_final": 0.1608191017858336, "token_confidences_first": [0.0845431536436081, 0.344837486743927, 0.2732319235801697, 0.15210090577602386, 0.13764461874961853, 0.1037314385175705], "token_confidences_second": null, "final_mean_entropy": 3.740383243560791, "final_min_margin": 0.22786903381347656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9967611336032388, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["S 10675 STOUT INDUSTRIES, INC. 6425 W. FLORISSANT AVE. ST. LOUIS MO 63136 . (314) 385- 2280 PROPOSAL Metal \"Pack\" Plaque TO Lorillard Corporation FOR 666 Fifth Avenue October 16, 1987 ADDRESS DATE CITY New York New York 10103 STATE Mr. A. D. Steinberg YOUR REPRESENTATIVE Attn: Mr. Robert Kennedy It is our pleasure to propose the following: ITEM: Harley Davidson Metal Plaque SIZE: 171/4 x 231/2 \" .025\" STEEL   OTHER  GAUGE MATERIAL: ALUMINUM COLORS: Transparent gold, opaque black, white and orange Aluminum BASE COLOR SINGLE FACE  DOUBLE FACE  HOLES: YES  NO  NUMBER OF 4 CORNERS: ROUND  SQUARE  ANGLE  CUT TO SHAPE  EDGES: HEMMED  CURLED  EMBOSSED  BEADED BORDER  STAMP FRAME  RIGHT ANGLE BEND  BACK FRAME  PACKING: PER CARTON 10 PER CRATE PER BUNDLE OTHER: Price is based on reproduction of customer supplied \"Pack\" box. Tooling: Form die, brass emboss die to achieve detail on eagle. QUANTITIES: @ $ 3,015.00 500 Plaques One time tooling Steel tips $ 1,045.00 PRICE: $ 9.18 each 4050 BILLING:  BILL AS MANUFACTURE  BILL AS SHIP FOR.  6 MOS.  12 MOS WAREHOUSING:   12 MOS. WHSE SHIP IMMEDIATELY  6 MOS. WHSE. DROP SHIPPING: PER SHIPMENT TOTAL 8650 CONDITIONS: PRICES QUOTED HEREIN ARE BASED ON CURRENT COSTS AND ARE FOR IMMEDIATE ACCEPTANCE *These prices will be updated periodically from date of order, to reflect changes in material and labor costs. Prices and terms quoted herein are not subject to verbal changes unless confirmed in writing by the home office of this company in S. T. LOUIS M. O. All contracts for delivers are contingent upon fires, strikes or other causes beyond our control. Purchaser agrees to accept overun or underrun to the extent of 10% of the quantity ordered. Any taxes or governmental changes which the seller may be required to pay or collect upon the production sale storage, or delivery under any existing or future law shall be for the account of the buyer who shall promptly pay the amount hereof to the seller upon F. O. B. S. T. LOUIS MISSOURI Shipments via truck shipped freight collect. 87528380 A 15 service charge will be added to reight costs for all prepaid shipments involving 5 or more pieces. TERMS - NET 10 DAYS A service charge of 11/2 per month will be applied to all unpaid balances over 30 days. STOUT INDUSTRIES INC,"], "experiment": "entropy_routing_default", "routed": {"answer": "stout industries inc", "used_ocr": false, "answer_first": "stout industries inc", "answer_second": null, "raw_answer": "stout industries inc", "raw_answer_first": "stout industries inc", "raw_answer_second": null, "mean_entropy_first": 1.7444212049245835, "normalized_entropy_first": -2.271264027911778, "min_margin_first": 0.3627138137817383, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 176, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 177, "total_latency_s": 0.177, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.027412414550781, 1.3513798713684082, 1.2716436386108398, 0.03181461989879608, 1.0398554801940918], "entropies_second": null, "final_normalized_entropy": -2.271264027911778, "sequence_confidence_first": 0.5812727582148108, "sequence_confidence_second": null, "sequence_confidence_final": 0.5812727582148108, "token_confidences_first": [0.11845345050096512, 0.7903821468353271, 0.7975171208381653, 0.9964908957481384, 0.8404672741889954, 0.6168233752250671], "token_confidences_second": null, "final_mean_entropy": 1.7444212049245835, "final_min_margin": 0.3627138137817383, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9913081269013473, "wer": 0.9951338199513382, "precision": 0.6666666666666666, "recall": 0.004866180048661801, "f1": 0.009661835748792272, "rouge_l": 0.009661835748792272, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["CENTER FOR INDOOR AIR RESEARCH 1099 WINTERSON ROAD SUITE 280 LINTHICUM, MD. 21090 (410) 684-3777 FAX (410) 684-3729 APPLICATION FOR RESEARCH CONTRACT 1. PRINCIPAL INVESTIGATOR NAME, TITLE, TELEPHONE # AND MAILING ADDRESS. Steven R. Kleeberger, Ph. D. Associate Professor (A) NAME (410) 955-3515/955-0299 (a) TITLE (c) TELEPHONE Environmental Health Sciences Johns Hopkins University, School of Hyg. & Pub. Hlth. (D) DEPARTMENT (E) INSTITUTION 615 North Wolfe Street, Baltimore, Maryland 21205 (F) MAILING (G) STATE/ZIP 2. PROJECT TITLE Mechanisms of Chronic Ozone Exposure: Role of Inflammation 3. KEY WORDS PLEASE PROVIDE THREE (3) KEY WORDS WHICH WILL BE USED AS REFERENCE HEADINGS Ozone, Inflammation, Mast Cell 4. INSTITUTION NAME AND ADDRESS OF INSTITUTION RESPONSIBLE AND ACCOUNTABLE FOR OF AWARDED ON THE OF DISPOSITION FUNDS BASIS THIS APPLICATION. Johns Hopkins University 615 North Wolfe Street (A) INSTITUTION (a) STREET ADDRESS Baltimore Maryland 21205 (C) City (D) STATE/ZIP 5. LOCATION LIST LOCATION WHERE RESEARCH WILL BE CONDUCTED IF OTHER THAN INSTITUTION IDENTIFIED IN #4 ABOVE. (A) (B) 6. INCLUSIVE DATES AND TOTAL COSTS OF THIS SPECIFIC PROJECT RELATED TO EACH 12 MONTH PERIOD IF MORE THAN ONE YEAR IS REQUIRED TO COMPLETE PROJECT. SUMMARIZE FROM BUDGET PAGE ITEM 12(s). IT MUST BE UNDERSTOOD THAT AWARDS FOR 2ND AND 3RD PERIODS ARE DEPENDENT ON CENTER APPROVAL OF CONTINUATION APPLICATION. INCLUSIVE DATE TOTAL COST 01/01/94 12/31/94 (A) 1ST 12 MONTH PERIOD 210, 910 THRU $ 01/01/95 12/31/95 THRU $ 212, 481 (B) 2ND 12 MONTH PERIOD IF REQUIRED 01/01/96 220, 416 (C) 3RD 12 MONTH PERIOD IF REQUIRED THRU 12/31/96 $ 7. INSTITUTIONAL OFFICER. NAME, TITLE AND TELEPHONE NUMBER OF INDIVIDUAL AUTHORIZED TO SIGN FOR THE INSTITUTION IDENTIFIED IN #4 ABOVE. IT IS UNDERSTOOD THAT THE OFFICER, IN APPLYING FOR A CONTACT. HAS READ AND FOUND ACCEPTABLE THE CENTER'S MANAGEMENT OF RESEARCH CONTRACTS AND CONTRACT ADMINISTRATION POLICY. Alan M. Goldberg, Ph. D. Assoc. Dean for Research (A) NAME (B) TITLE (410) 955-9253 (C) TELEPHONE (D) SIGNATURE OF (E) DATE 5/26/93 8. PRELIMINARY STUDIES* QUALIFICATIONS OF INVESTIGATOR 9. EXPERIMENTAL PLAN* (A) METHODS DATA INTERPRETATION RESULTS INVESTIGATION LITERATURE CITED 10. AVAILABLE FACILITIES AND RESOURCES 11. OTHER SUPPORT 87594142 * APPEND AS MUCH MATERIAL AS REQUIRED TYPE, SINGLE SPACE USE 8-1/2 x 11\" WHITE PAPER AND LABEL EACH SHEET WITH NAME THE PRINCIPAL NVESTIGATOR IN THE UPPER RIGHT HAND CORNER AND PAGE NUMBER AT THE BOTTOM. CONSECUTIVELY NUMBER EACH ADDENDUM BEGINNING WITH PAGES 5. DO NOT INSERT PACES BETWEEN PAGES 1 AND 6 E.G. 2A 2B 3A ETC. INCLUDE NINE COPIES AND AN ORIGINAL If SENDING PHOTOGRAPHS, INCLUDE 2 ORIGINAL SETS. NOTE: EACH OF THE NINE COPIES MUST BE PLACED IN BINDER PER MAILING INSTRUCTIONS."], "experiment": "entropy_routing_default", "routed": {"answer": "application for medical contract", "used_ocr": false, "answer_first": "application for medical contract", "answer_second": null, "raw_answer": "application for medical contract", "raw_answer_first": "application for medical contract", "raw_answer_second": null, "mean_entropy_first": 3.3901087641716003, "normalized_entropy_first": -0.318786714085975, "min_margin_first": 1.159332275390625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 155, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 156, "total_latency_s": 0.156, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.633461952209473, 1.251887559890747, 4.374153137207031, 3.3009324073791504], "entropies_second": null, "final_normalized_entropy": -0.318786714085975, "sequence_confidence_first": 0.4014274280617753, "sequence_confidence_second": null, "sequence_confidence_final": 0.4014274280617753, "token_confidences_first": [0.2910321354866028, 0.76991206407547, 0.23309879004955292, 0.37924724817276, 0.5262482762336731], "token_confidences_second": null, "final_mean_entropy": 3.3901087641716003, "final_min_margin": 1.159332275390625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9884892086330935, "wer": 0.9931350114416476, "precision": 0.75, "recall": 0.006864988558352402, "f1": 0.013605442176870748, "rouge_l": 0.013605442176870748, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Date October 17, 1979 MARKETING RESEARCH RPROJECT APPROVAL file (To be filled out by Marketing Research Department) PROJECT TITLE Triumph Disaster Check Study PRODUCT Triumph 5546/ 1979 Research Design (N, Cells, Elegibility, Design, Key Danner Breaks, Methodololy, Cities) Contact respondents from Buffalo and Kansas City who had previously participated in a steak knife offer This will consist of one cell of approximately 175 respondents who are Triumph most often smokers /triers This study is intended to provide us with any negatives associated with Triumph Banner points will include Triumph most often smokers (we anticipate approximately 25 most of ten people Switchers away from Triumph (N approximately 45). It should be noted that an action standard of at least 50% be obtained in acting upon any product negatives associated with these groups see research limitations below for additional action standard. (See attached memo Key Criteria for Analysis -Triumph switchers asked why no longer smoking Triumph -Present smokers of Triumph asked reasons for switching to Triumph -Mentions of \"harshness\" Research Limitations Due to sample size and experience we feel 25 respondents will presently be Triumph smokers. An action standard of 75% should be utilized for judgments on product negatives only among this group If 75% of Triumph smokers mention harshness we could consider it a 50- 75% problem If of Triumph smokers mention \"harshness\" we could it a look consider possible problem at other areas). If below 50% of Triumph smokers mention \"harshness\" we could consider it at a problem $ 2.250 Research Firm The Data Group. Inc Cost Estimate + - 10% Contingency Final Report Inc. yes no Incidence yes no - Scott R. Benson Prepared by: Lenght Int 10 minutes Approved # Open by: 4 # Reports 1 Marketing Director Research Topline 2 wks from start of fid. Product Manager Final 4 wks from start of fld Group Product Manager 89856243"], "experiment": "entropy_routing_default", "routed": {"answer": "1960s", "used_ocr": false, "answer_first": "1960s", "answer_second": null, "raw_answer": "1960s", "raw_answer_first": "1960s", "raw_answer_second": null, "mean_entropy_first": 2.914682070414225, "normalized_entropy_first": -0.7345621477392594, "min_margin_first": 0.044777870178222656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 194, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 195, "total_latency_s": 0.195, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.744485855102539, 2.016963481903076, 2.362149238586426, 2.0793938636779785, 2.144765853881836, 3.140334129333496], "entropies_second": null, "final_normalized_entropy": -0.7345621477392594, "sequence_confidence_first": 0.27320865673424627, "sequence_confidence_second": null, "sequence_confidence_final": 0.27320865673424627, "token_confidences_first": [0.07980789989233017, 0.36051300168037415, 0.30160996317863464, 0.23866437375545502, 0.22207406163215637, 0.36863255500793457, 0.6701462268829346], "token_confidences_second": null, "final_mean_entropy": 2.914682070414225, "final_min_margin": 0.044777870178222656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9974240082431737, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["\"CORRECTED FORM\" The Commonwealth of Massachusetts OFFICE OF CAMPAIGN AND POLITICAL FINANCE Office Use Only REPORT OF CORPORATE TREASURER Form CPF 22 (formerly CPF 10) File with: Director, Office of Campaign & Political Finance One Ashburton Place, Boston, MA 02108 (CHECK ONE)  60th Day Prior to Election  5th Day of the Month  20th Day of the Month Please Print or Type, except Signatures.  Final M. Alfred Peterson; Assistant Treasurer Peter J. Marzullo 1. Name of Treasurer Lorillard Tobacco Company 2. Name of Corporation 3. Address of Corporation One Park Avenue New York. NY 10016 -5895 1 relating to Tobacco Excise Tax Increase 4. Question No. (Describe question briefly) November 1992 Massachusetts 3, ballot on the submitted to the voters on (Election Date) (Name of City/ Town of State)* *Note: If this expenditure is made to influence a local ballot question, a copy of this form should be filed with the city or town clerk or election commission. November 5. 1992 October 16, 19 92 and Ending Fil in Dates: Reporting Period Beginning contribution I certify that this report is a true statement of the amount of value of gift, payment, expenditure or or whom promise to give, pay,, expend or contribute, together with the date, purpose, and full name and address of the person to Mass. Laws, Section, as amended. It was made. I make this General report in accordance with the requirements of Chapter, Signed under the penalties of perjury. Preasurer Senato March 30, 1993 Date Assistant Treasurer EXPENDITURES OR DISBURSEMENTS Amount or Value** Date Paid To Whom Paid (Alphabetical Listing Mandatory) Purpose Address P. O. B03 5979 Boston, MA 0212 Oppose Tax Increase 28, 482. 00 Committee Against Unfair Taxes 10/ 26/ 92 Oppose Tax increas 19, 503 00 P. O. Box 5979. Boston, MA 02114 10/ 30/ 92 Committee Against Unfair Taxes 91814768 48, 585 00 Total Expenditures or Disbursements on This Report 508. 789 00 Total Expenditures for Disbursements Previously Reported **In- kind contributions should be included here. Attach additional pages if necessary. 556 874. 00 Total Expenditures or Disbursements to Date REPORTING REQUIREMENTS CONTINUED ON REVERSE SIDE"], "experiment": "entropy_routing_default", "routed": {"answer": "application form for a job", "used_ocr": false, "answer_first": "application form for a job", "answer_second": null, "raw_answer": "application form for a job", "raw_answer_first": "application form for a job", "raw_answer_second": null, "mean_entropy_first": 3.8653777122497557, "normalized_entropy_first": 0.21158290496900686, "min_margin_first": 0.08840751647949219, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 176, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 177, "total_latency_s": 0.177, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.456614971160889, 2.0226733684539795, 1.6438734531402588, 5.23264741897583, 4.971079349517822], "entropies_second": null, "final_normalized_entropy": 0.21158290496900686, "sequence_confidence_first": 0.2013811307775774, "sequence_confidence_second": null, "sequence_confidence_final": 0.2013811307775774, "token_confidences_first": [0.0907871350646019, 0.3518122732639313, 0.48921382427215576, 0.09710846841335297, 0.13719342648983002, 0.3203968405723572], "token_confidences_second": null, "final_mean_entropy": 3.8653777122497557, "final_min_margin": 0.08840751647949219, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9880459770114942, "wer": 0.9943820224719101, "precision": 0.6, "recall": 0.008426966292134831, "f1": 0.01662049861495845, "rouge_l": 0.0110803324099723, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Executive Offices 1 GULF+ WESTE PLAZA . NEW YORK, NEW YORK 23- 7773 (212) 373- 7500 PRENTICE HALL CORPORATE SERVICES The Prentice- Hall Corporation System, Inc. United States Corporation Company 12- 13- 89 DATE: RECEIVED TX 3951 U TO: LORILLARD, INC. ONE PARK AVENUE 18TH FL NEW YORK, N. Y. 10016 DEC 14 89 ATTN: MR. ARTHUR STEVENS, ESQ A. J. STEVENS MOTOR CARRIER OR STATUTORY x 033052 LORILLARD, INC. Account # RE: (Represented Company) NOTICE OF SERVICE OF PROCESS We enclose the following documents which were served upon: UNITED STATES CORPORATION COMPANY IN TEXAS as registered agent for the above- captioned corporation on 12- 13- 89 via: x Mail: Regular or Certified Certified # Personal Service Notice of Mechanic's Lien Summons A self- addressed stamped envelope enclosed Notice of Default Jucgment Complaint Duplicate copies of the Notice and Acknowledgement enclosed Garnishment Subpoena Notice of Attorney's Lien CITATION AND FIRST ORIGINAL PETITION X Other: ) TITLE OF ACTION: WEBSTER CRECC 475,592 ) Case No. ) vs. R. J. REYNOLDS TOBACCO COMPANY, ET AL ) 345th Judicial District Court Travis County. Tx COURT OR JURISDICTION Monday next 20 days from date of service RETURN DATE Agent called New York Office Collect Tel Call Placed Direct Spoke to COMMENTS: ATTORNEYS FOR CLAIMANT Mary Ellen Felps 1000 West Ave. Austin, Tx. 78701 512/478- 4873 Phone PAPERS TRANSMITTED TO CLIENT Fed X Reg Mail X PAT HIGGINS FORM PREPARED BY Other 92380595 PLEASE ACKNOWLEDGE RECEIPT OF THIS NOTICE AND THE ENCLOSURES BY SIGNING AND RETURNING THE DUPLICATE COPY A BUSINESS REPLY ENVELOPE IS ENCLOSED FOR YOUR CONVENIENCE Signed: Date Received: 12/ 14/ 89 ORIGINAL"], "experiment": "entropy_routing_default", "routed": {"answer": "Prentice Hall Corporate Services", "used_ocr": true, "answer_first": "form", "answer_second": "Prentice Hall Corporate Services", "raw_answer": "Prentice Hall Corporate Services", "raw_answer_first": "form", "raw_answer_second": "Prentice Hall Corporate Services", "mean_entropy_first": 5.374140739440918, "normalized_entropy_first": 1.686426236460066, "min_margin_first": 0.06151771545410156, "mean_entropy_second": 1.1102771631308965, "normalized_entropy_second": -2.513528220901944, "min_margin_second": 1.2405624389648438, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 85, "latency_ms_ocr": 821, "latency_ms_second": 360, "total_latency_ms": 1269, "total_latency_s": 1.269, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.374140739440918], "entropies_second": [5.583049774169922, 0.40585434436798096, 0.09806522727012634, 0.15269707143306732, 1.1336443424224854, 0.2843145430088043, 0.11431483924388885], "final_normalized_entropy": -2.513528220901944, "sequence_confidence_first": 0.1401913586776242, "sequence_confidence_second": 0.669405279705765, "sequence_confidence_final": 0.669405279705765, "token_confidences_first": [0.06692463904619217, 0.29366788268089294], "token_confidences_second": [0.12593179941177368, 0.9442130923271179, 0.9878197908401489, 0.9816784262657166, 0.7109947800636292, 0.9515570402145386, 0.9848901629447937, 0.5247731804847717], "final_mean_entropy": 1.1102771631308965, "final_min_margin": 1.2405624389648438, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9807344972907887, "wer": 0.9851851851851852, "precision": 1.0, "recall": 0.014814814814814815, "f1": 0.029197080291970802, "rouge_l": 0.029197080291970802, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["LORILLARD MEDIA SERVICES ONE PARK AVENUE, NEW YORK, NY 10016- 5896 MAGAZINE INSERTION ORDER DATE: MARCH 17, 1995 TO: ESSENCE 1500 BROADWAY NEW YORK, NY 10036 ADVERTISER: LORILLARD ATTN: JOYCE WINSTON PRODUCT: NEWPORT THIS ADVERTISEMENT COMPLIES WITH THE FTC REQUIREMENT FOR A WARNING STATEMENT AND TAR AND NICOTINE LINE WHICH MUST APPEAR IN ALL CIGARETTE ADVERTISING CHECK MATERIAL YOU RECEIVE AGAINST THE PROOF TO BE SURE IT IS CORRECT, UNDER NO CIRCUMSTANCES ARE TO YOU RUN SUBSTITUTE MATERIALS, ALTERIOR OR OMIT ANY COPY WITHOUT PRIOR APPROVAL FROM LORILLARD MEDIA SERVICES. CAPTION: SPACE: DATE: AD#: NPT- 533- 7 FOUNTAIN COUPLE P5CE JUNE 1995 PO #77219 IF UNABLE TO INSERT ON THE DATE ORDERED KINDLY NOTIFY US AT ONCE AND WAIT FOR NEW INSERTION DATE. NO CREDIT CAN BE ALLOWED SHOULD THIS ADVERTISEMENT APPEAR INCORRECTLY OR ON A DATE OTHER THAN THAT AUTHORIZED. POSITION URGENTLY REQUESTED: FAR FORWARD, OPPOSITE FULL EDITORIAL - No coupon ad on backing page. - Maintain at least six page separation from bompetitive ads. - No aditional/ advertising matter to cigarette within 6 pages of our ad. COPY INSTRUCTIONS: SURGEON GENERALS WARNING Cigarette Smoke contains carbon Monoxide 5 COLOR PROOF ATTACHED, FILM FROM COLLIER WITH \"D\" WARNING SPACE BILLING INSTRUCTIONS: IMPORTANT INSTRUCTIONS: The space is being brdered by: A. Check material carefully against proof to make sure it corresponds in every respect LOAILLARD MEDIA SERVICES B. Please inspect repro material immediately. They should produce good printing results. Advise us promptly if Hor satisfactory Direct all invoices and full checking copies of all regional and national additions to: C. Poor printing will not be paid for. D. Advise us at once if instructions are not clear. LORILLARD MEDIA SERVICES ONE PARK AVENUE 17TH FLOOR NEW YORK NEW YORK 10016- 5896 ATTN: STEVE MOLLOY 93106788 E. Under no circumstances are you to space out our advertisement without specific instructions from us."], "experiment": "entropy_routing_default", "routed": {"answer": "medical assistance services", "used_ocr": false, "answer_first": "medical assistance services", "answer_second": null, "raw_answer": "medical assistance services", "raw_answer_first": "medical assistance services", "raw_answer_second": null, "mean_entropy_first": 4.100968758265178, "normalized_entropy_first": 0.24526146394908008, "min_margin_first": 0.08386898040771484, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 139, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 140, "total_latency_s": 0.14, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.729259967803955, 4.857308387756348, 2.7163379192352295], "entropies_second": null, "final_normalized_entropy": 0.24526146394908008, "sequence_confidence_first": 0.20731093454937713, "sequence_confidence_second": null, "sequence_confidence_final": 0.20731093454937713, "token_confidences_first": [0.21500998735427856, 0.07067664712667465, 0.4614066779613495, 0.2634331285953522], "token_confidences_second": null, "final_mean_entropy": 4.100968758265178, "final_min_margin": 0.08386898040771484, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9862244897959184, "wer": 0.9967845659163987, "precision": 0.3333333333333333, "recall": 0.003215434083601286, "f1": 0.006369426751592356, "rouge_l": 0.006369426751592356, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["A MOVE to stop Mr. Gaitskell from nominating any more Labour life Peers is to be made at a meeting of Labour M tomorrow . Mr. Michael Foot has put down a resolution on the subject and he is to be backed by Mr. Will Griffiths , M for Manchester Exchange ."], "experiment": "entropy_routing_default", "routed": {"answer": "a letter to mr gordon brown from the writer in the audience", "used_ocr": false, "answer_first": "a letter to mr gordon brown from the writer in the audience", "answer_second": null, "raw_answer": "a letter to mr gordon brown from the writer in the audience", "raw_answer_first": "a letter to mr gordon brown from the writer in the audience", "raw_answer_second": null, "mean_entropy_first": 4.241324961185455, "normalized_entropy_first": 0.36711675116508, "min_margin_first": 0.014386177062988281, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 403, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 406, "total_latency_s": 0.406, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.743931770324707, 3.3012571334838867, 2.114490032196045, 3.1729745864868164, 1.0990277528762817, 5.839247226715088, 5.597186088562012, 5.637469291687012, 3.559375524520874, 5.043868541717529, 5.796130180358887, 3.475574016571045, 4.665065765380859, 6.332951545715332], "entropies_second": null, "final_normalized_entropy": 0.36711675116508, "sequence_confidence_first": 0.19448917126604362, "sequence_confidence_second": null, "sequence_confidence_final": 0.19448917126604362, "token_confidences_first": [0.22892887890338898, 0.5124689340591431, 0.5864966511726379, 0.47890546917915344, 0.6501736044883728, 0.06979191303253174, 0.10425256192684174, 0.08916450291872025, 0.4200710356235504, 0.08785253018140793, 0.06206151098012924, 0.23234835267066956, 0.3204585313796997, 0.02919241040945053, 0.3114253878593445], "token_confidences_second": null, "final_mean_entropy": 4.241324961185455, "final_min_margin": 0.014386177062988281, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8188976377952756, "wer": 0.9230769230769231, "precision": 0.3333333333333333, "recall": 0.07692307692307693, "f1": 0.125, "rouge_l": 0.125, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Though they may gather some Left-wing support , a large majority of Labour M are likely to turn down the Foot-Griffiths resolution . Mr. Foot's line will be that as Labour M opposed the Government Bill which brought life peers into existence , they should not now put forward nominees . He believes that the House of Lords should be abolished and that Labour should not take any steps which would appear to \" prop up \" an out-dated institution ."], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": false, "answer_first": "yes", "answer_second": null, "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": null, "mean_entropy_first": 3.7681639194488525, "normalized_entropy_first": -0.13105480823526885, "min_margin_first": 0.18038177490234375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 100, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 104, "total_latency_s": 0.104, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7681639194488525], "entropies_second": null, "final_normalized_entropy": -0.13105480823526885, "sequence_confidence_first": 0.3348470915220076, "sequence_confidence_second": null, "sequence_confidence_final": 0.3348470915220076, "token_confidences_first": [0.21269385516643524, 0.5271547436714172], "token_confidences_second": null, "final_mean_entropy": 3.7681639194488525, "final_min_margin": 0.18038177490234375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9932584269662922, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Though they may gather some Left-wing support , a large majority of Labour 0M are likely to turn down the Foot-Griffiths resolution . Mr. Foot's line will be that as Labour 0M opposed the Govern- ment Bill which brought life peers into existence , they should not now put forward nominees . He believes that the House of Lords should be abolished and that Labour should not take any steps which would appear to \" prop up \" an out-dated institution ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.7610450983047485, "normalized_entropy_first": -1.1935344667944399, "min_margin_first": 0.34462928771972656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 122, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 127, "total_latency_s": 0.127, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.178730010986328, 1.343360185623169], "entropies_second": null, "final_normalized_entropy": -1.1935344667944399, "sequence_confidence_first": 0.3719011195119442, "sequence_confidence_second": null, "sequence_confidence_final": 0.3719011195119442, "token_confidences_first": [0.20675303041934967, 0.4490797817707062, 0.5539965629577637], "token_confidences_second": null, "final_mean_entropy": 2.7610450983047485, "final_min_margin": 0.34462928771972656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9755011135857461, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Delegates from Mr. Kenneth Kaunda's United National Independence Party ( 280,000 members ) and Mr. Harry Nkumbula's African National Congress ( 400,000 ) will meet in London today to discuss a common course of action . Sir Roy is violently opposed to Africans getting an elected majority in Northern Rhodesia , but the Colonial Secretary , Mr. Iain Macleod , is insisting on a policy of change ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.9536768198013306, "normalized_entropy_first": -0.8576419540500597, "min_margin_first": 0.0806732177734375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 121, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 126, "total_latency_s": 0.126, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.700290203094482, 1.2070634365081787], "entropies_second": null, "final_normalized_entropy": -0.8576419540500597, "sequence_confidence_first": 0.32496732999017897, "sequence_confidence_second": null, "sequence_confidence_final": 0.32496732999017897, "token_confidences_first": [0.16413699090480804, 0.44286608695983887, 0.4721067547798157], "token_confidences_second": null, "final_mean_entropy": 2.9536768198013306, "final_min_margin": 0.0806732177734375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9721518987341772, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Sir Roy's United Federal Party is boycotting the London talks on the Protectorate's future . Said Mr. Nkumbula last night : \" We want to discuss what to do if the British Government gives in to Sir Roy and the talks fall through . There are bound to be demonstrations . \" Yesterday Sir Roy's chief aide , Mr. Julius Greenfield , telephoned his chief a report on his talks with Mr. Macmillan at Chequers ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.8240129351615906, "normalized_entropy_first": -0.9233869007811173, "min_margin_first": 0.2662944793701172, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 121, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 125, "total_latency_s": 0.125, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.362924098968506, 1.2851017713546753], "entropies_second": null, "final_normalized_entropy": -0.9233869007811173, "sequence_confidence_first": 0.3829332669274938, "sequence_confidence_second": null, "sequence_confidence_final": 0.3829332669274938, "token_confidences_first": [0.203065887093544, 0.4612009525299072, 0.5995730757713318], "token_confidences_second": null, "final_mean_entropy": 2.8240129351615906, "final_min_margin": 0.2662944793701172, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9727722772277227, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["He said these concerned Mr. Weaver's alleged association with organisations black- listed by the Government . Immediately Mr. Kennedy rushed a letter to Senator Robertson saying the Federal Bureau of In- vestigation had reported on Mr. Weaver . He believed he would perform \" outstanding service \" in his post . Senator Robertson's committee has to pass Mr. Weaver's nomination before it can be con- # sidered by the full Senate ."], "experiment": "entropy_routing_default", "routed": {"answer": "0", "used_ocr": false, "answer_first": "0", "answer_second": null, "raw_answer": "0", "raw_answer_first": "0", "raw_answer_second": null, "mean_entropy_first": 1.9467240869998932, "normalized_entropy_first": -1.7864773662522277, "min_margin_first": 1.7473573684692383, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 118, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 123, "total_latency_s": 0.123, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.1866750717163086, 0.7067731022834778], "entropies_second": null, "final_normalized_entropy": -1.7864773662522277, "sequence_confidence_first": 0.6930196577418887, "sequence_confidence_second": null, "sequence_confidence_final": 0.6930196577418887, "token_confidences_first": [0.5357618927955627, 0.8560914397239685, 0.7256792187690735], "token_confidences_second": null, "final_mean_entropy": 1.9467240869998932, "final_min_margin": 1.7473573684692383, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["And , since this is election year in West Germany , Dr. Adenauer is in a tough spot . Joyce Egginton cables : President Kennedy at his Washington Press con- ference admitted he did not know whether America was lagging behind Russia in missile power . He said he was waiting for his senior military aides to come up with the answer on February 20 ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.0767972469329834, "normalized_entropy_first": -0.35772038517229793, "min_margin_first": 0.21390724182128906, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 120, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 124, "total_latency_s": 0.124, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.860897064208984, 1.2926974296569824], "entropies_second": null, "final_normalized_entropy": -0.35772038517229793, "sequence_confidence_first": 0.37709438713847, "sequence_confidence_second": null, "sequence_confidence_final": 0.37709438713847, "token_confidences_first": [0.16738204658031464, 0.452621728181839, 0.7077924609184265], "token_confidences_second": null, "final_mean_entropy": 3.0767972469329834, "final_min_margin": 0.21390724182128906, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.968299711815562, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["The result of the vote was not in doubt . For the Tories were massed in answer to their whips to defeat a censure motion on the Government for \" undermining the Health Service \" and placing heavy burdens on those least able to bear them . Mr. Brown declared that the policy under censure was monstrous . It had offended many people far beyond the ranks of Labour supporters ."], "experiment": "entropy_routing_default", "routed": {"answer": "1000x667", "used_ocr": false, "answer_first": "1000x667", "answer_second": null, "raw_answer": "1000x667", "raw_answer_first": "1000x667", "raw_answer_second": null, "mean_entropy_first": 2.5295728312598333, "normalized_entropy_first": -0.9042029141403953, "min_margin_first": 0.07138347625732422, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 271, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 275, "total_latency_s": 0.275, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.082858085632324, 2.160581588745117, 2.4912946224212646, 3.054516553878784, 2.8038344383239746, 2.5832290649414062, 1.6850041151046753, 2.075559616088867, 1.8292773962020874], "entropies_second": null, "final_normalized_entropy": -0.9042029141403953, "sequence_confidence_first": 0.3086661317970669, "sequence_confidence_second": null, "sequence_confidence_final": 0.3086661317970669, "token_confidences_first": [0.1764497607946396, 0.21437031030654907, 0.3689558207988739, 0.2893781065940857, 0.48088014125823975, 0.38543665409088135, 0.3097338378429413, 0.2996748387813568, 0.4203581213951111, 0.26879167556762695], "token_confidences_second": null, "final_mean_entropy": 2.5295728312598333, "final_min_margin": 0.07138347625732422, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["In fact , the Tories made it worse now for the sick and needy than Labour had to make it in 1950 . And as a percentage of social service expenditure , health had fallen from 28.5 to 23.1 per cent. Then Mr. Brown swung his attack directly to the unsmiling Mr. Powell . He demanded that instead of taking it out of the patients Mr. Powell should take ruthless action against the drug making industry , # whose profits had risen by up to 400 per"], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.8194077014923096, "normalized_entropy_first": -0.5203987020143036, "min_margin_first": 0.4068431854248047, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 119, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 123, "total_latency_s": 0.123, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.387256622314453, 1.251558780670166], "entropies_second": null, "final_normalized_entropy": -0.5203987020143036, "sequence_confidence_first": 0.4020126364805089, "sequence_confidence_second": null, "sequence_confidence_final": 0.4020126364805089, "token_confidences_first": [0.1999439001083374, 0.5000199675559998, 0.6498656868934631], "token_confidences_second": null, "final_mean_entropy": 2.8194077014923096, "final_min_margin": 0.4068431854248047, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9751131221719457, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["\" That cannot continue without either development being limited or an adjustment being made in financing . \" The Government decided to adjust the financing - which Mr. Powell claimed was underpinning - not undermining - the service . Answering the attack on \" economic charges \" for welfare foods , Mr. Powell said that all these foods would still be free in families receiving regular National Assistance grants ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.634145736694336, "normalized_entropy_first": -0.6894834965830882, "min_margin_first": 0.478240966796875, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 119, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 123, "total_latency_s": 0.123, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.079380512237549, 1.188910961151123], "entropies_second": null, "final_normalized_entropy": -0.6894834965830882, "sequence_confidence_first": 0.405245456983731, "sequence_confidence_second": null, "sequence_confidence_final": 0.405245456983731, "token_confidences_first": [0.19550102949142456, 0.5282884240150452, 0.6443685293197632], "token_confidences_second": null, "final_mean_entropy": 2.634145736694336, "final_min_margin": 0.478240966796875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9734299516908212, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["On the other hand , Mr. Pearson excels in meeting people informally , but many still regard him \" as some sort of cross between an egghead and a missionary \" . His party advisers are now trying to correct that image . The bow tie has gone ; he is having lessons on television techniques and is being coached by speech experts ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.761086881160736, "normalized_entropy_first": -0.49629768234258886, "min_margin_first": 0.09135723114013672, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 119, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 123, "total_latency_s": 0.123, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.275720596313477, 1.2464531660079956], "entropies_second": null, "final_normalized_entropy": -0.49629768234258886, "sequence_confidence_first": 0.3403013153863471, "sequence_confidence_second": null, "sequence_confidence_final": 0.3403013153863471, "token_confidences_first": [0.14451617002487183, 0.4762287735939026, 0.5726098418235779], "token_confidences_second": null, "final_mean_entropy": 2.761086881160736, "final_min_margin": 0.09135723114013672, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9663608562691132, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Apart from their formal Admiralty House talks , followed by lunch given by Lady Dorothy Macmillan with Mrs. Kennedy and other guests present , Mr. Kennedy and Mr. Macmillan met three more times yesterday . In PARIS , Mr. Dean Rusk , U.S. Secretary of State , gave a 90-minute briefing on the Vienna talks to the 15-nation Nato council . Some of his listeners said he was \" rather pessimistic \" and talked of a Berlin crisis later this year ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.071848690509796, "normalized_entropy_first": -0.10112320408291708, "min_margin_first": 0.20627689361572266, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 120, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 124, "total_latency_s": 0.124, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.913997650146484, 1.229699730873108], "entropies_second": null, "final_normalized_entropy": -0.10112320408291708, "sequence_confidence_first": 0.3419142636097498, "sequence_confidence_second": null, "sequence_confidence_final": 0.3419142636097498, "token_confidences_first": [0.12050431221723557, 0.5071569681167603, 0.6540435552597046], "token_confidences_second": null, "final_mean_entropy": 3.071848690509796, "final_min_margin": 0.20627689361572266, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9750566893424036, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["The second reason is concerned with doubts as to the safety of the people of Great Britain ; \" in the time of crisis it would probably be impossible for the British authorities to exercise any degree of control over the action of Polaris submarines . \" He argues that there is a distinct possibility that so long as there is a Polaris base in Britain the Soviet Union might retaliate against Britain alone ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.1748024225234985, "normalized_entropy_first": 0.031168906620437288, "min_margin_first": 0.6103229522705078, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 120, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 125, "total_latency_s": 0.125, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.038706302642822, 1.3108985424041748], "entropies_second": null, "final_normalized_entropy": 0.031168906620437288, "sequence_confidence_first": 0.3775544415940511, "sequence_confidence_second": null, "sequence_confidence_final": 0.3775544415940511, "token_confidences_first": [0.179717019200325, 0.5132433176040649, 0.5834803581237793], "token_confidences_second": null, "final_mean_entropy": 3.1748024225234985, "final_min_margin": 0.6103229522705078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.972972972972973, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Sir Francis is to hand over to Sir Richard as from Nov. 1 . The hand-over , due in September , was delayed because of the Berlin crisis . Mr. Watkinson and his advisers felt the change would be unwise at a moment # when attention had to be concentrated on possible need for important military operations . For this reason Sir Francis stayed on , and # sacrificed his leave ."], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 4.146533966064453, "normalized_entropy_first": 1.2935749763522195, "min_margin_first": 0.2505226135253906, "mean_entropy_second": 3.920640707015991, "normalized_entropy_second": 0.9997379998153453, "min_margin_second": 0.1450510025024414, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 98, "latency_ms_ocr": 837, "latency_ms_second": 147, "total_latency_ms": 1086, "total_latency_s": 1.086, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.146533966064453], "entropies_second": [3.920640707015991], "final_normalized_entropy": 0.9997379998153453, "sequence_confidence_first": 0.15700732639919351, "sequence_confidence_second": 0.4346381468044687, "sequence_confidence_final": 0.4346381468044687, "token_confidences_first": [0.17747153341770172, 0.13890284299850464], "token_confidences_second": [0.18901987373828888, 0.9994204044342041], "final_mean_entropy": 3.920640707015991, "final_min_margin": 0.1450510025024414, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9919786096256684, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["The small rocket craft , for destroying big ships , are controlled automatically , even to the preparations for launching their rockets . Applauding on the river banks at Leningrad were thousands now told that in 20 years they will have free food , housing , light , heat , transport and medical treatment - all for a working week of 34 to 36 hours ."], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.771468162536621, "normalized_entropy_first": 1.9289184368049774, "min_margin_first": 0.02236175537109375, "mean_entropy_second": 5.382908821105957, "normalized_entropy_second": 2.7048773710451894, "min_margin_second": 0.523463249206543, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 97, "latency_ms_ocr": 521, "latency_ms_second": 135, "total_latency_ms": 758, "total_latency_s": 0.758, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.771468162536621], "entropies_second": [5.382908821105957], "final_normalized_entropy": 2.7048773710451894, "sequence_confidence_first": 0.17314966243738641, "sequence_confidence_second": 0.353775517885195, "sequence_confidence_final": 0.353775517885195, "token_confidences_first": [0.13982565701007843, 0.21441562473773956], "token_confidences_second": [0.12531468272209167, 0.9987426400184631], "final_mean_entropy": 5.382908821105957, "final_min_margin": 0.523463249206543, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9914285714285714, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Mr. Macmillan said we could be more help to the Commonwealth through the strength we would gain in the Common Market than by isolation . He paid tribute to the development of the Common Market . \" The Community ( Common Market ) has imparted an impetus and an economic growth to The Six . Above all , it is an idea which has gripped men's minds , \" he said ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwritten", "used_ocr": true, "answer_first": "yes", "answer_second": "handwritten", "raw_answer": "handwritten", "raw_answer_first": "yes", "raw_answer_second": "handwritten", "mean_entropy_first": 4.532821178436279, "normalized_entropy_first": 1.289695536314891, "min_margin_first": 0.11086177825927734, "mean_entropy_second": 3.0932886600494385, "normalized_entropy_second": -0.3542828273512034, "min_margin_second": 0.012708663940429688, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 98, "latency_ms_ocr": 550, "latency_ms_second": 169, "total_latency_ms": 823, "total_latency_s": 0.823, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.532821178436279], "entropies_second": [5.164571762084961, 1.022005558013916], "final_normalized_entropy": -0.3542828273512034, "sequence_confidence_first": 0.22295577514816228, "sequence_confidence_second": 0.313102988885344, "sequence_confidence_final": 0.313102988885344, "token_confidences_first": [0.18590690195560455, 0.2673880159854889], "token_confidences_second": [0.1407465785741806, 0.6072323322296143, 0.3591442406177521], "final_mean_entropy": 3.0932886600494385, "final_min_margin": 0.012708663940429688, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9720670391061452, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["THE Queen and the Duke of Edinburgh come home tonight from their tour in the East . The duke's trigger-finger and the ritual slaughter of beasts have taken the headlines in this country . Nevertheless , the tour has been an immense success . The Queen has won a triumph . It would be pleasanter if such cruel and feudal performances as tiger and rhino hunts were dropped from future Royal programmes ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.7487789392471313, "normalized_entropy_first": -0.8556849625378041, "min_margin_first": 0.2984170913696289, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 119, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 123, "total_latency_s": 0.123, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.348195552825928, 1.149362325668335], "entropies_second": null, "final_normalized_entropy": -0.8556849625378041, "sequence_confidence_first": 0.34899426294750674, "sequence_confidence_second": null, "sequence_confidence_final": 0.34899426294750674, "token_confidences_first": [0.14290548861026764, 0.5607338547706604, 0.5304557681083679], "token_confidences_second": null, "final_mean_entropy": 2.7487789392471313, "final_min_margin": 0.2984170913696289, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.972568578553616, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Certainly , the rise is very small . But it is a step in the direction of live-and-let-live . Hopes will now grow brighter of further international co-operation , which is the only way to solve the payments difficulties that upset the Western world . Britain and the U.S. , which have problems with their balances , will gain some immediate help . What it means in practical terms is that our exports to Germany will now be a little cheaper for Germans to buy , while the goods which Germany exports will be made a little dearer ."], "experiment": "entropy_routing_default", "routed": {"answer": "9 1024x768", "used_ocr": false, "answer_first": "9 1024x768", "answer_second": null, "raw_answer": "9 1024x768", "raw_answer_first": "9 1024x768", "raw_answer_second": null, "mean_entropy_first": 2.152110067280856, "normalized_entropy_first": -1.4603153534460789, "min_margin_first": 0.15615272521972656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 321, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 325, "total_latency_s": 0.325, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.434841632843018, 1.972503900527954, 2.814572811126709, 1.9214894771575928, 1.8696887493133545, 3.4192042350769043, 0.4858083128929138, 3.414881706237793, 1.1601650714874268, 2.0563366413116455, 0.12371820211410522], "entropies_second": null, "final_normalized_entropy": -1.4603153534460789, "sequence_confidence_first": 0.3604294502490213, "sequence_confidence_second": null, "sequence_confidence_final": 0.3604294502490213, "token_confidences_first": [0.16947491466999054, 0.288460910320282, 0.2672331929206848, 0.34300631284713745, 0.6044811010360718, 0.15606611967086792, 0.923460066318512, 0.3427499234676361, 0.5917654037475586, 0.2718331217765808, 0.9830260872840881, 0.22717183828353882], "token_confidences_second": null, "final_mean_entropy": 2.152110067280856, "final_min_margin": 0.15615272521972656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9962264150943396, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["That is doubtful . If however , in addition to her new good-neighbour gesture , Germany takes a really big share in giving aid to underdeveloped nations , the world outlook will be brighter . What gives rise to optimism is the sign that Germany and the other leading Western nations are at long last moving towards a solution of currency problems by co-operation ."], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 5.637564659118652, "normalized_entropy_first": 2.525282713766673, "min_margin_first": 0.15563488006591797, "mean_entropy_second": 1.8151661157608032, "normalized_entropy_second": -1.6234550841557513, "min_margin_second": 1.3468170166015625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 96, "latency_ms_ocr": 520, "latency_ms_second": 146, "total_latency_ms": 767, "total_latency_s": 0.767, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.637564659118652], "entropies_second": [1.8151661157608032], "final_normalized_entropy": -1.6234550841557513, "sequence_confidence_first": 0.19527145021236808, "sequence_confidence_second": 0.7979023542677227, "sequence_confidence_final": 0.7979023542677227, "token_confidences_first": [0.09388051182031631, 0.40616458654403687], "token_confidences_second": [0.6367087364196777, 0.9999048709869385], "final_mean_entropy": 1.8151661157608032, "final_min_margin": 1.3468170166015625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9917582417582418, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["A CURIOUS advertisement on page nine , paid for by that curious body Moral Re-Armament . Those who lend their names to this kind of advertisement are worthy people , a little innocent of politics , perhaps , or carried away by the idea that moral regeneration would solve all our problems . So it would . While we are waiting for the millenium , however , most of us would prefer to put our hopes for earthly justice in instruments of democracy , such as trade unions and our local and national Parliaments ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.85470449924469, "normalized_entropy_first": -0.6158637982024759, "min_margin_first": 0.17766761779785156, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 122, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 126, "total_latency_s": 0.126, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.439810276031494, 1.2695987224578857], "entropies_second": null, "final_normalized_entropy": -0.6158637982024759, "sequence_confidence_first": 0.36368670620977966, "sequence_confidence_second": null, "sequence_confidence_final": 0.36368670620977966, "token_confidences_first": [0.17201776802539825, 0.48207715153694153, 0.5800860524177551], "token_confidences_second": null, "final_mean_entropy": 2.85470449924469, "final_min_margin": 0.17766761779785156, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9783464566929134, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["But back , Mr. Hammarskjold is determined , they must go . The best news for the Congo would be agreement between its rival political leaders . Through the patient efforts of UN conciliators they are meeting for the first time , in Malagasy ( formerly Madagascar ) . THE world will sigh with relief when this strife-torn land gets itself a government which all outsiders can recognise ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.7277294397354126, "normalized_entropy_first": -0.6909354475599564, "min_margin_first": 0.21744918823242188, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 120, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 124, "total_latency_s": 0.124, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.139065742492676, 1.3163931369781494], "entropies_second": null, "final_normalized_entropy": -0.6909354475599564, "sequence_confidence_first": 0.4448813274774683, "sequence_confidence_second": null, "sequence_confidence_final": 0.4448813274774683, "token_confidences_first": [0.30593594908714294, 0.44515448808670044, 0.6465338468551636], "token_confidences_second": null, "final_mean_entropy": 2.7277294397354126, "final_min_margin": 0.21744918823242188, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9715025906735751, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["ONLY a man wrapped in the impenetrable cocoon of what he regards as a divine mission could have spoken of apartheid as \" a policy of good neighbourliness . \" We may be sure that he is not being hypocritical . That is what he really believes . A good neighbour to those Africans who , under apartheid , will be forced back to their tribal reserves with no prospect but a cramped and primitive existence ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.909697949886322, "normalized_entropy_first": -0.4670375152755923, "min_margin_first": 0.3203582763671875, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 117, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 121, "total_latency_s": 0.121, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.5305938720703125, 1.2888020277023315], "entropies_second": null, "final_normalized_entropy": -0.4670375152755923, "sequence_confidence_first": 0.3599281197348409, "sequence_confidence_second": null, "sequence_confidence_final": 0.3599281197348409, "token_confidences_first": [0.15628479421138763, 0.479958713054657, 0.6216225028038025], "token_confidences_second": null, "final_mean_entropy": 2.909697949886322, "final_min_margin": 0.3203582763671875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9727047146401985, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["The views of the Archbishop , who has maintained an unflinching witness to what Christianity really means , must carry weight . But what , in fact , can the other Commonwealth countries do to bring support and comfort to this gallant minority ? THERE is no evidence that the policy of appeasement has modified the actions of the Nationalists . On the contrary , apartheid is being applied ever more ruthlessly ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.8071388006210327, "normalized_entropy_first": -0.5401882875494223, "min_margin_first": 0.72119140625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 119, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 124, "total_latency_s": 0.124, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.370655059814453, 1.2436225414276123], "entropies_second": null, "final_normalized_entropy": -0.5401882875494223, "sequence_confidence_first": 0.4186730948842949, "sequence_confidence_second": null, "sequence_confidence_final": 0.4186730948842949, "token_confidences_first": [0.2359991818666458, 0.542788565158844, 0.5729067921638489], "token_confidences_second": null, "final_mean_entropy": 2.8071388006210327, "final_min_margin": 0.72119140625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9732360097323601, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["On this reading what Mr. Gollancz calls manoeuvring , and what we should call cool-headed and inventive negotiation , is a means not to destruction but to safety . The Government's pompous little statement on Northern Rhodesia does not say much , but it says what is necessary - that the Northern Rhodesia Constitution is open to revision . This is news , however much the Government tries to disguise it by saying that the revision would be"], "experiment": "entropy_routing_default", "routed": {"answer": "10", "used_ocr": true, "answer_first": "yes", "answer_second": "10", "raw_answer": "10", "raw_answer_first": "yes", "raw_answer_second": "10", "mean_entropy_first": 4.372170448303223, "normalized_entropy_first": 1.1100904925964092, "min_margin_first": 0.2541370391845703, "mean_entropy_second": 3.4682323137919107, "normalized_entropy_second": 0.17715228858787707, "min_margin_second": 0.3836231231689453, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 97, "latency_ms_ocr": 757, "latency_ms_second": 193, "total_latency_ms": 1053, "total_latency_s": 1.053, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.372170448303223], "entropies_second": [5.3402886390686035, 2.0350441932678223, 3.0293641090393066], "final_normalized_entropy": 0.17715228858787707, "sequence_confidence_first": 0.24509276584234863, "sequence_confidence_second": 0.25291924876243554, "sequence_confidence_final": 0.25291924876243554, "token_confidences_first": [0.173956498503685, 0.34531888365745544], "token_confidences_second": [0.15906760096549988, 0.29848533868789673, 0.1864965409040451, 0.462117075920105], "final_mean_entropy": 3.4682323137919107, "final_min_margin": 0.3836231231689453, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["To be able to say \" New York next week \" is an important advance . We must not be overconfident that this # meeting will lead on to further and decisive ones ; but without it , we could not look for them . Federal Germany votes tomorrow and not a day too soon . There can seldom have been an election campaign which more people in and out of the country wanted to see over and done with ."], "experiment": "entropy_routing_default", "routed": {"answer": "letter", "used_ocr": false, "answer_first": "letter", "answer_second": null, "raw_answer": "letter", "raw_answer_first": "letter", "raw_answer_second": null, "mean_entropy_first": 4.085179805755615, "normalized_entropy_first": 0.6990814607083745, "min_margin_first": 0.16192626953125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 102, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 106, "total_latency_s": 0.106, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.085179805755615], "entropies_second": null, "final_normalized_entropy": 0.6990814607083745, "sequence_confidence_first": 0.35339112279071566, "sequence_confidence_second": null, "sequence_confidence_final": 0.35339112279071566, "token_confidences_first": [0.19814756512641907, 0.6302640438079834], "token_confidences_second": null, "final_mean_entropy": 4.085179805755615, "final_min_margin": 0.16192626953125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9845360824742269, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Who are they ? The trade union officials of Britain . Men who earn only a fraction of what their talents and responsibilities could bring in the open labour market . The unions are fortunate indeed to find dedicated leaders at cut-rate prices . But it is time the members decided to pay up and be good employers . THE Labour Party says that the Tory Government is destroying the social services ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.7844711542129517, "normalized_entropy_first": -0.7266479874271691, "min_margin_first": 0.23002338409423828, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 126, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 130, "total_latency_s": 0.13, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.285125732421875, 1.2838165760040283], "entropies_second": null, "final_normalized_entropy": -0.7266479874271691, "sequence_confidence_first": 0.368179910721583, "sequence_confidence_second": null, "sequence_confidence_final": 0.368179910721583, "token_confidences_first": [0.1740076243877411, 0.4721111059188843, 0.6075300574302673], "token_confidences_second": null, "final_mean_entropy": 2.7844711542129517, "final_min_margin": 0.23002338409423828, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9747474747474747, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["All this has been achieved through Nato under American leadership . But a big role has been played not only by the British Government but by Right-Wing Labour in this country . They have helped build up Nato and rearm Western Germany , in pursuit of the old familiar anti-Soviet policy which brought disaster in 1939 ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.8478437066078186, "normalized_entropy_first": -0.6030662887400894, "min_margin_first": 0.26153564453125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 124, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 129, "total_latency_s": 0.129, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.487659454345703, 1.208027958869934], "entropies_second": null, "final_normalized_entropy": -0.6030662887400894, "sequence_confidence_first": 0.4066425174987633, "sequence_confidence_second": null, "sequence_confidence_final": 0.4066425174987633, "token_confidences_first": [0.18736954033374786, 0.5516912341117859, 0.6504939794540405], "token_confidences_second": null, "final_mean_entropy": 2.8478437066078186, "final_min_margin": 0.26153564453125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9654088050314465, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Ordinary working people will never rally to defend a policy founded on political chicanery or elect a Labour Government to carry through Tory policy - Gaitskell's stupid hope . The tragedy is that enormous inroads could already have been made into Tory strength by a fighting policy , based on Scarborough . THE desire for unity in the Labour and trade union movement following the"], "experiment": "entropy_routing_default", "routed": {"answer": "1000 words", "used_ocr": false, "answer_first": "1000 words", "answer_second": null, "raw_answer": "1000 words", "raw_answer_first": "1000 words", "raw_answer_second": null, "mean_entropy_first": 3.1700151364008584, "normalized_entropy_first": -0.19992265165433096, "min_margin_first": 0.00806427001953125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 216, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 220, "total_latency_s": 0.22, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.004744052886963, 2.18741512298584, 2.806633949279785, 3.478731632232666, 3.0302562713623047, 2.5123097896575928], "entropies_second": null, "final_normalized_entropy": -0.19992265165433096, "sequence_confidence_first": 0.33839884252518543, "sequence_confidence_second": null, "sequence_confidence_final": 0.33839884252518543, "token_confidences_first": [0.1449974924325943, 0.2509539723396301, 0.37988123297691345, 0.2595471143722534, 0.4316752254962921, 0.5732470750808716, 0.5723800659179688], "token_confidences_second": null, "final_mean_entropy": 3.1700151364008584, "final_min_margin": 0.00806427001953125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.984251968503937, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["At the same time that unity cannot be established on a false basis , or by creating further confusion within the movement . Unity will never be established on the basis of leaders being a law unto themselves and opposing conference decisions when it suits their own convenience . Unity can never be established by any formula uniting those who oppose German troops being trained on British soil and Polaris , and those who are for this policy - which is the same as that of the Tory Government ."], "experiment": "entropy_routing_default", "routed": {"answer": "9th grade essay", "used_ocr": false, "answer_first": "9th grade essay", "answer_second": null, "raw_answer": "9th grade essay", "raw_answer_first": "9th grade essay", "raw_answer_second": null, "mean_entropy_first": 2.5753909846146903, "normalized_entropy_first": -0.8922901450509435, "min_margin_first": 0.060085296630859375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 214, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 218, "total_latency_s": 0.218, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.938422441482544, 2.01037335395813, 3.4755139350891113, 1.6860380172729492, 3.840270519256592, 0.5017276406288147], "entropies_second": null, "final_normalized_entropy": -0.8922901450509435, "sequence_confidence_first": 0.32116058548814913, "sequence_confidence_second": null, "sequence_confidence_final": 0.32116058548814913, "token_confidences_first": [0.23504574596881866, 0.32581841945648193, 0.17303626239299774, 0.7402971982955933, 0.1463187038898468, 0.8045353293418884, 0.3051683306694031], "token_confidences_second": null, "final_mean_entropy": 2.5753909846146903, "final_min_margin": 0.060085296630859375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9717171717171718, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Strangely enough , the Berlin audience received the film with extreme coolness , much preferring Jean-Luc Godard's disappointing \" Une Femme est une Femme , \" a ninety-one minute hymn to \" Vogue , \" \" Cahiers du Cinema , \" and the worst aspects of the American cinema . From a brilliantly funny start , the work fizzles out into a series of repetitious sight-gags and personal jokes incomprehensible to the uninitiated ( including four plugs for Charles Aznavour ) ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.451251804828644, "normalized_entropy_first": 0.2358064150478071, "min_margin_first": 0.1834430694580078, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 124, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 128, "total_latency_s": 0.128, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.607975959777832, 1.2945276498794556], "entropies_second": null, "final_normalized_entropy": 0.2358064150478071, "sequence_confidence_first": 0.3064016995288154, "sequence_confidence_second": null, "sequence_confidence_final": 0.3064016995288154, "token_confidences_first": [0.11954079568386078, 0.4481355547904968, 0.5369674563407898], "token_confidences_second": null, "final_mean_entropy": 3.451251804828644, "final_min_margin": 0.1834430694580078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9763948497854077, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Arguably , the dramatist has committed a technical error in allowing Irene to speak for herself ; we would be altogether clearer in our minds about her if she remained a flawed but beautiful enigma , seen but not heard . However , Miss Pinkie Johnstone makes her few brief scenes effective , and Mr. Dinsdale Landen , in the longest and most exacting role , that of the sergeant , gives a performance of rare intelligence and restrained power ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.495164930820465, "normalized_entropy_first": 0.27845035288574943, "min_margin_first": 0.2715883255004883, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 124, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 128, "total_latency_s": 0.128, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.829293251037598, 1.1610366106033325], "entropies_second": null, "final_normalized_entropy": 0.27845035288574943, "sequence_confidence_first": 0.36056548047594966, "sequence_confidence_second": null, "sequence_confidence_final": 0.36056548047594966, "token_confidences_first": [0.11547651886940002, 0.5737414956092834, 0.7075261473655701], "token_confidences_second": null, "final_mean_entropy": 3.495164930820465, "final_min_margin": 0.2715883255004883, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9752252252252253, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Mr. William Lucas ( Morris ) is always insen- sitively pushing , Miss Sheila Allen his wife , always palely appealing , Mr. James Maxwell , the editor , always comically abashed by the events , and Mr. Aubrey Richards , the father-in-law , always comically grotesque ; they were not asked to modulate from their set moods but played with proper efficiency and , in the case of Mr. Richards , with lavish and suitably gaudy colour ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.839646816253662, "normalized_entropy_first": -0.6046583134063361, "min_margin_first": 0.4353179931640625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 124, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 128, "total_latency_s": 0.128, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.516921520233154, 1.16237211227417], "entropies_second": null, "final_normalized_entropy": -0.6046583134063361, "sequence_confidence_first": 0.3747596393261706, "sequence_confidence_second": null, "sequence_confidence_final": 0.3747596393261706, "token_confidences_first": [0.1551142930984497, 0.5300970077514648, 0.6401050686836243], "token_confidences_second": null, "final_mean_entropy": 2.839646816253662, "final_min_margin": 0.4353179931640625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.974477958236659, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Only Mr. Lucas's actions , therefore , arose explicably from appreciable motives . The rest , one feels , were driven to effective action by the author in spite of the ineffectuality with which he had endowed them . One hopes that he is not asking us to believe that , because of their odd accents , they act oddly like the queer foreigners of tradition ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.356598913669586, "normalized_entropy_first": 0.14512259704769037, "min_margin_first": 0.1277008056640625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 123, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 127, "total_latency_s": 0.127, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.549943923950195, 1.163253903388977], "entropies_second": null, "final_normalized_entropy": 0.14512259704769037, "sequence_confidence_first": 0.3275685754835913, "sequence_confidence_second": null, "sequence_confidence_final": 0.3275685754835913, "token_confidences_first": [0.11309100687503815, 0.46586787700653076, 0.6671382784843445], "token_confidences_second": null, "final_mean_entropy": 3.356598913669586, "final_min_margin": 0.1277008056640625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.971830985915493, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["HOW do you get on records ? Well , you 've got to have something different . Sing slightly flat . All the good singers sing in tune . Twang a guitar slightly off key . Everybody 's fed up with the right way - so the best-seller charts say . Play an OLD 2pianna instead of a new one . You got to get it into your head , son ... people don't like things as they should be - not on record , anyway ."], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.477193355560303, "normalized_entropy_first": 1.754818272571551, "min_margin_first": 1.2013835906982422, "mean_entropy_second": 2.866372585296631, "normalized_entropy_second": -0.5699840094121712, "min_margin_second": 0.6274833679199219, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 100, "latency_ms_ocr": 780, "latency_ms_second": 174, "total_latency_ms": 1060, "total_latency_s": 1.06, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.477193355560303], "entropies_second": [2.866372585296631], "final_normalized_entropy": -0.5699840094121712, "sequence_confidence_first": 0.24688640934593634, "sequence_confidence_second": 0.6285279453745815, "sequence_confidence_final": 0.6285279453745815, "token_confidences_first": [0.24478723108768463, 0.2490035891532898], "token_confidences_second": [0.3953245282173157, 0.9992989301681519], "final_mean_entropy": 2.866372585296631, "final_min_margin": 0.6274833679199219, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9924242424242424, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Become a success with a disc and hey presto ! You 're a star ... . Rolly sings with assuredness \" Bella Bella Marie \" ( Parlophone ) , a lively song that changes tempo mid-way . I don't think he will storm the charts with this one , but it 's a good start . CHRIS CHARLES , 39 , who lives in Stockton-on-Tees , is an accountant ."], "experiment": "entropy_routing_default", "routed": {"answer": "9 1000", "used_ocr": false, "answer_first": "9 1000", "answer_second": null, "raw_answer": "9 1000", "raw_answer_first": "9 1000", "raw_answer_second": null, "mean_entropy_first": 2.6535782473427907, "normalized_entropy_first": -0.9701522085334714, "min_margin_first": 0.007175445556640625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 239, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 243, "total_latency_s": 0.243, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.477555751800537, 1.6852208375930786, 2.493168354034424, 1.7679420709609985, 1.8683078289031982, 3.675872802734375, 2.606980085372925], "entropies_second": null, "final_normalized_entropy": -0.9701522085334714, "sequence_confidence_first": 0.3223277311744955, "sequence_confidence_second": null, "sequence_confidence_final": 0.3223277311744955, "token_confidences_first": [0.23764543235301971, 0.5245527625083923, 0.3286909759044647, 0.3406355679035187, 0.6115711331367493, 0.13027332723140717, 0.6057272553443909, 0.17298376560211182], "token_confidences_second": null, "final_mean_entropy": 2.6535782473427907, "final_min_margin": 0.007175445556640625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.993920972644377, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["IT is mid-morning on a Dublin Sunday . The streets are tranquilly sunny and still , for the town is at Mass . Most of it . In the front room of a house in Anglesey-road is a congregation who never actually got to church , but who are gathered with devotion around Brendan Behan and a brandy bottle ."], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 4.505520343780518, "normalized_entropy_first": 1.6026570290503404, "min_margin_first": 0.08023357391357422, "mean_entropy_second": 4.712947368621826, "normalized_entropy_second": 1.8807151272493066, "min_margin_second": 0.5174884796142578, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 99, "latency_ms_ocr": 500, "latency_ms_second": 137, "total_latency_ms": 742, "total_latency_s": 0.742, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.505520343780518], "entropies_second": [4.712947368621826], "final_normalized_entropy": 1.8807151272493066, "sequence_confidence_first": 0.21067296669869826, "sequence_confidence_second": 0.4427962868541857, "sequence_confidence_final": 0.4427962868541857, "token_confidences_first": [0.15115110576152802, 0.29363396763801575], "token_confidences_second": [0.1964310258626938, 0.9981546998023987], "final_mean_entropy": 4.712947368621826, "final_min_margin": 0.5174884796142578, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9899665551839465, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["That 's as bloody silly as calling a Rolls- Royce a type of transport . She 's the flower in a cultural desert . \" Now , me - I 'm a journalist , I write to entertain rather than educate . And I don't write at all unless I 'm exceedingly 2skint . \" But I 'll say this . I 'd like to live in America and do some writing there ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.8545740246772766, "normalized_entropy_first": -0.7246581836551513, "min_margin_first": 0.1930084228515625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 122, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 126, "total_latency_s": 0.126, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.540266513824463, 1.1688815355300903], "entropies_second": null, "final_normalized_entropy": -0.7246581836551513, "sequence_confidence_first": 0.42754163577095666, "sequence_confidence_second": null, "sequence_confidence_final": 0.42754163577095666, "token_confidences_first": [0.17662611603736877, 0.6169407367706299, 0.7171943783760071], "token_confidences_second": null, "final_mean_entropy": 2.8545740246772766, "final_min_margin": 0.1930084228515625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9662576687116564, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["\" That 's how I got into all this trouble . \" \" He 's got to be 35 , \" says Bobby Darin , the chief spokesman of the jeans-and- Jeep brigadiers as they 're scheming to get rid of old man , solid Rock . \" How many hills can he take ? \" Of course Mr. Hudson can take one more hill than the youngsters ."], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.940627098083496, "normalized_entropy_first": 2.031351432583965, "min_margin_first": 0.04549598693847656, "mean_entropy_second": 1.9299085140228271, "normalized_entropy_second": -1.8675499480792954, "min_margin_second": 0.9753732681274414, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 100, "latency_ms_ocr": 513, "latency_ms_second": 135, "total_latency_ms": 754, "total_latency_s": 0.754, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.940627098083496], "entropies_second": [1.9299085140228271], "final_normalized_entropy": -1.8675499480792954, "sequence_confidence_first": 0.1706118079036985, "sequence_confidence_second": 0.7760648748553093, "sequence_confidence_final": 0.7760648748553093, "token_confidences_first": [0.10341033339500427, 0.28148433566093445], "token_confidences_second": [0.6041821241378784, 0.9968462586402893], "final_mean_entropy": 1.9299085140228271, "final_min_margin": 0.9753732681274414, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.99, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["This man is the worm , the creature that cuts and polishes Altar-Stones . Such a man is the Shamir that guards him- self against all the irrelevant pleasures . Such a Shamir possesses the real acid to mould our character , to melt our heart of stone . This Shamir helps us earthly creatures to build an Altar for God to come nearer to God ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.9745452404022217, "normalized_entropy_first": -0.6366650008552108, "min_margin_first": 0.153076171875, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 120, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 124, "total_latency_s": 0.124, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.652072906494141, 1.2970175743103027], "entropies_second": null, "final_normalized_entropy": -0.6366650008552108, "sequence_confidence_first": 0.3504477329567989, "sequence_confidence_second": null, "sequence_confidence_final": 0.3504477329567989, "token_confidences_first": [0.14540131390094757, 0.4863922595977783, 0.6085759401321411], "token_confidences_second": null, "final_mean_entropy": 2.9745452404022217, "final_min_margin": 0.153076171875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9705882352941176, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["For without the vision to serve the Lord your God with all your heart and with all your soul and with all your might the problem of life cannot be solved . \" Therefore shall 1ye lay up these my words in your heart and in your soul . \" The text adds and in your soul , searching your soul ."], "experiment": "entropy_routing_default", "routed": {"answer": "900x670 essay example how to write a good conclusion for an argumentative paper", "used_ocr": false, "answer_first": "900x670 essay example how to write a good conclusion for an argumentative paper", "answer_second": null, "raw_answer": "900x670 essay example how to write a good conclusion for an argumentative paper", "raw_answer_first": "900x670 essay example how to write a good conclusion for an argumentative paper", "raw_answer_second": null, "mean_entropy_first": 2.7904938757419586, "normalized_entropy_first": -0.8105485712864221, "min_margin_first": 0.061951637268066406, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 563, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 568, "total_latency_s": 0.568, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.750607490539551, 0.852839469909668, 2.534992218017578, 0.8770873546600342, 2.9611220359802246, 0.9124078750610352, 0.5270088911056519, 1.801203966140747, 4.415431022644043, 0.15343886613845825, 4.68336296081543, 5.117035865783691, 0.6621289253234863, 1.6885464191436768, 3.1703414916992188, 4.909294128417969, 4.848361968994141, 4.345544815063477, 4.124996662139893, 4.324631690979004, 0.7618334293365479, 3.9686477184295654], "entropies_second": null, "final_normalized_entropy": -0.8105485712864221, "sequence_confidence_first": 0.31517388556845266, "sequence_confidence_second": null, "sequence_confidence_final": 0.31517388556845266, "token_confidences_first": [0.2634713649749756, 0.7361195683479309, 0.24850910902023315, 0.8370315432548523, 0.38461336493492126, 0.7823449373245239, 0.9009507298469543, 0.2582128942012787, 0.20037031173706055, 0.9674032330513, 0.11253457516431808, 0.07645200937986374, 0.9097777009010315, 0.7324328422546387, 0.4635855257511139, 0.10556760430335999, 0.07106833159923553, 0.1834581196308136, 0.1714308261871338, 0.20729228854179382, 0.9033692479133606, 0.2343481481075287, 0.19440001249313354], "token_confidences_second": null, "final_mean_entropy": 2.7904938757419586, "final_min_margin": 0.061951637268066406, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8339100346020761, "wer": 0.9838709677419355, "precision": 0.15384615384615385, "recall": 0.03225806451612903, "f1": 0.05333333333333333, "rouge_l": 0.026666666666666665, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Even worse is to laugh . Tremendous damage may be done to a child by laughing at what are very real fears . As adults , we know that their fears are groundless , indeed to us they appear laughable , but to a child they are very real . Not that I am suggesting that children should be molly-coddled - they must be made to face their fears , to see through them and come out on the other side as victors ."], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 5.027442455291748, "normalized_entropy_first": 1.9659619848609589, "min_margin_first": 0.2716407775878906, "mean_entropy_second": 1.2874581813812256, "normalized_entropy_second": -2.566321631981671, "min_margin_second": 1.742654800415039, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 99, "latency_ms_ocr": 664, "latency_ms_second": 148, "total_latency_ms": 917, "total_latency_s": 0.917, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.027442455291748], "entropies_second": [1.2874581813812256], "final_normalized_entropy": -2.566321631981671, "sequence_confidence_first": 0.23829461104109909, "sequence_confidence_second": 0.8593138097820746, "sequence_confidence_final": 0.8593138097820746, "token_confidences_first": [0.13519465923309326, 0.4200189709663391], "token_confidences_second": [0.7386573553085327, 0.9996789693832397], "final_mean_entropy": 1.2874581813812256, "final_min_margin": 1.742654800415039, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9925558312655087, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Amen . MOST people would probably regard tiredness as a purely physical thing . The cure for which is sleep . This is only partly true . Many people wake up tired of a morning and no amount of rest seems to make any difference . Sleep , to be effective , must be of that child-like quality which comes from innocence ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.3990213871002197, "normalized_entropy_first": -0.18264634404454497, "min_margin_first": 0.22643566131591797, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 122, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 127, "total_latency_s": 0.127, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.436325550079346, 1.3617172241210938], "entropies_second": null, "final_normalized_entropy": -0.18264634404454497, "sequence_confidence_first": 0.34752149921028164, "sequence_confidence_second": null, "sequence_confidence_final": 0.34752149921028164, "token_confidences_first": [0.12965764105319977, 0.4864964783191681, 0.6653761267662048], "token_confidences_second": null, "final_mean_entropy": 3.3990213871002197, "final_min_margin": 0.22643566131591797, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9716981132075472, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Or it is possible that our sugya contains the original question and answer and this is quoted in the other sugya . ( This can be supported by the use of the expression : ' Boaz did it of his own accord but there was no approval of his action in Heaven ' in both sugyoth . Such an expression appears to have been framed in response to the particular point at issue here , whether the Heavenly Court concurred in the decision of the human court . )"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 4.181312561035156, "normalized_entropy_first": 0.7200939998459379, "min_margin_first": 0.41611385345458984, "mean_entropy_second": 2.8110058307647705, "normalized_entropy_second": -0.8442755511164878, "min_margin_second": 0.8517694473266602, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 100, "latency_ms_ocr": 615, "latency_ms_second": 147, "total_latency_ms": 868, "total_latency_s": 0.868, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.181312561035156], "entropies_second": [2.8110058307647705], "final_normalized_entropy": -0.8442755511164878, "sequence_confidence_first": 0.2304999581675781, "sequence_confidence_second": 0.6839817676552636, "sequence_confidence_final": 0.6839817676552636, "token_confidences_first": [0.1743364781141281, 0.3047568202018738], "token_confidences_second": [0.46787595748901367, 0.9999040365219116], "final_mean_entropy": 2.8110058307647705, "final_min_margin": 0.8517694473266602, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9932735426008968, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["First launder crochet and then pin to the required shape , ensuring that all lines of the crochet are accurate . Place crochet in correct position on linen and secure with pins . Run a line of basting stitches on the linen following the outline of the crochet edges which are to be attached to the linen . Remove crochet ."], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "letter", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "letter", "raw_answer_second": "yes", "mean_entropy_first": 4.533156394958496, "normalized_entropy_first": 1.0789211428909904, "min_margin_first": 0.0098419189453125, "mean_entropy_second": 3.583066463470459, "normalized_entropy_second": -0.035854288314784495, "min_margin_second": 0.6751565933227539, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 100, "latency_ms_ocr": 570, "latency_ms_second": 149, "total_latency_ms": 825, "total_latency_s": 0.825, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.533156394958496], "entropies_second": [3.583066463470459], "final_normalized_entropy": -0.035854288314784495, "sequence_confidence_first": 0.29480056524150516, "sequence_confidence_second": 0.556549540432661, "sequence_confidence_final": 0.556549540432661, "token_confidences_first": [0.1509484201669693, 0.5757421851158142], "token_confidences_second": [0.3098403215408325, 0.9997000694274902], "final_mean_entropy": 3.583066463470459, "final_min_margin": 0.6751565933227539, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9937888198757764, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["For short ones a smoothing plane can be used . The gauge can now be used to nick in the tapers on the newly planed surfaces , and these treated as before . It is unnecessary to mark the taper with the straight-edge as one relies upon the truth of the plane sole to make the tapered surfaces straight ."], "experiment": "entropy_routing_default", "routed": {"answer": "1000 words", "used_ocr": false, "answer_first": "1000 words", "answer_second": null, "raw_answer": "1000 words", "raw_answer_first": "1000 words", "raw_answer_second": null, "mean_entropy_first": 3.2938085794448853, "normalized_entropy_first": -0.4819959865106206, "min_margin_first": 0.2690572738647461, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 213, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 217, "total_latency_s": 0.217, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.796011924743652, 2.084205150604248, 3.14129376411438, 3.595154047012329, 3.401240348815918, 2.744946241378784], "entropies_second": null, "final_normalized_entropy": -0.4819959865106206, "sequence_confidence_first": 0.3138012748432063, "sequence_confidence_second": null, "sequence_confidence_final": 0.3138012748432063, "token_confidences_first": [0.1302412748336792, 0.2820447087287903, 0.3315233886241913, 0.23868708312511444, 0.3403560221195221, 0.5458590984344482, 0.5548291206359863], "token_confidences_second": null, "final_mean_entropy": 3.2938085794448853, "final_min_margin": 0.2690572738647461, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9800664451827242, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["Decide on the required angle of slope , keeping B flat on the chair seat , and mark off the exact position of B on the side pieces . These can then be cut at the correct angle and B is glued and nailed in place . A piece of hardboard is then cut and pinned to the frame and its edges planed off flush ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 3.2508689165115356, "normalized_entropy_first": -0.5044177602725943, "min_margin_first": 0.2131938934326172, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 123, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 127, "total_latency_s": 0.127, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [5.225707530975342, 1.2760303020477295], "entropies_second": null, "final_normalized_entropy": -0.5044177602725943, "sequence_confidence_first": 0.3760191595282464, "sequence_confidence_second": null, "sequence_confidence_final": 0.3760191595282464, "token_confidences_first": [0.18117570877075195, 0.46097370982170105, 0.6365811824798584], "token_confidences_second": null, "final_mean_entropy": 3.2508689165115356, "final_min_margin": 0.2131938934326172, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9668874172185431, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["To complete the job , screw two fittings to the inside of the chair arms about 2 1/2 in. from the back to hold the baby's safety harness . These can be made by shaping and soldering two pieces of stout wire as shown in Fig. 6 . Make sure that these are well secured as they will have to withstand considerable pulling as the child becomes older ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.7458017468452454, "normalized_entropy_first": -1.1138476248454507, "min_margin_first": 0.05689430236816406, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 125, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 129, "total_latency_s": 0.129, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.325093746185303, 1.166509747505188], "entropies_second": null, "final_normalized_entropy": -1.1138476248454507, "sequence_confidence_first": 0.40368411027800777, "sequence_confidence_second": null, "sequence_confidence_final": 0.40368411027800777, "token_confidences_first": [0.16590268909931183, 0.552057683467865, 0.7182689309120178], "token_confidences_second": null, "final_mean_entropy": 2.7458017468452454, "final_min_margin": 0.05689430236816406, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9682080924855492, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["If you do not have a wooden floor on which to anchor the moulds , make a frame of rough lumber as shown in Fig. 2 . The main idea is to have the moulds standing as rigid as possible , for it is on these you will be building and shaping your little craft , upside-down . For cheapness I recommend using Douglas Fir Plywood from British Columbia ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.9536479115486145, "normalized_entropy_first": -0.7342902744822026, "min_margin_first": 0.1385364532470703, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 123, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 128, "total_latency_s": 0.128, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.593970775604248, 1.313325047492981], "entropies_second": null, "final_normalized_entropy": -0.7342902744822026, "sequence_confidence_first": 0.309667101785468, "sequence_confidence_second": null, "sequence_confidence_final": 0.309667101785468, "token_confidences_first": [0.1376892626285553, 0.43401801586151123, 0.49690958857536316], "token_confidences_second": null, "final_mean_entropy": 2.9536479115486145, "final_min_margin": 0.1385364532470703, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9681159420289855, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["I have also included a sketch of paddles I make for rowing this dinghy ( Fig. 3 ) . They are very simple , cheap and easy to make . As will be seen from the plan there is only a single gunwale on the outside . I find that the type of rowlock we use in Canada is difficult to obtain here and expensive . I overcome this in another way as shown in Fig. 4 ."], "experiment": "entropy_routing_default", "routed": {"answer": "9780321546567 1000 how to write a research paper in apa format", "used_ocr": false, "answer_first": "9780321546567 1000 how to write a research paper in apa format", "answer_second": null, "raw_answer": "9780321546567 1000 how to write a research paper in apa format", "raw_answer_first": "9780321546567 1000 how to write a research paper in apa format", "raw_answer_second": null, "mean_entropy_first": 2.609551160756884, "normalized_entropy_first": -1.1245645913321245, "min_margin_first": 0.0037746429443359375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 740, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 744, "total_latency_s": 0.744, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.66104793548584, 1.4147744178771973, 2.6934731006622314, 0.07803184539079666, 1.1025729179382324, 2.1102559566497803, 1.514119029045105, 1.73014235496521, 2.372516632080078, 2.2297613620758057, 2.2400283813476562, 2.3838555812835693, 2.3821799755096436, 2.599123477935791, 5.004642009735107, 2.4166178703308105, 4.698654651641846, 3.9709367752075195, 2.715120792388916, 5.448159217834473, 1.75018310546875, 1.800121545791626, 3.482734203338623, 4.356618881225586, 0.8189808130264282, 5.391825199127197, 4.0784912109375, 0.08375763893127441, 1.148256778717041], "entropies_second": null, "final_normalized_entropy": -1.1245645913321245, "sequence_confidence_first": 0.2786467232714464, "sequence_confidence_second": null, "sequence_confidence_final": 0.2786467232714464, "token_confidences_first": [0.3439747989177704, 0.6352218389511108, 0.4102931022644043, 0.9900216460227966, 0.452332079410553, 0.20514078438282013, 0.5845078825950623, 0.3399481475353241, 0.21396252512931824, 0.20955398678779602, 0.28405407071113586, 0.14695940911769867, 0.12081530690193176, 0.12143182754516602, 0.133387953042984, 0.2082182914018631, 0.0969642773270607, 0.3496779203414917, 0.614702582359314, 0.06424184888601303, 0.7393444180488586, 0.7584906220436096, 0.43573838472366333, 0.1703513115644455, 0.8815387487411499, 0.08205119520425797, 0.1697300225496292, 0.9905927777290344, 0.5493122935295105, 0.0483572892844677], "token_confidences_second": null, "final_mean_entropy": 2.609551160756884, "final_min_margin": 0.0037746429443359375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.8898305084745762, "wer": 0.9615384615384616, "precision": 0.2727272727272727, "recall": 0.038461538461538464, "f1": 0.06741573033707866, "rouge_l": 0.06741573033707866, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["The edges of the transoms should be bevelled to correspond to the sides and bottom of the boat . Don't forget to cut out on each side of each mould to allow for the chines to rest in these notches , as they are not fastened to the moulds , which will only be used whilst the hull is under construction ."], "experiment": "entropy_routing_default", "routed": {"answer": "handwriting", "used_ocr": false, "answer_first": "handwriting", "answer_second": null, "raw_answer": "handwriting", "raw_answer_first": "handwriting", "raw_answer_second": null, "mean_entropy_first": 2.9285808205604553, "normalized_entropy_first": -0.594497310124026, "min_margin_first": 0.38929176330566406, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 126, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 131, "total_latency_s": 0.131, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.597626209259033, 1.2595354318618774], "entropies_second": null, "final_normalized_entropy": -0.594497310124026, "sequence_confidence_first": 0.40362401232224926, "sequence_confidence_second": null, "sequence_confidence_final": 0.40362401232224926, "token_confidences_first": [0.20173600316047668, 0.495829313993454, 0.6573783159255981], "token_confidences_second": null, "final_mean_entropy": 2.9285808205604553, "final_min_margin": 0.38929176330566406, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.966996699669967, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["   #   ###  1_2 3_  3./_4_ 5_ AHQ469 EXPRESS   1._2.    / # 798704  ##     3 2    801002   1 ## 799277 800932      15:20  23:40 801002    00:20      /   800932 1655 30/8 15:50   19:00  29/8 573          # 1/9 799277 CYS 30 70    2 3 4 5 6    04:35 -##  33656208532 # 1 13:45    #    9.1  31/8"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "ha", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "ha", "mean_entropy_first": 4.252050876617432, "normalized_entropy_first": 1.210675079747006, "min_margin_first": 0.8649320602416992, "mean_entropy_second": 4.963457107543945, "normalized_entropy_second": 2.15939312824929, "min_margin_second": 0.06296634674072266, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 90, "latency_ms_ocr": 559, "latency_ms_second": 100, "total_latency_ms": 751, "total_latency_s": 0.751, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.252050876617432], "entropies_second": [4.963457107543945], "final_normalized_entropy": 1.210675079747006, "sequence_confidence_first": 0.19617614172267367, "sequence_confidence_second": 0.19224171236480087, "sequence_confidence_final": 0.19617614172267367, "token_confidences_first": [0.25033247470855713, 0.15373586118221283], "token_confidences_second": [0.09118834882974625, 0.4052806794643402], "final_mean_entropy": 4.252050876617432, "final_min_margin": 0.8649320602416992, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9968895800933126, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" 2012        #    "], "experiment": "entropy_routing_default", "routed": {"answer": "a book with chinese writing on it that says 2 0 1 2", "used_ocr": true, "answer_first": "yes", "answer_second": "a book with chinese writing on it that says 2 0 1 2", "raw_answer": "a book with chinese writing on it that says 2 0 1 2", "raw_answer_first": "yes", "raw_answer_second": "a book with chinese writing on it that says 2 0 1 2", "mean_entropy_first": 4.219366073608398, "normalized_entropy_first": 1.0297165370751238, "min_margin_first": 0.6144514083862305, "mean_entropy_second": 1.9765620082616806, "normalized_entropy_second": -1.9146281070900295, "min_margin_second": 0.024084091186523438, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 85, "latency_ms_ocr": 218, "latency_ms_second": 486, "total_latency_ms": 793, "total_latency_s": 0.793, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.219366073608398], "entropies_second": [2.487795352935791, 3.7918248176574707, 2.63427734375, 3.642683982849121, 0.12620341777801514, 1.3713055849075317, 2.351696729660034, 0.7646631598472595, 3.115884304046631, 2.2445127964019775, 3.945871353149414, 1.784381628036499, 3.9571356773376465, 1.1757478713989258, 0.7752314209938049, 0.25203385949134827, 0.5018236637115479, 0.6550431847572327], "final_normalized_entropy": -1.9146281070900295, "sequence_confidence_first": 0.19950698851444307, "sequence_confidence_second": 0.46171036980304353, "sequence_confidence_final": 0.46171036980304353, "token_confidences_first": [0.20276133716106415, 0.19630487263202667], "token_confidences_second": [0.5703280568122864, 0.24303101003170013, 0.37288224697113037, 0.2276478409767151, 0.982221782207489, 0.5878115892410278, 0.3500753939151764, 0.8465121984481812, 0.20897158980369568, 0.2848634719848633, 0.3671407401561737, 0.5990096926689148, 0.10591167211532593, 0.713408887386322, 0.8582454919815063, 0.9529544115066528, 0.9319183230400085, 0.8607353568077087, 0.3213326334953308], "final_mean_entropy": 1.9765620082616806, "final_min_margin": 0.024084091186523438, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.8921568627450981, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" TE95   WUHAN YUSHENGOPTICAL DEVICESCO,.LTD           YC178250 2o17.08.30        21:15 2017.08.30  YSB522P4C-SC-S28-C609   21:00 2017.08.30 YSOD"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt with chinese writing on it", "used_ocr": false, "answer_first": "a receipt with chinese writing on it", "answer_second": null, "raw_answer": "a receipt with chinese writing on it", "raw_answer_first": "a receipt with chinese writing on it", "raw_answer_second": null, "mean_entropy_first": 1.7019464545365837, "normalized_entropy_first": -2.383568553595115, "min_margin_first": 0.37991905212402344, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 263, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 264, "total_latency_s": 0.264, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.90358304977417, 3.58171010017395, 0.01786567084491253, 2.7152771949768066, 2.470277786254883, 0.06161218136548996, 1.3947834968566895, 1.0738483667373657, 0.09856024384498596], "entropies_second": null, "final_normalized_entropy": -2.383568553595115, "sequence_confidence_first": 0.5850062064590438, "sequence_confidence_second": null, "sequence_confidence_final": 0.5850062064590438, "token_confidences_first": [0.31422165036201477, 0.23031187057495117, 0.997744083404541, 0.3119800388813019, 0.5233277082443237, 0.9916374087333679, 0.6598080396652222, 0.7676878571510315, 0.987210750579834, 0.8030961751937866], "token_confidences_second": null, "final_mean_entropy": 1.7019464545365837, "final_min_margin": 0.37991905212402344, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9555555555555556, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["           3     55   2 57 23    4   "], "experiment": "entropy_routing_default", "routed": {"answer": "chinese writing", "used_ocr": false, "answer_first": "chinese writing", "answer_second": null, "raw_answer": "chinese writing", "raw_answer_first": "chinese writing", "raw_answer_second": null, "mean_entropy_first": 2.706246296564738, "normalized_entropy_first": -0.6933938844731319, "min_margin_first": 0.23514175415039062, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 132, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 132, "total_latency_s": 0.132, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.477468490600586, 0.30576324462890625, 3.3355071544647217], "entropies_second": null, "final_normalized_entropy": -0.6933938844731319, "sequence_confidence_first": 0.3625450798785962, "sequence_confidence_second": null, "sequence_confidence_final": 0.3625450798785962, "token_confidences_first": [0.16937929391860962, 0.9374017715454102, 0.1829443871974945, 0.5947615504264832], "token_confidences_second": null, "final_mean_entropy": 2.706246296564738, "final_min_margin": 0.23514175415039062, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9988776655443322, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" 2API682Planl1+72+75 3API682Plan74  0546-7787070 0546-7787070 Qiyao Screw ## # ##    www.hsflowseal  CBI GBI   233 CSD GBI CSD F ##"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 4.443833351135254, "normalized_entropy_first": 1.3390122988127826, "min_margin_first": 0.23463058471679688, "mean_entropy_second": 2.609034538269043, "normalized_entropy_second": -0.7534069525529714, "min_margin_second": 0.9425888061523438, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 86, "latency_ms_ocr": 311, "latency_ms_second": 122, "total_latency_ms": 522, "total_latency_s": 0.522, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.443833351135254], "entropies_second": [2.609034538269043], "final_normalized_entropy": -0.7534069525529714, "sequence_confidence_first": 0.15044340934809322, "sequence_confidence_second": 0.6275770332017107, "sequence_confidence_final": 0.6275770332017107, "token_confidences_first": [0.16357558965682983, 0.1383655071258545], "token_confidences_second": [0.3939969837665558, 0.9996343851089478], "final_mean_entropy": 2.609034538269043, "final_min_margin": 0.9425888061523438, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9887218045112782, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" Has taken part in the following training course in Shenzhen,China ISO90012008 ISO90012008Internal Auditor and has successfully passed tho final examination FOXCONN Technology Group Certificate 20121118,25  Director Greater China Precisely Right. Nov18&25.2012 We here wih confim that TUV Rheinlandb Group TUV Rheinland Group Training&Consulting Training&Consulting Mr.Thomas Zhu Xiao Yuhong Ms.Sherin Lin   Trainer  On  of ? # Sroi"], "experiment": "entropy_routing_default", "routed": {"answer": "certificate", "used_ocr": false, "answer_first": "certificate", "answer_second": null, "raw_answer": "certificate", "raw_answer_first": "certificate", "raw_answer_second": null, "mean_entropy_first": 3.601806402206421, "normalized_entropy_first": 0.23767286885789218, "min_margin_first": 0.6858921051025391, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 85, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 85, "total_latency_s": 0.085, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.601806402206421], "entropies_second": null, "final_normalized_entropy": 0.23767286885789218, "sequence_confidence_first": 0.3529704133664096, "sequence_confidence_second": null, "sequence_confidence_final": 0.3529704133664096, "token_confidences_first": [0.3300503194332123, 0.37748217582702637], "token_confidences_second": null, "final_mean_entropy": 3.601806402206421, "final_min_margin": 0.6858921051025391, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9776876267748479, "wer": 0.9838709677419355, "precision": 1.0, "recall": 0.016129032258064516, "f1": 0.031746031746031744, "rouge_l": 0.031746031746031744, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" _     ___        _      2016  2  1 2026228        -13-"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": false, "answer_first": "yes", "answer_second": null, "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": null, "mean_entropy_first": 3.7844932079315186, "normalized_entropy_first": 0.4374064871202798, "min_margin_first": 0.8831720352172852, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 86, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 88, "total_latency_s": 0.088, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7844932079315186], "entropies_second": null, "final_normalized_entropy": 0.4374064871202798, "sequence_confidence_first": 0.2708299177351661, "sequence_confidence_second": null, "sequence_confidence_final": 0.2708299177351661, "token_confidences_first": [0.2814127206802368, 0.2606450915336609], "token_confidences_second": null, "final_mean_entropy": 3.7844932079315186, "final_min_margin": 0.8831720352172852, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" ,,  , , , , (,::) (ABC (AB)    :00243358521   (): *   : / ()    *  :    CCE4L : :        HS           No.              "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.245229721069336, "normalized_entropy_first": 0.9708034338955923, "min_margin_first": 0.17592239379882812, "mean_entropy_second": 2.1182050704956055, "normalized_entropy_second": -1.6133555110184903, "min_margin_second": 2.4050073623657227, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 88, "latency_ms_ocr": 825, "latency_ms_second": 127, "total_latency_ms": 1044, "total_latency_s": 1.044, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.245229721069336], "entropies_second": [2.1182050704956055], "final_normalized_entropy": -1.6133555110184903, "sequence_confidence_first": 0.28948375468962056, "sequence_confidence_second": 0.8053355664374692, "sequence_confidence_final": 0.8053355664374692, "token_confidences_first": [0.1724013239145279, 0.4860800504684448], "token_confidences_second": [0.6486902236938477, 0.9998075366020203], "final_mean_entropy": 2.1182050704956055, "final_min_margin": 2.4050073623657227, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9965928449744463, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["0472-2293934       3      4 3 5 5:,, 2 2 11S090 1           : 2/6 30%  4    360"], "experiment": "entropy_routing_default", "routed": {"answer": "a document with chinese writing on it that has a number of numbers and letters in the top right corner", "used_ocr": true, "answer_first": "yes", "answer_second": "a document with chinese writing on it that has a number of numbers and letters in the top right corner", "raw_answer": "a document with chinese writing on it that has a number of numbers and letters in the top right corner", "raw_answer_first": "yes", "raw_answer_second": "a document with chinese writing on it that has a number of numbers and letters in the top right corner", "mean_entropy_first": 3.7578377723693848, "normalized_entropy_first": 0.28374386349181174, "min_margin_first": 0.5209035873413086, "mean_entropy_second": 2.500622378573531, "normalized_entropy_second": -1.2553945048303978, "min_margin_second": 0.03958320617675781, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 96, "latency_ms_ocr": 1673, "latency_ms_second": 560, "total_latency_ms": 2334, "total_latency_s": 2.334, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7578377723693848], "entropies_second": [3.107405185699463, 3.1704306602478027, 2.433356761932373, 3.3269355297088623, 0.10214432328939438, 1.6901005506515503, 2.2687535285949707, 0.5501427054405212, 3.4873147010803223, 2.7378156185150146, 3.5104682445526123, 3.7067134380340576, 2.640989065170288, 4.635678291320801, 2.257603645324707, 2.4479479789733887, 3.0859062671661377, 3.025113582611084, 2.635495662689209, 1.0932261943817139, 0.5995280146598816], "final_normalized_entropy": -1.2553945048303978, "sequence_confidence_first": 0.25557349025034104, "sequence_confidence_second": 0.36577697068059745, "sequence_confidence_final": 0.36577697068059745, "token_confidences_first": [0.2408210188150406, 0.27122968435287476], "token_confidences_second": [0.2867189049720764, 0.24665893614292145, 0.3512539565563202, 0.26234573125839233, 0.9858625531196594, 0.4096779227256775, 0.44327762722969055, 0.9065722227096558, 0.22634227573871613, 0.29374849796295166, 0.190233051776886, 0.2968297600746155, 0.2828464210033417, 0.14723274111747742, 0.457845002412796, 0.5951163172721863, 0.25052210688591003, 0.2072245478630066, 0.31374427676200867, 0.5918676257133484, 0.8578673601150513, 0.6598669290542603], "final_mean_entropy": 2.500622378573531, "final_min_margin": 0.03958320617675781, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9878345498783455, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["FM  TO   DOORDOOR 2017.9.4 20170000211 1257 2017.9.2              0.775 31 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt for payment of 1000 yuan", "used_ocr": false, "answer_first": "yes this is a receipt for payment of 1000 yuan", "answer_second": null, "raw_answer": "yes this is a receipt for payment of 1000 yuan", "raw_answer_first": "yes this is a receipt for payment of 1000 yuan", "raw_answer_second": null, "mean_entropy_first": 2.7535373708233237, "normalized_entropy_first": -1.022724162537274, "min_margin_first": 0.10700798034667969, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 432, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 436, "total_latency_s": 0.436, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.810403347015381, 4.5605082511901855, 1.435814380645752, 2.6797215938568115, 3.046175718307495, 0.02349148690700531, 2.389664649963379, 4.735409736633301, 2.5426652431488037, 4.514544486999512, 2.001542568206787, 2.0317115783691406, 2.9366140365600586, 3.176922082901001, 3.093625068664551, 1.0777837038040161], "entropies_second": null, "final_normalized_entropy": -1.022724162537274, "sequence_confidence_first": 0.36778154662754303, "sequence_confidence_second": null, "sequence_confidence_final": 0.36778154662754303, "token_confidences_first": [0.3267453908920288, 0.17218661308288574, 0.76981121301651, 0.4809655249118805, 0.4761490821838379, 0.9974285960197449, 0.32100948691368103, 0.1572607159614563, 0.3028795123100281, 0.11360997706651688, 0.3037009537220001, 0.4426657557487488, 0.4096718430519104, 0.3208671808242798, 0.4881215989589691, 0.5345533490180969, 0.5200798511505127], "token_confidences_second": null, "final_mean_entropy": 2.7535373708233237, "final_min_margin": 0.10700798034667969, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.927461139896373, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["--6.35mm --6.35mm --6.35mm --6.35mm --6.35mm --6.35mm --6.35mm         T-1 0030101229 0030101229 0030101229 0030101229 0030101229 0030101229 0030101229 0020102393   & & & & & & & & -N/A      # 9270 9270 9270 9270 9270 9270 9270    9790                 8 7 6 5 4 3 2 1"], "experiment": "entropy_routing_default", "routed": {"answer": "1000", "used_ocr": true, "answer_first": "1000", "answer_second": "yes", "raw_answer": "1000", "raw_answer_first": "1000", "raw_answer_second": "yes", "mean_entropy_first": 3.6070323467254637, "normalized_entropy_first": 0.17706759167858102, "min_margin_first": 0.26361083984375, "mean_entropy_second": 4.478926658630371, "normalized_entropy_second": 1.3010155917880393, "min_margin_second": 0.1993122100830078, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 170, "latency_ms_ocr": 512, "latency_ms_second": 122, "total_latency_ms": 806, "total_latency_s": 0.806, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.7204742431640625, 2.049684762954712, 2.7373595237731934, 4.110020637512207, 4.4176225662231445], "entropies_second": [4.478926658630371], "final_normalized_entropy": 0.17706759167858102, "sequence_confidence_first": 0.2272785624524062, "sequence_confidence_second": 0.4256359514762274, "sequence_confidence_final": 0.2272785624524062, "token_confidences_first": [0.16951556503772736, 0.3697621822357178, 0.3389715254306793, 0.22776006162166595, 0.2489468902349472, 0.11441192030906677], "token_confidences_second": [0.18253517150878906, 0.9924989342689514], "final_mean_entropy": 3.6070323467254637, "final_min_margin": 0.26361083984375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9928443649373881, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["    123420 2020178112037  123 811     #  2017 17     8  #   "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a book", "used_ocr": false, "answer_first": "yes this is a book", "answer_second": null, "raw_answer": "yes this is a book", "raw_answer_first": "yes this is a book", "raw_answer_second": null, "mean_entropy_first": 3.1396889209747316, "normalized_entropy_first": -0.466322884111375, "min_margin_first": 0.0709524154663086, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 178, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 179, "total_latency_s": 0.179, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.095083236694336, 4.126524448394775, 1.6074450016021729, 2.4629082679748535, 3.4064836502075195], "entropies_second": null, "final_normalized_entropy": -0.466322884111375, "sequence_confidence_first": 0.3117452224799263, "sequence_confidence_second": null, "sequence_confidence_final": 0.3117452224799263, "token_confidences_first": [0.17440438270568848, 0.15046249330043793, 0.7182355523109436, 0.48748457431793213, 0.393892377614975, 0.2536342144012451], "token_confidences_second": null, "final_mean_entropy": 3.1396889209747316, "final_min_margin": 0.0709524154663086, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9869281045751634, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["  S8102 11630  92320803MA1Q50XW14  20170824   201708  320803000201708240067   24                      "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.6689281463623047, "normalized_entropy_first": 0.3110969910065816, "min_margin_first": 0.3560638427734375, "mean_entropy_second": 3.5843353271484375, "normalized_entropy_second": 0.19141682065309304, "min_margin_second": 0.622248649597168, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 84, "latency_ms_ocr": 238, "latency_ms_second": 123, "total_latency_ms": 447, "total_latency_s": 0.447, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6689281463623047], "entropies_second": [3.5843353271484375], "final_normalized_entropy": 0.19141682065309304, "sequence_confidence_first": 0.2274112118338716, "sequence_confidence_second": 0.5236975195863832, "sequence_confidence_final": 0.5236975195863832, "token_confidences_first": [0.21776455640792847, 0.23748520016670227], "token_confidences_second": [0.3042445778846741, 0.90144282579422], "final_mean_entropy": 3.5843353271484375, "final_min_margin": 0.622248649597168, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.99581589958159, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" _P0002733 / 8.29 15      8.29 / 20170829002 : :  13:30      20170829 20.00   61190370    9.2 11:40 91     450  450 -   9:00 ERP:201709 010005"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": false, "answer_first": "yes", "answer_second": null, "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": null, "mean_entropy_first": 3.5652153491973877, "normalized_entropy_first": 0.13978993657814237, "min_margin_first": 1.1202831268310547, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 87, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 89, "total_latency_s": 0.089, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.5652153491973877], "entropies_second": null, "final_normalized_entropy": 0.13978993657814237, "sequence_confidence_first": 0.2724212551502245, "sequence_confidence_second": null, "sequence_confidence_final": 0.2724212551502245, "token_confidences_first": [0.3319753110408783, 0.22355078160762787], "token_confidences_second": null, "final_mean_entropy": 3.5652153491973877, "final_min_margin": 1.1202831268310547, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9964912280701754, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["          31 8 2017              IP           ## /                              yinxingongtong.com        21113391659                       "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.960645914077759, "normalized_entropy_first": 0.7505048616812983, "min_margin_first": 1.0312938690185547, "mean_entropy_second": 5.103631973266602, "normalized_entropy_second": 2.536876150584212, "min_margin_second": 0.4019126892089844, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 101, "latency_ms_ocr": 1081, "latency_ms_second": 139, "total_latency_ms": 1327, "total_latency_s": 1.327, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.960645914077759], "entropies_second": [5.103631973266602], "final_normalized_entropy": 0.7505048616812983, "sequence_confidence_first": 0.2901890807674716, "sequence_confidence_second": 0.3819816612265669, "sequence_confidence_final": 0.2901890807674716, "token_confidences_first": [0.29321157932281494, 0.2871977388858795], "token_confidences_second": [0.17137481272220612, 0.8514086008071899], "final_mean_entropy": 3.960645914077759, "final_min_margin": 1.0312938690185547, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9990740740740741, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" 3  P054511107 20051  2005-20061 2005-20062 2006-20072 2006-20071 2007-20082  2007-20081  113              2 C 2      4 2 3       2008-10-31  ISDNATM 1          IIII            85.8       vc++                3.5                         2 2 4 2 2 2 4 67 71 76 64 73 82 82        3 71.9 C  1 1 71 70 88 94 3.5 1 3     4 3 62 84        91 3 88 4 4 4 3.5 4 1.0 4    3.5 75.5 75.8 73 88.2 95.8 92.8 92.4 86.6 88.4    3 2 1 2 3.5 2      4 4 2 5 72 83.6 76.9 86 82 75.7 84 76.8 95 78       4 2 2 1 3 3.5 4 3 1 69.8 87.4 81 63 86.6 60 74 70      2 2 2 80.4 81.2 86.8 1.0 73 4 4 1 2 3.5 3.5 90.2 84.4 93.2 79 88 93.8  "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 3.790255069732666, "normalized_entropy_first": 0.41962676449575287, "min_margin_first": 1.0954761505126953, "mean_entropy_second": 3.79331374168396, "normalized_entropy_second": 0.42452955693948746, "min_margin_second": 1.0796289443969727, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 85, "latency_ms_ocr": 977, "latency_ms_second": 200, "total_latency_ms": 1264, "total_latency_s": 1.264, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.790255069732666], "entropies_second": [3.79331374168396], "final_normalized_entropy": 0.41962676449575287, "sequence_confidence_first": 0.31443559116709746, "sequence_confidence_second": 0.555781258335163, "sequence_confidence_final": 0.31443559116709746, "token_confidences_first": [0.325901061296463, 0.3033734858036041], "token_confidences_second": [0.30929532647132874, 0.9986985921859741], "final_mean_entropy": 3.790255069732666, "final_min_margin": 1.0954761505126953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9991680532445923, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["65 170260260260260260 250210210210210 10 TPE GP1140HDBK-UV 2600    CMS888 A17-0403-132    # PPY2600T 25020RPM ETON/QRY-7 21031703W2 SEBS503 150# 21011704002 A301A303 2017/08/07 2001705006 24030   21050 150N   4010HZ  DP170807     ##1 16020  402HZ 4218098  80.45 LL3608 4000KG 12.65 0.22 102 21010   cABoT A310 A308 7300 A705  A209       33 22 0.158 0.158 0.158 0.158 DV 0.949 11   2017030"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.642213857422272, "normalized_entropy_first": -1.528265243969124, "min_margin_first": 0.47424983978271484, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 217, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 223, "total_latency_s": 0.223, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.152019500732422, 3.755093574523926, 1.534862756729126, 2.7423112392425537, 3.6460788249969482, 0.0229172483086586], "entropies_second": null, "final_normalized_entropy": -1.528265243969124, "sequence_confidence_first": 0.46374936853406107, "sequence_confidence_second": null, "sequence_confidence_final": 0.46374936853406107, "token_confidences_first": [0.30763599276542664, 0.1993434727191925, 0.7654937505722046, 0.5312293767929077, 0.4147534668445587, 0.9974945783615112, 0.44711562991142273], "token_confidences_second": null, "final_mean_entropy": 2.642213857422272, "final_min_margin": 0.47424983978271484, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9777777777777777, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["   #  1131-17-   112 21001463701052501998  2017090600001 9121010279315333XQ 91210106734642379G 06135001040003465   201796  024-23856410 024-23214972 024-82711347 PC6-02 PC8-02  APA6 APY12 APA8         11 XHL                            1 2 3 4 5  20 20 50 50 50 3.90 2.20 2.20 11.80 10.50  861.00 195.00 110.00 110.00 236.00 210.00                 30%"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 4.21862268447876, "normalized_entropy_first": 1.2005270335861575, "min_margin_first": 0.8316879272460938, "mean_entropy_second": 1.7916522026062012, "normalized_entropy_second": -2.6574723126044337, "min_margin_second": 1.201970100402832, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 91, "latency_ms_ocr": 870, "latency_ms_second": 173, "total_latency_ms": 1137, "total_latency_s": 1.137, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.21862268447876], "entropies_second": [1.7916522026062012], "final_normalized_entropy": -2.6574723126044337, "sequence_confidence_first": 0.22935800930877392, "sequence_confidence_second": 0.7941568445479416, "sequence_confidence_final": 0.7941568445479416, "token_confidences_first": [0.2548730671405792, 0.20639723539352417], "token_confidences_second": [0.6311376094818115, 0.9992830157279968], "final_mean_entropy": 1.7916522026062012, "final_min_margin": 1.201970100402832, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9986684420772304, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["taitter,com/askbestdenk I bestdenki,com.sg book,com/Bestsg Join us on Please come again THANK YOU 81.06 1,239.00 7% ---GST 1,239.00 1,239.00 OCBC24MTHS-0 Total$ 1,239.00 1 1,239.00 LENOVO520S-80X2006SSS 2912199 NOTEBOOK Amount Qty Price Item No SALESPERSON CODE,7783LENOYO(BDS) Slip:2000000629 Date:03/09/175:53 Trans:720105766 Staff:3333 Opening Hrs:12:00:PM TO9:00:00PM GST REG NO.:M2-0053813-7 SAMSUNG MOB/TPLINK/GARMIN-6440-4188 MICROSOFT-6732-8122 LENOVO-6440-4188 ACER-6659-9626 DELL/HP-6276-6636 ASUS-6835-2855 COMEX SHOW2017 BEST DENKI(S)PTE LTD TAX INVOICE"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.58441820461303, "normalized_entropy_first": -1.4952633291179906, "min_margin_first": 0.43865299224853516, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 213, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 217, "total_latency_s": 0.217, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.490111827850342, 4.2381792068481445, 1.6035528182983398, 2.2914066314697266, 2.8698606491088867, 0.013398094102740288], "entropies_second": null, "final_normalized_entropy": -1.4952633291179906, "sequence_confidence_first": 0.4698426515764731, "sequence_confidence_second": null, "sequence_confidence_final": 0.4698426515764731, "token_confidences_first": [0.20022983849048615, 0.23011988401412964, 0.7184788584709167, 0.6276141405105591, 0.5089194774627686, 0.9986043572425842, 0.47866854071617126], "token_confidences_second": null, "final_mean_entropy": 2.58441820461303, "final_min_margin": 0.43865299224853516, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9646017699115044, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["20   3  Approved By  Checked By Date/2014-12-16 Prepared By/  Broadway Precision(Shenzhen)Company Limited Doc.Name/ Product Inspection Instruction  Molding Inspection Instruction  Part Name/  Front she11 Material name/ 3-ENC-RNGRP318-23REV2 3-ENC-RNGRP318-21 Part No./ Kingstec Customer/ Model/ GPS  Error Type CR MIN MAJ PCEXL1414TNA8A005T    Product Photo Transparent Color/ 7 Revision:7 QCI-K004-00102  Dec.No. Page2of6  Method Inspection  part Visual/Assembly           Visual inspection Visual inspection Visual inspection Visual inspection Visual inspection Visual inspection Visual inspection Visual inspection Visual inspection Visual inspection   Respond. Revised Date RoHS Product Form No.BWSZ-0126/R06/2013-12-02 4 3 2 1 NO. Inspection Cautions   AQL  Packing refer to\"PM\"  RoHS Test  Assembly  Key Visual  Sample Plan ---- Process Flow:Injection-Painting-printing-Packing-Delivery  1y Assemb  Visual  Marks  Detail to below page & Reference&Trace problem  2.ALL workers must wear gloves when take this product.  1.Header sample is put on the machine, AQL=(0.65)/(1.0)  OQC/IPQC:/LOT OQC/AQL:(0.65)(1.0)/LOT IPQC:11OQC:LOT/ IPQC:First Article once.once every shift OQC:LOT/time IPQC&FQC:4H/11 OQC:AQL=(0.65)/(1.0)/LOT IPQC:1/2H2 OQC:AQL=MAJ(0.65)/MIN:1.0)/LOT IPQC:ltime/2H,check twice for full cavities  4.:90+ 45 3.:5 2.:400MM-500MM (AR813A); 1.:800 1200LUX :  4.Visual angle:9045 3.Vision retention time:five second; 2.Vision distance:400MM-500MM of light(AR813A digital luminometer); 1.Light intensity:800-1200LUX(LUX)range Visual check based on below 4 points::  Refer to page 5.  10.Produce date must adjust by monthly and correct.   9.The edge of nner frame can not have flash,bump mark,shrinkage,roughness.  8.Insert part can not higher than the plane of frame.  7.Gate mark can not have roughness,the surrounding can not deformation  6.The screw position can not have crack,block,short shot and slanting. / flash, deformation,short-shot,deformation,over shot and stick mould. 5.Frame  and clutch can not have bump mark,white mark,  spot, contamination mark,gas mark and erack. 4.The position of laser number can not have serach, wipe mark, blnck  / part line,shrinkage must refer to master sauple. 3. Surface can not have foreign mark,scratch,bump mark, scuffing mark,   2.The color of product refer to master sample.   1.The structure of product refer to master sample.  Checklist&Specification"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 4.7126359939575195, "normalized_entropy_first": 1.8946070528375172, "min_margin_first": 0.7718095779418945, "mean_entropy_second": 1.3306801319122314, "normalized_entropy_second": -3.1539776921676057, "min_margin_second": 1.4478120803833008, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 104, "latency_ms_ocr": 3656, "latency_ms_second": 267, "total_latency_ms": 4033, "total_latency_s": 4.033, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.7126359939575195], "entropies_second": [1.3306801319122314], "final_normalized_entropy": -3.1539776921676057, "sequence_confidence_first": 0.17860730995347016, "sequence_confidence_second": 0.8383199336464265, "sequence_confidence_final": 0.8383199336464265, "token_confidences_first": [0.2035134881734848, 0.1567491739988327], "token_confidences_second": [0.7139028310775757, 0.984420120716095], "final_mean_entropy": 1.3306801319122314, "final_min_margin": 1.4478120803833008, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.998991935483871, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["11.91 20151112  2035.07.15        14.9   2015.07.15"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.480209827423096, "normalized_entropy_first": 1.2281005394494677, "min_margin_first": 1.1224517822265625, "mean_entropy_second": 4.81268310546875, "normalized_entropy_second": 1.6768819855356354, "min_margin_second": 0.5836830139160156, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 94, "latency_ms_ocr": 147, "latency_ms_second": 103, "total_latency_ms": 347, "total_latency_s": 0.347, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.480209827423096], "entropies_second": [4.81268310546875], "final_normalized_entropy": 1.2281005394494677, "sequence_confidence_first": 0.1928762317333472, "sequence_confidence_second": 0.42543506386165836, "sequence_confidence_final": 0.1928762317333472, "token_confidences_first": [0.22719000279903412, 0.16374506056308746], "token_confidences_second": [0.1828809529542923, 0.9896875023841858], "final_mean_entropy": 4.480209827423096, "final_min_margin": 1.1224517822265625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["   131001550112 31011213336588X E0510316  00004589    11213336588X 00004589    1   : : 2000021729 127.16 92.84 2.89 2016  : 2.11 220 : 44 44 44  0    04   "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.498830392025411, "normalized_entropy_first": -1.5419164544003432, "min_margin_first": 0.07045745849609375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 221, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 227, "total_latency_s": 0.227, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.124935150146484, 4.073308944702148, 1.5115125179290771, 2.4677348136901855, 2.799276828765869, 0.016214096918702126], "entropies_second": null, "final_normalized_entropy": -1.5419164544003432, "sequence_confidence_first": 0.44261157230943116, "sequence_confidence_second": null, "sequence_confidence_final": 0.44261157230943116, "token_confidences_first": [0.19761605560779572, 0.17484088242053986, 0.761294960975647, 0.5613076686859131, 0.5332793593406677, 0.9981756210327148, 0.42342692613601685], "token_confidences_second": null, "final_mean_entropy": 2.498830392025411, "final_min_margin": 0.07045745849609375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9809160305343512, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1366242-43 7.5-9.5// 200 cushmanwakefield.cn 52/11 71015776 500 1000Iphone7 500P9  5001.75 5001.5 311.4844 +862122080088 10002 61 2.75-31  2.82-4  1093  35// 200 31788 VRV      5000           1500/      3-31  AN   500   WAKEFIELD CUSHMAN& Yan'an Elevaloe Roed"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a flyer for an event in china", "used_ocr": false, "answer_first": "yes this is a flyer for an event in china", "answer_second": null, "raw_answer": "yes this is a flyer for an event in china", "raw_answer_first": "yes this is a flyer for an event in china", "raw_answer_second": null, "mean_entropy_first": 2.561152254541715, "normalized_entropy_first": -1.236500782066844, "min_margin_first": 0.09718990325927734, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 338, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 340, "total_latency_s": 0.34, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.164383888244629, 5.007250785827637, 1.4719741344451904, 2.5465657711029053, 4.625563621520996, 0.049261271953582764, 2.0844082832336426, 3.5567574501037598, 3.1662211418151855, 2.3556270599365234, 1.372589111328125, 0.3332245349884033], "entropies_second": null, "final_normalized_entropy": -1.236500782066844, "sequence_confidence_first": 0.42174965264710806, "sequence_confidence_second": null, "sequence_confidence_final": 0.42174965264710806, "token_confidences_first": [0.2723066806793213, 0.13179627060890198, 0.7954413294792175, 0.4473569393157959, 0.08672963827848434, 0.9948112964630127, 0.517366349697113, 0.3197670876979828, 0.30924710631370544, 0.424728125333786, 0.7390475869178772, 0.9210888147354126, 0.8195152282714844], "token_confidences_second": null, "final_mean_entropy": 2.561152254541715, "final_min_margin": 0.09718990325927734, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9647887323943662, "wer": 0.9836065573770492, "precision": 0.1, "recall": 0.01639344262295082, "f1": 0.028169014084507043, "rouge_l": 0.028169014084507043, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["-8><1->4/78<773390+55725<8< 860>++/<9-97>5*+261310-3*16 32>298+9*500<89739/7123+/>+ 3<46>2011>9+3190133<9+897*>  91520102750155271C 91520102683959121G   0851-85751917 65235443173959422449  5200171320 130012010200053533    91520102750155271C      20170901 08163692  2900.01 3219.00 201.35135135  08163692 99.099099099 85.585585586 34.684684685 39.459459459 318.99   5200171320          1027.03                    No          110.74 54.50 19.08 21.70 112.97    11% 11% 11% 11% 11% 1006.76 495.50 173.42 197.30   5 5 5 5 12      250 250 125 125 500 2016675 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": false, "answer_first": "yes", "answer_second": null, "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": null, "mean_entropy_first": 3.8628978729248047, "normalized_entropy_first": 0.5134252295173698, "min_margin_first": 0.7406692504882812, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 98, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 101, "total_latency_s": 0.101, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8628978729248047], "entropies_second": null, "final_normalized_entropy": 0.5134252295173698, "sequence_confidence_first": 0.2445082616118169, "sequence_confidence_second": null, "sequence_confidence_final": 0.2445082616118169, "token_confidences_first": [0.2535049021244049, 0.2358309030532837], "token_confidences_second": null, "final_mean_entropy": 3.8628978729248047, "final_min_margin": 0.7406692504882812, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["### ####SDS4/# #####///// ######/  # 240532-8388-9090<> MITSUBISHI GAS CHEMICAL COMPANY,INC. ## #/## Proper shipping nameCORROSIVE LIQUIDTOX1CN.O.S. ### ## 97% ###2-5-2 (Glycidy1 MethacrylateGMA)  #  +81-3-3283-4788 UN2922 MEHQ100 GG70326 100-8324  MGC INHIBITOR  LOT No. 200 UNNo. 16.12 NET kg #### # ##// ##"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.349887371063232, "normalized_entropy_first": 1.1058791626147964, "min_margin_first": 0.42740726470947266, "mean_entropy_second": 1.585114598274231, "normalized_entropy_second": -2.4429668518261347, "min_margin_second": 2.1781482696533203, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 86, "latency_ms_ocr": 1033, "latency_ms_second": 127, "total_latency_ms": 1248, "total_latency_s": 1.248, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.349887371063232], "entropies_second": [1.585114598274231], "final_normalized_entropy": -2.4429668518261347, "sequence_confidence_first": 0.17854782468216363, "sequence_confidence_second": 0.8646501666973017, "sequence_confidence_final": 0.8646501666973017, "token_confidences_first": [0.19134081900119781, 0.16661016643047333], "token_confidences_second": [0.7479008436203003, 0.9996243715286255], "final_mean_entropy": 1.585114598274231, "final_min_margin": 2.1781482696533203, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9971264367816092, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["ROTO INJECT FLUID2,000 GA11-315Kw  () 4,000/6,000/8,000  / (2)   (1)  (2)   Atlas Copco    16,000    8,000 2,000 2,000        D C B A I           T SPM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 (1) (2)4,000GA5/7/106,000GA11GA758,000GA90GA250  3 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.8923017978668213, "normalized_entropy_first": 0.405899090907097, "min_margin_first": 1.2961015701293945, "mean_entropy_second": 3.7167491912841797, "normalized_entropy_second": 0.18168656938058614, "min_margin_second": 1.4992485046386719, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 95, "latency_ms_ocr": 829, "latency_ms_second": 171, "total_latency_ms": 1099, "total_latency_s": 1.099, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8923017978668213], "entropies_second": [3.7167491912841797], "final_normalized_entropy": 0.18168656938058614, "sequence_confidence_first": 0.2593007517582053, "sequence_confidence_second": 0.6015795323765957, "sequence_confidence_final": 0.6015795323765957, "token_confidences_first": [0.33538517355918884, 0.20047660171985626], "token_confidences_second": [0.38516390323638916, 0.9395946264266968], "final_mean_entropy": 3.7167491912841797, "final_min_margin": 1.4992485046386719, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9960474308300395, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["2. 3. 7.30, 1.  6.  5. 4. ()  SP4401121110000421 28     140520152023398          2014516 2017515 *9401004211* 2014516  "], "experiment": "entropy_routing_default", "routed": {"answer": "a certificate of authenticity for a product made by a company called 'shanghai yi xing'", "used_ocr": true, "answer_first": "yes", "answer_second": "a certificate of authenticity for a product made by a company called 'shanghai yi xing'", "raw_answer": "a certificate of authenticity for a product made by a company called 'shanghai yi xing'", "raw_answer_first": "yes", "raw_answer_second": "a certificate of authenticity for a product made by a company called 'shanghai yi xing'", "mean_entropy_first": 3.9919729232788086, "normalized_entropy_first": 0.5150283554423245, "min_margin_first": 0.08258056640625, "mean_entropy_second": 3.6368828256699173, "normalized_entropy_second": 0.04087213832352715, "min_margin_second": 0.06342411041259766, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 100, "latency_ms_ocr": 2067, "latency_ms_second": 644, "total_latency_ms": 2816, "total_latency_s": 2.816, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.9919729232788086], "entropies_second": [4.130358695983887, 4.1510515213012695, 2.934359550476074, 3.8223347663879395, 0.06251663714647293, 3.0344502925872803, 3.7272305488586426, 4.836527347564697, 3.3408901691436768, 0.7561333775520325, 5.4946489334106445, 1.6407110691070557, 1.9208183288574219, 5.7973785400390625, 6.490452289581299, 3.8663721084594727, 1.6541814804077148, 6.1269731521606445, 4.110105991363525, 4.767281532287598, 2.0956878662109375, 5.25095796585083], "final_normalized_entropy": 0.04087213832352715, "sequence_confidence_first": 0.22549413467075588, "sequence_confidence_second": 0.226782778753233, "sequence_confidence_final": 0.226782778753233, "token_confidences_first": [0.17372341454029083, 0.2926928699016571], "token_confidences_second": [0.22163720428943634, 0.2009379267692566, 0.20097079873085022, 0.3720477521419525, 0.9947751760482788, 0.2147032767534256, 0.2808052897453308, 0.2612127363681793, 0.22224698960781097, 0.716294527053833, 0.06744824349880219, 0.7611063122749329, 0.4881003499031067, 0.107611283659935, 0.03093554452061653, 0.21980462968349457, 0.7632514238357544, 0.06737124919891357, 0.1289970725774765, 0.06632619351148605, 0.35215437412261963, 0.1369343250989914, 0.4674924612045288], "final_mean_entropy": 3.6368828256699173, "final_min_margin": 0.06342411041259766, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9691358024691358, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["16.65  550.49             "], "experiment": "entropy_routing_default", "routed": {"answer": "erka is a company that makes electronic devices", "used_ocr": true, "answer_first": "yes", "answer_second": "erka is a company that makes electronic devices", "raw_answer": "erka is a company that makes electronic devices", "raw_answer_first": "yes", "raw_answer_second": "erka is a company that makes electronic devices", "mean_entropy_first": 4.7082839012146, "normalized_entropy_first": 1.4773715024923981, "min_margin_first": 0.23856353759765625, "mean_entropy_second": 3.6937359306547375, "normalized_entropy_second": 0.06792250352094131, "min_margin_second": 0.04176139831542969, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 91, "latency_ms_ocr": 231, "latency_ms_second": 285, "total_latency_ms": 610, "total_latency_s": 0.61, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.7082839012146], "entropies_second": [4.9317216873168945, 1.6213442087173462, 2.926274299621582, 3.8687565326690674, 4.503694534301758, 2.4760587215423584, 3.6961865425109863, 5.715566635131836, 3.5040202140808105], "final_normalized_entropy": 0.06792250352094131, "sequence_confidence_first": 0.21496363285022824, "sequence_confidence_second": 0.2324180119766447, "sequence_confidence_final": 0.2324180119766447, "token_confidences_first": [0.1368265450000763, 0.33772221207618713], "token_confidences_second": [0.10274594277143478, 0.7183206677436829, 0.31678125262260437, 0.17881090939044952, 0.22294846177101135, 0.32133743166923523, 0.2331703156232834, 0.0609629824757576, 0.20607924461364746, 0.524229884147644], "final_mean_entropy": 3.6937359306547375, "final_min_margin": 0.04176139831542969, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9496402877697842, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["4015TGDI 8      DAE  FDT-XC-2017-374    DAED145336S1   DAEBCG033     4G15TGDI   2017.8.22 VA/VE \\   2017.11.30        1 /                  # 2017.7.28 2017.7.28 2017.7.28"], "experiment": "entropy_routing_default", "routed": {"answer": "chinese document with english writing on it", "used_ocr": false, "answer_first": "chinese document with english writing on it", "answer_second": null, "raw_answer": "chinese document with english writing on it", "raw_answer_first": "chinese document with english writing on it", "raw_answer_second": null, "mean_entropy_first": 2.2327530591024294, "normalized_entropy_first": -2.0145648522696358, "min_margin_first": 0.14577484130859375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 268, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 269, "total_latency_s": 0.269, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.614590644836426, 0.31181544065475464, 3.7942521572113037, 2.46457576751709, 3.6677680015563965, 0.034394390881061554, 2.847411632537842, 1.613865613937378, 0.7461038827896118], "entropies_second": null, "final_normalized_entropy": -2.0145648522696358, "sequence_confidence_first": 0.44812034833490944, "sequence_confidence_second": null, "sequence_confidence_final": 0.44812034833490944, "token_confidences_first": [0.14525891840457916, 0.9316249489784241, 0.19522269070148468, 0.3464393615722656, 0.22546504437923431, 0.9967989921569824, 0.3760387599468231, 0.5385691523551941, 0.8449864387512207, 0.927672266960144], "token_confidences_second": null, "final_mean_entropy": 2.2327530591024294, "final_min_margin": 0.14577484130859375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9723247232472325, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["6  6      5|1|2012  ! !   "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a letter", "used_ocr": false, "answer_first": "yes this is a letter", "answer_second": null, "raw_answer": "yes this is a letter", "raw_answer_first": "yes this is a letter", "raw_answer_second": null, "mean_entropy_first": 3.371658277511597, "normalized_entropy_first": -0.2685539507532444, "min_margin_first": 0.29550743103027344, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 182, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 183, "total_latency_s": 0.183, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.4197282791137695, 4.364567279815674, 1.5598461627960205, 2.6464128494262695, 3.86773681640625], "entropies_second": null, "final_normalized_entropy": -0.2685539507532444, "sequence_confidence_first": 0.2972905545875036, "sequence_confidence_second": null, "sequence_confidence_final": 0.2972905545875036, "token_confidences_first": [0.1692061871290207, 0.18509314954280853, 0.7486076951026917, 0.45729613304138184, 0.32350024580955505, 0.1990460902452469], "token_confidences_second": null, "final_mean_entropy": 3.371658277511597, "final_min_margin": 0.29550743103027344, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9806763285024155, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["  20179  1    2017830      8."], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": false, "answer_first": "yes", "answer_second": null, "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": null, "mean_entropy_first": 3.6834590435028076, "normalized_entropy_first": 0.13241044637730442, "min_margin_first": 1.095515251159668, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 100, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 105, "total_latency_s": 0.105, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6834590435028076], "entropies_second": null, "final_normalized_entropy": 0.13241044637730442, "sequence_confidence_first": 0.25072154761051224, "sequence_confidence_second": null, "sequence_confidence_final": 0.25072154761051224, "token_confidences_first": [0.31950753927230835, 0.19674432277679443], "token_confidences_second": null, "final_mean_entropy": 3.6834590435028076, "final_min_margin": 1.095515251159668, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["9:00-10:00a.m  IFS L506 +/ +/ + +/ +/ * 91-105 B A A B *94   33 33 29 22 Doree Brioche    25"], "experiment": "entropy_routing_default", "routed": {"answer": "1000 yuan", "used_ocr": false, "answer_first": "1000 yuan", "answer_second": null, "raw_answer": "1000 yuan", "raw_answer_first": "1000 yuan", "raw_answer_second": null, "mean_entropy_first": 3.5767610924584523, "normalized_entropy_first": -0.01370344386816349, "min_margin_first": 0.14295482635498047, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 222, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 223, "total_latency_s": 0.223, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.748015880584717, 2.1880407333374023, 2.829578161239624, 4.3680419921875, 4.560266971588135, 5.277364730834961, 1.0660191774368286], "entropies_second": null, "final_normalized_entropy": -0.01370344386816349, "sequence_confidence_first": 0.22410873662924322, "sequence_confidence_second": null, "sequence_confidence_final": 0.22410873662924322, "token_confidences_first": [0.08186688274145126, 0.2852051258087158, 0.3164447844028473, 0.21248379349708557, 0.16599363088607788, 0.11222310364246368, 0.5667626261711121, 0.3838893473148346], "token_confidences_second": null, "final_mean_entropy": 3.5767610924584523, "final_min_margin": 0.14295482635498047, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9742489270386266, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["   522       500 978:00-12:00         "], "experiment": "entropy_routing_default", "routed": {"answer": "yes, chinese writing on paper", "used_ocr": false, "answer_first": "yes, chinese writing on paper", "answer_second": null, "raw_answer": "yes, chinese writing on paper", "raw_answer_first": "yes, chinese writing on paper", "raw_answer_second": null, "mean_entropy_first": 2.892455292599542, "normalized_entropy_first": -0.9541011977079894, "min_margin_first": 0.022649765014648438, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 224, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 224, "total_latency_s": 0.224, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.00633430480957, 4.285914421081543, 4.591612815856934, 0.1550067961215973, 3.2205891609191895, 2.281524896621704, 1.7062046527862549], "entropies_second": null, "final_normalized_entropy": -0.9541011977079894, "sequence_confidence_first": 0.3167421179643912, "sequence_confidence_second": null, "sequence_confidence_final": 0.3167421179643912, "token_confidences_first": [0.18924202024936676, 0.16407570242881775, 0.1276906281709671, 0.9742954969406128, 0.24519936740398407, 0.34229981899261475, 0.5319671034812927, 0.5873867869377136], "token_confidences_second": null, "final_mean_entropy": 2.892455292599542, "final_min_margin": 0.022649765014648438, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9891891891891892, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["// ////    2GDP6-7% 5 3  4 VEFAC : The21th Vietnam International Fashion Fair 2017 21  +  5-20 ///  !  20171222-26 ? 2     3      1  120161815%   //"], "experiment": "entropy_routing_default", "routed": {"answer": "2017 international conference on biotechnology and agriculture", "used_ocr": false, "answer_first": "2017 international conference on biotechnology and agriculture", "answer_second": null, "raw_answer": "2017 international conference on biotechnology and agriculture", "raw_answer_first": "2017 international conference on biotechnology and agriculture", "raw_answer_second": null, "mean_entropy_first": 2.471954301993052, "normalized_entropy_first": -1.4501543986442034, "min_margin_first": 0.0035238265991210938, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 401, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 402, "total_latency_s": 0.402, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.1413679122924805, 2.0600314140319824, 1.2796626091003418, 0.4042421579360962, 2.029465436935425, 4.901945114135742, 5.900259971618652, 1.8438867330551147, 5.704798698425293, 1.454063057899475, 0.3486957252025604, 0.10315141081809998, 2.7107133865356445, 3.5791923999786377, 0.6178385019302368], "entropies_second": null, "final_normalized_entropy": -1.4501543986442034, "sequence_confidence_first": 0.3537835709008209, "sequence_confidence_second": null, "sequence_confidence_final": 0.3537835709008209, "token_confidences_first": [0.1860428750514984, 0.3158746659755707, 0.7370633482933044, 0.9408764839172363, 0.23239834606647491, 0.21938063204288483, 0.05386345461010933, 0.6770685911178589, 0.05203527957201004, 0.5617958903312683, 0.9173927307128906, 0.986057460308075, 0.5254853367805481, 0.19671857357025146, 0.7939890623092651, 0.3662053346633911], "token_confidences_second": null, "final_mean_entropy": 2.471954301993052, "final_min_margin": 0.0035238265991210938, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9779735682819384, "wer": 0.9782608695652174, "precision": 0.14285714285714285, "recall": 0.021739130434782608, "f1": 0.03773584905660378, "rouge_l": 0.03773584905660378, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [":   1,3  2019-08-09 : A01-XS-20190809000 : :  : () : ()  :       No   106.05 7.07 6922507820414 15 800g*15   91.40 4.57 20 6922507800706 500g*20 2   91.40 4.57 20 500g*20 3  78.60 3.93 20 500g*20  4 6924331681063 () 78.60 3.93 20  500g*20 500g 6924331681032 5 78.60 20  3.93 500g*20 () 6924331681056 6 102.96  24 500g*24 4.29  6918962000348 7  108.75 900g*15 15 7.25  6918962007644 8  1000g*15 15 93.75  6.25 6918962006647 9  1000g*15 15  127.80 6922507800614 8.52 10 15 6922507800218 8.75 131.25 11 6922507824061  15 6.85 102.75 12 6918962005862   750g*15 15 13 5.50 82.50 : : : :   1000g*15 1000g*15 () 6922507800676 1"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.5260109193623066, "normalized_entropy_first": -1.1786345694618927, "min_margin_first": 0.1022176742553711, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 202, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 204, "total_latency_s": 0.204, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.000458240509033, 3.8969779014587402, 1.481658935546875, 2.512423515319824, 3.2454464435577393, 0.019100479781627655], "entropies_second": null, "final_normalized_entropy": -1.1786345694618927, "sequence_confidence_first": 0.4585942317451237, "sequence_confidence_second": null, "sequence_confidence_final": 0.4585942317451237, "token_confidences_first": [0.2919928729534149, 0.1766594797372818, 0.7761003375053406, 0.5680626034736633, 0.48006391525268555, 0.9978610873222351, 0.39156845211982727], "token_confidences_second": null, "final_mean_entropy": 2.5260109193623066, "final_min_margin": 0.1022176742553711, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9941520467836257, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["   /1:1 : /: [Y00006] [sq1001] [1021] :PI2019100900020 :    :: :2019-10-2620:52:04 :sq1001          4.75 4.7500  1.00 820 6922165900855 6922165900855 14.25 4.7500 3.00  1*12 820ml 6922165900138 6922165900138 4.75 4.7500  1.00 820 6922165901913 Y05688 23.75 5.00 : : : :     [sq1001] 2019-10-09 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.7136106491088867, "normalized_entropy_first": 0.5121055404739613, "min_margin_first": 1.1832828521728516, "mean_entropy_second": 4.233293533325195, "normalized_entropy_second": 1.194680545074328, "min_margin_second": 0.8587894439697266, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 84, "latency_ms_ocr": 437, "latency_ms_second": 175, "total_latency_ms": 699, "total_latency_s": 0.699, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7136106491088867], "entropies_second": [4.233293533325195], "final_normalized_entropy": 0.5121055404739613, "sequence_confidence_first": 0.24787014302552235, "sequence_confidence_second": 0.4951255884243034, "sequence_confidence_final": 0.24787014302552235, "token_confidences_first": [0.35200193524360657, 0.1745433807373047], "token_confidences_second": [0.24539241194725037, 0.9990094900131226], "final_mean_entropy": 3.7136106491088867, "final_min_margin": 1.1832828521728516, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9957264957264957, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [": 2019-08-14 :  : : : :         600ml 1 1*15 48 48 1 2 600ml 1*15 2 48 96 3 600ml 1*15 48 48 1 4 600ml 1*15 2 48 96 5 600ml 1*24 3   0 0 600ml 6 1*24  0 0 : : 10 :288 ,15968811172  "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.961301803588867, "normalized_entropy_first": 0.8180946743495565, "min_margin_first": 0.9521656036376953, "mean_entropy_second": 4.379706382751465, "normalized_entropy_second": 1.3899231812453676, "min_margin_second": 1.2038793563842773, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 91, "latency_ms_ocr": 282, "latency_ms_second": 126, "total_latency_ms": 501, "total_latency_s": 0.501, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.961301803588867], "entropies_second": [4.379706382751465], "final_normalized_entropy": 1.3899231812453676, "sequence_confidence_first": 0.22336472862264026, "sequence_confidence_second": 0.4893885601918377, "sequence_confidence_final": 0.4893885601918377, "token_confidences_first": [0.2804655134677887, 0.17788925766944885], "token_confidences_second": [0.27431946992874146, 0.8730738759040833], "final_mean_entropy": 4.379706382751465, "final_min_margin": 1.2038793563842773, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["#: : :2019-08-29 N0.GR0020190829 00271 : : :         6948880060018 119.88 3.33 338ml 1*12  36.00 50.80 10.80 6.00  6948880060247 200ml 179.88 42.00 : :0  () :   :"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.850877523422241, "normalized_entropy_first": 0.5973672766817651, "min_margin_first": 1.3940696716308594, "mean_entropy_second": 3.6942594051361084, "normalized_entropy_second": 0.3789320959401832, "min_margin_second": 1.2451086044311523, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 90, "latency_ms_ocr": 359, "latency_ms_second": 133, "total_latency_ms": 584, "total_latency_s": 0.584, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.850877523422241], "entropies_second": [3.6942594051361084], "final_normalized_entropy": 0.3789320959401832, "sequence_confidence_first": 0.24005449792297362, "sequence_confidence_second": 0.5968464409566361, "sequence_confidence_final": 0.5968464409566361, "token_confidences_first": [0.32482171058654785, 0.1774085909128189], "token_confidences_second": [0.35687246918678284, 0.9981876015663147], "final_mean_entropy": 3.6942594051361084, "final_min_margin": 1.2451086044311523, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["  : 001- : 2019-10-23 1/1 : JH001201910180000010  : 157-() : : 2019-10-18 :        6251 03020160 6906151601094 540000 4.00 216.00  4.00 216.00 : :  :"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.621228919674953, "normalized_entropy_first": -1.2194782112953906, "min_margin_first": 0.3179187774658203, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 192, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 193, "total_latency_s": 0.193, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.003480434417725, 4.443634033203125, 1.4910458326339722, 2.6490957736968994, 3.1076502799987793, 0.03246716409921646], "entropies_second": null, "final_normalized_entropy": -1.2194782112953906, "sequence_confidence_first": 0.4201737470315015, "sequence_confidence_second": null, "sequence_confidence_final": 0.4201737470315015, "token_confidences_first": [0.23446662724018097, 0.16310417652130127, 0.7830840945243835, 0.48694589734077454, 0.4614507555961609, 0.9962621331214905, 0.3448801338672638], "token_confidences_second": null, "final_mean_entropy": 2.621228919674953, "final_min_margin": 0.3179187774658203, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9799196787148594, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" SO001909050947  176 0001   2019-09-05   ? #  1 2 3 4  6902022132537 6917751460042 6917751461117 6924882335514      C1 80     600g 1"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.4406757978722453, "normalized_entropy_first": -1.3359392084211492, "min_margin_first": 0.09048271179199219, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 196, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 197, "total_latency_s": 0.197, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6045336723327637, 4.524835109710693, 1.5933263301849365, 2.775500774383545, 2.1230297088623047, 0.022829191759228706], "entropies_second": null, "final_normalized_entropy": -1.3359392084211492, "sequence_confidence_first": 0.46324810361189334, "sequence_confidence_second": null, "sequence_confidence_final": 0.46324810361189334, "token_confidences_first": [0.3614591360092163, 0.15567965805530548, 0.74141925573349, 0.47980570793151855, 0.6884883642196655, 0.9973600506782532, 0.33306318521499634], "token_confidences_second": null, "final_mean_entropy": 2.4406757978722453, "final_min_margin": 0.09048271179199219, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9755102040816327, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" : : :2019-09-19 2019-10-19   002734 :           4.00  48.00 0.00  114g 12.00 6928802470361  0.00 4.00 48.00 1318  12.00 6957427660017  375.00 0.00 2.50 150.00 80g 80g 6921956703613 0.00  10.00 120.00  280 12.00 6915993304650 110.00 0.00  3.67 270g 30.00 6921956700315  1.00 7.50 90.00 200m1 12.00 200m1 6921317644135 40.00 0.00 53g 0.80 53g 50.00 6915993303028 53g 0.80 40.00 0.00 50.00 6915993303011 63 53g 0.80 0.00 53 50.00 40.00 6915993303363   0.80 40.00 0.00 6915993302212 63 50.00  6915993302236  53 50 0Q 40.00 0.00 0.80  6952492302558  40g 5000 75.00 0.00 1.50 : 528.00 0.00 1,066.00 ():  : : 1/1 : :2019-09-19 09:11:44     : : "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.4845866231868663, "normalized_entropy_first": -1.1068991060911963, "min_margin_first": 0.022622108459472656, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 202, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 203, "total_latency_s": 0.203, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.9711709022521973, 4.178882598876953, 1.615220069885254, 2.5851802825927734, 2.5351853370666504, 0.02188054844737053], "entropies_second": null, "final_normalized_entropy": -1.1068991060911963, "sequence_confidence_first": 0.46295859400055206, "sequence_confidence_second": null, "sequence_confidence_final": 0.46295859400055206, "token_confidences_first": [0.29961395263671875, 0.1667335033416748, 0.7499738931655884, 0.5321398377418518, 0.6105515956878662, 0.9975401163101196, 0.3753924071788788], "token_confidences_second": null, "final_mean_entropy": 2.4845866231868663, "final_min_margin": 0.022622108459472656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9950920245398773, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["5/   : XS-2019-10-19-312 :  () :             41 6920238012115 -120g 120g*5/ 4 87.2 21.8 4 42 6920238082019 -120g 120g/ 10 10 4.5 43 6920238011118 -120g 120g/ 10 10 4.5 45 44 6920238011156 -120g 120g/ 10 10 4.5 45 6922507827468 -900g 900g*15 10 150 5.2 46 6922507827444 -900g 6 90 5.2 900g*15 468  60 5.2 312  4 6922507827451 -900g 900g*15 47 : 4344.7  1782.2  :  : ,  780 45 45"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.582279753560821, "normalized_entropy_first": -0.8570468182462999, "min_margin_first": 0.08053970336914062, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 206, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 207, "total_latency_s": 0.207, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.03529167175293, 4.215943336486816, 1.4254037141799927, 2.673957347869873, 3.115896224975586, 0.027186226099729538], "entropies_second": null, "final_normalized_entropy": -0.8570468182462999, "sequence_confidence_first": 0.4723822646274724, "sequence_confidence_second": null, "sequence_confidence_final": 0.4723822646274724, "token_confidences_first": [0.31541523337364197, 0.17339280247688293, 0.7968811988830566, 0.5471481084823608, 0.5068865418434143, 0.9967795014381409, 0.43564528226852417], "token_confidences_second": null, "final_mean_entropy": 2.582279753560821, "final_min_margin": 0.08053970336914062, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.990909090909091, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [":   2019-10-05 :  :2019-11-04  :  :  :  :  0.00 : :  : 0001           75.00 7.50 0.00 10.00 10.00 1*20 1 6922824589148 40.00 4.00 0.00 10.00 10.00 2 6952389212427 48.00 2.40 0.00 20.00 20.00 3 6922824589506 45.00 4.50 0.00 10.00 10.00 150 4 6952389212557 100.00 5.00 0.00 20.00 20.00 5 5952389218146 80.00 4.00 0.00 20.00 20.00 6 388.00 0.00 90.00 90.00 : : : : : 1/1 :  0001  10034  6952389210492 360g 150g 80g 96g 150g   : :2019-10-25 13:08:37"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt with numbers and letters in chinese characters", "used_ocr": true, "answer_first": "yes", "answer_second": "a receipt with numbers and letters in chinese characters", "raw_answer": "a receipt with numbers and letters in chinese characters", "raw_answer_first": "yes", "raw_answer_second": "a receipt with numbers and letters in chinese characters", "mean_entropy_first": 3.8856394290924072, "normalized_entropy_first": 1.0352394692580147, "min_margin_first": 0.7131433486938477, "mean_entropy_second": 2.583433840847151, "normalized_entropy_second": -0.7831438237651447, "min_margin_second": 0.20665454864501953, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 87, "latency_ms_ocr": 572, "latency_ms_second": 370, "total_latency_ms": 1032, "total_latency_s": 1.032, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8856394290924072], "entropies_second": [4.613701820373535, 2.818706750869751, 0.011021801270544529, 2.788905620574951, 3.8321902751922607, 2.308372735977173, 3.8580472469329834, 2.3433127403259277, 2.810835361480713, 0.10005594044923782, 2.932621955871582], "final_normalized_entropy": -0.7831438237651447, "sequence_confidence_first": 0.2175635192801508, "sequence_confidence_second": 0.34550695851886304, "sequence_confidence_final": 0.34550695851886304, "token_confidences_first": [0.2832663655281067, 0.16710026562213898], "token_confidences_second": [0.14422574639320374, 0.5675551891326904, 0.9987674951553345, 0.3126392066478729, 0.14705424010753632, 0.4296759068965912, 0.1973380446434021, 0.38167470693588257, 0.3439367115497589, 0.9877034425735474, 0.20443622767925262, 0.34256038069725037], "final_mean_entropy": 2.583433840847151, "final_min_margin": 0.20665454864501953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9866220735785953, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [":      9.00  6888001011348 1 9.00  6888001011447 2 9.00  3 6888001011546 14.00 4 6888001011645  5  14.00 6888001011744 6 6888001011843  14.00 7 6888001011942  18.00 8 6971969790155  16.00 9 6971969790162  16.00 10 6971969790179  16.00 11 6971969790117 (13000) 49.00 12 :   C4 :        ()"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.4380874447524548, "normalized_entropy_first": -1.0915642137960944, "min_margin_first": 0.21834945678710938, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 200, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 200, "total_latency_s": 0.2, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8065977096557617, 4.1891398429870605, 1.6015963554382324, 2.7392427921295166, 2.2683310508728027, 0.023616917431354523], "entropies_second": null, "final_normalized_entropy": -1.0915642137960944, "sequence_confidence_first": 0.47055721689600055, "sequence_confidence_second": null, "sequence_confidence_final": 0.47055721689600055, "token_confidences_first": [0.31042590737342834, 0.1612134724855423, 0.7516072988510132, 0.5141143798828125, 0.6693726778030396, 0.997277557849884, 0.3957245647907257], "token_confidences_second": null, "final_mean_entropy": 2.4380874447524548, "final_min_margin": 0.21834945678710938, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.988479262672811, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [": 100078] : 2019-08-1217:08:05 : : 2019-08-12 : : :          136.00 17.00  6971846090071 090071 1 136.00 8.00 : 11  :PI011908120362 : 2019-08-12 17:07:43 :1 : : : :  8.00 :<>  1900g"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.735013257091244, "normalized_entropy_first": -0.5650069198544144, "min_margin_first": 0.045517921447753906, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 203, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 204, "total_latency_s": 0.204, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.9373950958251953, 4.270702362060547, 1.552432656288147, 2.867399215698242, 3.76017427444458, 0.021975938230752945], "entropies_second": null, "final_normalized_entropy": -0.5650069198544144, "sequence_confidence_first": 0.4155843206247701, "sequence_confidence_second": null, "sequence_confidence_final": 0.4155843206247701, "token_confidences_first": [0.3138313591480255, 0.17424319684505463, 0.7617749571800232, 0.49466627836227417, 0.34676918387413025, 0.9974952936172485, 0.3003803789615631], "token_confidences_second": null, "final_mean_entropy": 2.735013257091244, "final_min_margin": 0.045517921447753906, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9840764331210191, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" :668 :2019-10-07 1019  : :           6934024512123 1 15,120.00   (): : : 6163409 10.1 #BT550ml/ 1*12   32,400.0 32,400.0 0.00 0.00 0.47 15,120.00 0.5333"], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt with numbers and chinese writing on it", "used_ocr": true, "answer_first": "yes", "answer_second": "a receipt with numbers and chinese writing on it", "raw_answer": "a receipt with numbers and chinese writing on it", "raw_answer_first": "yes", "raw_answer_second": "a receipt with numbers and chinese writing on it", "mean_entropy_first": 3.76981258392334, "normalized_entropy_first": 0.9690015455215027, "min_margin_first": 1.0874147415161133, "mean_entropy_second": 2.0163491448726165, "normalized_entropy_second": -1.5670797466442627, "min_margin_second": 0.19176959991455078, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 86, "latency_ms_ocr": 284, "latency_ms_second": 353, "total_latency_ms": 725, "total_latency_s": 0.725, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.76981258392334], "entropies_second": [3.6172075271606445, 2.387875556945801, 0.009783065877854824, 2.9402542114257812, 3.4412026405334473, 2.2458038330078125, 3.557358980178833, 0.1241738423705101, 1.7572585344314575, 1.7853689193725586, 0.31355348229408264], "final_normalized_entropy": -1.5670797466442627, "sequence_confidence_first": 0.2088341062111896, "sequence_confidence_second": 0.43683390124791593, "sequence_confidence_final": 0.43683390124791593, "token_confidences_first": [0.28181999921798706, 0.15475013852119446], "token_confidences_second": [0.23502320051193237, 0.5377833843231201, 0.9989835619926453, 0.2669193744659424, 0.18160155415534973, 0.4082443118095398, 0.19870436191558838, 0.9822016358375549, 0.4463978409767151, 0.6692661046981812, 0.9481269121170044, 0.34954598546028137], "final_mean_entropy": 2.0163491448726165, "final_min_margin": 0.19176959991455078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9634146341463414, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" 2019-10-14 :  :         55  30g*9*10 018  125 100g*50  453  95 95  65g*50 288  68 80g*40  105  40 () 65g*50 049  63 160g*15  032 72  72 150g*20  231 26 0.8666  30 6902890252399 45g*60  446 10  6902890234180 45g*60  021 17  10 6902890234326 45g*60  023 17  10 6902890234302 45g*60  024 27.5 5.5  6902890245247 190g*40  294 21 3  6902890228592 280g*18  33 066 11 3  6902890230632 260g*18 067  676.5 78   : : 17 7 1.7 1.7 1.7 63 40 68 125 55  5 1 1 1 1 1 1 1 XS-2019-10-14-29771 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.3057596950481334, "normalized_entropy_first": -1.2551588398028002, "min_margin_first": 0.3290376663208008, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 202, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 202, "total_latency_s": 0.202, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7952046394348145, 3.9606552124023438, 1.5970631837844849, 2.3009719848632812, 2.1617109775543213, 0.018952172249555588], "entropies_second": null, "final_normalized_entropy": -1.2551588398028002, "sequence_confidence_first": 0.4914517371038382, "sequence_confidence_second": null, "sequence_confidence_final": 0.4914517371038382, "token_confidences_first": [0.3041183650493622, 0.18924377858638763, 0.7428876757621765, 0.5968188047409058, 0.6693846583366394, 0.9978380799293518, 0.4062565565109253], "token_confidences_second": null, "final_mean_entropy": 2.3057596950481334, "final_min_margin": 0.3290376663208008, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.993431855500821, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" : XK-000-2019-08-18-34  2019-08-18 : 304.20 : --        / 31.50 31.5 90 35.00 6923304324754 50 48.60 48.6 90 54.00 6909493801047 *36 72.90 72.9 90 81.00 1 6907992822860 *35 19.80 9.9 90 11.00 2 *40 54.00 54 90 60.00 6923644266257 40 32.40 32.4 90 36.00 6931459916663 45.00 *16 45 90 50.00 6907992822921 304.20 : 8     *45 1 1 1 1 1"], "experiment": "entropy_routing_default", "routed": {"answer": "Yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "Yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 3.914579391479492, "normalized_entropy_first": 1.190846861176246, "min_margin_first": 0.32872867584228516, "mean_entropy_second": 3.2391602993011475, "normalized_entropy_second": 0.22626135100494596, "min_margin_second": 0.6958847045898438, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 85, "latency_ms_ocr": 414, "latency_ms_second": 176, "total_latency_ms": 678, "total_latency_s": 0.678, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.914579391479492], "entropies_second": [3.2391602993011475], "final_normalized_entropy": 0.22626135100494596, "sequence_confidence_first": 0.26108032590542773, "sequence_confidence_second": 0.5807911325742425, "sequence_confidence_final": 0.5807911325742425, "token_confidences_first": [0.24414470791816711, 0.27919071912765503], "token_confidences_second": [0.33749333024024963, 0.9994814991950989], "final_mean_entropy": 3.2391602993011475, "final_min_margin": 0.6958847045898438, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" : : :2019-04-12 5008        140.00 3.50   15.00 1.50 2021 10.00 6970459380210 37.50 2.50 3.80 0233 57.00 1.50  15.00 2065 6970459380067 48.00 5.00 240.00 6959999854528  3.60 602 43.20   2.80 56.00 127.00 603.70 603.70   : :  : : : 1/2   :SO001904122650  6940216415028 6971671644104 6971671644128 6928479102398 6832209530078  0231 2.5l   40.00 15.00 15.00 10.00 12.00 20.00   "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 3.5951967239379883, "normalized_entropy_first": 0.6073096104806233, "min_margin_first": 0.25261688232421875, "mean_entropy_second": 4.097248554229736, "normalized_entropy_second": 1.3145995339384073, "min_margin_second": 0.15141677856445312, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 94, "latency_ms_ocr": 506, "latency_ms_second": 205, "total_latency_ms": 808, "total_latency_s": 0.808, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.5951967239379883], "entropies_second": [4.097248554229736], "final_normalized_entropy": 0.6073096104806233, "sequence_confidence_first": 0.20481737052105486, "sequence_confidence_second": 0.3944305308271946, "sequence_confidence_final": 0.20481737052105486, "token_confidences_first": [0.2543911933898926, 0.16490411758422852], "token_confidences_second": [0.15576058626174927, 0.9988113641738892], "final_mean_entropy": 3.5951967239379883, "final_min_margin": 0.25261688232421875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9981203007518797, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" :T0170424 00015  P017042482002 :201704CP24956367CS016111016 : /  ID  () 480//480 51.60 14661492 41-074-006 / /460g/ 59.80 7382752 41-077-007 252//252 59.80 17747092 41-077-015 / "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.410938262939453, "normalized_entropy_first": 1.7554445642753718, "min_margin_first": 0.18071269989013672, "mean_entropy_second": 4.388800621032715, "normalized_entropy_second": 1.7231600506530789, "min_margin_second": 0.8935012817382812, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 89, "latency_ms_ocr": 274, "latency_ms_second": 134, "total_latency_ms": 500, "total_latency_s": 0.5, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.410938262939453], "entropies_second": [4.388800621032715], "final_normalized_entropy": 1.7231600506530789, "sequence_confidence_first": 0.17926153366184372, "sequence_confidence_second": 0.46952058593964446, "sequence_confidence_final": 0.46952058593964446, "token_confidences_first": [0.14797724783420563, 0.2171597182750702], "token_confidences_second": [0.22138595581054688, 0.9957703948020935], "final_mean_entropy": 4.388800621032715, "final_min_margin": 0.8935012817382812, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9962121212121212, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["21117 No. SS-201910020 : : : 2019-10-13        150ml150ml  5.00 6921694200139 8.80 44.00  300g 5.00 6921204802203 5.00 25.00  100g 5.00 7.00 35.00  150g 1.60 16.00 10.00 6921204896036  400g 5.00 3.80 19.00  3.80 38.00 400g 10.00 8.50 100g  5.00 1.70 6933323400025 20.00  4.00 250g 5.09 6933323400049 26.00 26.00 45g1*10  1.00 9.00  5.00 1.80 100g 6958031500034 168.00 168.00  1.00 1*40*400g 17.00 1.70 10.00  115g 6943764700012 8.00 0.80 10.00  13g13g 433.50 77.00  : : : :  18522645807 803079593"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.679306281109651, "normalized_entropy_first": -0.8713222735122426, "min_margin_first": 0.13706684112548828, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 213, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 214, "total_latency_s": 0.214, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.335792541503906, 4.146838665008545, 1.551584005355835, 2.6768760681152344, 3.3339414596557617, 0.030804947018623352], "entropies_second": null, "final_normalized_entropy": -0.8713222735122426, "sequence_confidence_first": 0.45893878209043465, "sequence_confidence_second": null, "sequence_confidence_final": 0.45893878209043465, "token_confidences_first": [0.28862881660461426, 0.1766698658466339, 0.7700920701026917, 0.5766014456748962, 0.48385095596313477, 0.9963681697845459, 0.39285412430763245], "token_confidences_second": null, "final_mean_entropy": 2.679306281109651, "final_min_margin": 0.13706684112548828, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9922360248447205, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [": : M-S20190905112658146  201909-05 #20          1.12kg 6920174754483 1*10  5 8.5 42.5  1kg+128g 1*10  6901894122004 5 8 40 600ML 600ML*24 3 6907469114665 3 14 42  6901469010158 1*24 3 12 36  6907469014200 1*60 10 2 26 12*4*6(12  6956393480025 ()8002 12 1.8 6 21.6 / 6956393481152 12*4*6(12 ()8115  12 3.1 37.2 /)  (): 114 630.50 : 3 1 : : :  ###  1 2 4 5 7  #  600ML   10 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.3154670748238764, "normalized_entropy_first": -1.293857887972164, "min_margin_first": 0.04142475128173828, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 214, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 215, "total_latency_s": 0.215, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8581368923187256, 3.9230592250823975, 1.535977840423584, 2.427382230758667, 2.130035877227783, 0.018210383132100105], "entropies_second": null, "final_normalized_entropy": -1.293857887972164, "sequence_confidence_first": 0.4698064126934851, "sequence_confidence_second": null, "sequence_confidence_final": 0.4698064126934851, "token_confidences_first": [0.24354210495948792, 0.1812361180782318, 0.7601217031478882, 0.5636005997657776, 0.6492583155632019, 0.998005211353302, 0.41229575872421265], "token_confidences_second": null, "final_mean_entropy": 2.3154670748238764, "final_min_margin": 0.04142475128173828, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9906542056074766, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["[02]  :[9001] :PI00031909222122  [10300] :[02] : :[0002] 2019-10-02 :2019-09-23 06:57:32 :2019-09-22 18:02:00 :0  :    6924137320067 0400121  6924187832657 0400128  6924187821644 0400122  6924187328544 0400127 quc8808 6903244370776 0700038 42.50 3 6947929616216 1002774 20.00  6947929617114 61.60 2400029  49.00 6348939665393 2901244 100 100g 17.15 6948939623157 3400256  6948939666154 2901373 909.27 156.00 6948939651587  :  :1/        54.50 10.90 5.00 94.40 150.12 140.00 140.00 140.00 4.38 5.60 7.00 8.34 5.90 3.50 2.50 6.16 9.80 3.43 10.00 5.00 5.00 8.00 12.00 16.00 18.00 20.00 25.00 32.00               2909785 11 10 9 8 7 6 5 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.670264720916748, "normalized_entropy_first": 0.6692220912511417, "min_margin_first": 1.394205093383789, "mean_entropy_second": 2.693429470062256, "normalized_entropy_second": -0.6324125573429752, "min_margin_second": 1.7929506301879883, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 88, "latency_ms_ocr": 699, "latency_ms_second": 205, "total_latency_ms": 995, "total_latency_s": 0.995, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.670264720916748], "entropies_second": [2.693429470062256], "final_normalized_entropy": -0.6324125573429752, "sequence_confidence_first": 0.2548269272516025, "sequence_confidence_second": 0.7407732419806158, "sequence_confidence_final": 0.7407732419806158, "token_confidences_first": [0.33993613719940186, 0.19102635979652405], "token_confidences_second": [0.552016019821167, 0.9940744042396545], "final_mean_entropy": 2.693429470062256, "final_min_margin": 1.7929506301879883, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" :Z2 :     51.00      1.70 90.00  1*30 9 6920818397373 350ml 3.00 30.00 51.00 1*30 10 6920818300588 10.00 42.00 1*100 11 6922860303630 30g 10.00 1*100 12 6922860303616 30g 23.00 2.30 10.00 1*100 33.00 6922860303692 40g 13 10.00 1*40 6922555298142 17.50 14 10.00 1*125  40g 67.50 6920761202106 15 1*20 6940486020342 375.00 16 115.00  375.00   :  30.00 5.10 4.20 3.30 1.75 5.00 13.50         "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.4587558144703507, "normalized_entropy_first": -1.0436667576836092, "min_margin_first": 0.07899093627929688, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 214, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 216, "total_latency_s": 0.216, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.6517269611358643, 4.40463924407959, 1.6920937299728394, 2.704026699066162, 2.2811508178710938, 0.018897434696555138], "entropies_second": null, "final_normalized_entropy": -1.0436667576836092, "sequence_confidence_first": 0.4581327224062951, "sequence_confidence_second": null, "sequence_confidence_final": 0.4581327224062951, "token_confidences_first": [0.35004398226737976, 0.14661839604377747, 0.7232639789581299, 0.5078457593917847, 0.6606213450431824, 0.9977943897247314, 0.34088334441185], "token_confidences_second": null, "final_mean_entropy": 2.4587558144703507, "final_min_margin": 0.07899093627929688, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9920634920634921, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" : :2019-08-08 :  XSD-2019-08-08-00001   :    6925303730574     1*15  2.00 47.00 6925303739454 94.00 1.5L 2 1*6 4.00 51.00 204.00 6925303733704  3 1*15  1.00 59.00 59.00 6925303721039 450ml 4 1*15  1.00 37.00 37.00 1L 5 1*8 5.00 0.00 0.00 6925303721398 500m1 6 1*15 2.00 0.00 0.00 : 15.00 : 18942515566 394.00  15.00    1     "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "Yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "Yes", "mean_entropy_first": 3.9274184703826904, "normalized_entropy_first": 1.0799202424425083, "min_margin_first": 1.2434253692626953, "mean_entropy_second": 4.051775932312012, "normalized_entropy_second": 1.2509739867494587, "min_margin_second": 0.34791088104248047, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 92, "latency_ms_ocr": 615, "latency_ms_second": 207, "total_latency_ms": 916, "total_latency_s": 0.916, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.9274184703826904], "entropies_second": [4.051775932312012], "final_normalized_entropy": 1.0799202424425083, "sequence_confidence_first": 0.2710829312005082, "sequence_confidence_second": 0.4276616179124799, "sequence_confidence_final": 0.2710829312005082, "token_confidences_first": [0.32314518094062805, 0.2274084836244583], "token_confidences_second": [0.18302780389785767, 0.9992714524269104], "final_mean_entropy": 3.9274184703826904, "final_min_margin": 1.2434253692626953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9977426636568849, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["  : 2019-8-1       () 6924187871083 1  150g 5 4.5 22.5 2 6921089500363  35gx2 2.7 27 3 6924187871083  150g 5 4.5 22.5 4 6903252100785  106g 2 3.25 78 36  0.33 108 6923450683163 5 1 107.5 21.5 5 20ml  6903148079987 6 36 18 2 19gx25g 1 6901668007193 7 156 13 1x12 180X6 6903244673587 8 65 4.33 1 15 268m1 6917878030630 96 9 3.2 15  6956416200319 646.5 10  2 1 10"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.622047185897827, "normalized_entropy_first": 0.5505261281753921, "min_margin_first": 1.377263069152832, "mean_entropy_second": 2.818779945373535, "normalized_entropy_second": -0.5516380604724581, "min_margin_second": 1.9541072845458984, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 90, "latency_ms_ocr": 396, "latency_ms_second": 174, "total_latency_ms": 662, "total_latency_s": 0.662, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.622047185897827], "entropies_second": [2.818779945373535], "final_normalized_entropy": -0.5516380604724581, "sequence_confidence_first": 0.27718530138800446, "sequence_confidence_second": 0.7313506801889579, "sequence_confidence_final": 0.7313506801889579, "token_confidences_first": [0.362529456615448, 0.21193227171897888], "token_confidences_second": [0.5362922549247742, 0.9973551034927368], "final_mean_entropy": 2.818779945373535, "final_min_margin": 1.9541072845458984, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": [" : : 2019-09-29         200g() 21  30 6901377958427 3 10 1*40 22 15 245g1*40  6930320600038 1.5 10 30g() 18 23  1.8 10 6926502311519 1*100 45g( 20 24  2 10 6926502311731 ) ()1*60 42  4.2 10 6930575550126 25 30g1*30 I50g 55  5.5 10 6942032700494 26 1*40 35  3.5 10 6904417120198 130g1*60 27 16 1.6  10 6920104420136 90g1*100 28 32  3.2 10 200g1*40 6920104420143 29    "], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 3.411494731903076, "normalized_entropy_first": 0.21452171503287984, "min_margin_first": 1.277247428894043, "mean_entropy_second": 3.6937668323516846, "normalized_entropy_second": 0.6167285302321127, "min_margin_second": 1.2279052734375, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 99, "latency_ms_ocr": 984, "latency_ms_second": 209, "total_latency_ms": 1295, "total_latency_s": 1.295, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.411494731903076], "entropies_second": [3.6937668323516846], "final_normalized_entropy": 0.21452171503287984, "sequence_confidence_first": 0.270760115794807, "sequence_confidence_second": 0.5847148968230372, "sequence_confidence_final": 0.270760115794807, "token_confidences_first": [0.3804507851600647, 0.19269520044326782], "token_confidences_second": [0.34232842922210693, 0.9987236857414246], "final_mean_entropy": 3.411494731903076, "final_min_margin": 1.277247428894043, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["1/1 :[9001] :PI00031908081515 ###:[02] : 18 :2019-08-08 13:28:56 :2019-08-08 12:43.00 :O     6909409023020   100.00 0.72 7200 0.72 6909409039793 50.00  36.00 6909409023013 50.00 0.72 36.00  0.72 36.00 50.00 6926265302137    2.50 180.00 72.00 6911988006448   2.50 120.00 48.00  6911988006455 120.00 2.50  48.00 6911988006479  53.00 2.90 2000 6926265301130 58.00 20.00 2.90   6926265388100 58.00 2.90 20.00   6909409040799 :[0002]          "], "experiment": "entropy_routing_default", "routed": {"answer": "a receipt with numbers and chinese writing on it", "used_ocr": true, "answer_first": "yes", "answer_second": "a receipt with numbers and chinese writing on it", "raw_answer": "a receipt with numbers and chinese writing on it", "raw_answer_first": "yes", "raw_answer_second": "a receipt with numbers and chinese writing on it", "mean_entropy_first": 3.7887206077575684, "normalized_entropy_first": 0.7683278800852615, "min_margin_first": 1.3844146728515625, "mean_entropy_second": 2.3010368955067615, "normalized_entropy_second": -1.4609993150679474, "min_margin_second": 0.23088645935058594, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 89, "latency_ms_ocr": 551, "latency_ms_second": 392, "total_latency_ms": 1035, "total_latency_s": 1.035, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.7887206077575684], "entropies_second": [4.060161590576172, 4.210742950439453, 0.01203065924346447, 3.116260528564453, 3.566615104675293, 2.1424429416656494, 4.113335609436035, 0.07307006418704987, 1.7710622549057007, 1.7886416912078857, 0.4570424556732178], "final_normalized_entropy": -1.4609993150679474, "sequence_confidence_first": 0.26552887213927756, "sequence_confidence_second": 0.4270448588044639, "sequence_confidence_final": 0.4270448588044639, "token_confidences_first": [0.3385257124900818, 0.20827245712280273], "token_confidences_second": [0.3078681528568268, 0.2443810999393463, 0.9986135959625244, 0.2742519974708557, 0.2531610131263733, 0.4276282787322998, 0.15289250016212463, 0.9904720783233643, 0.4264718294143677, 0.6443937420845032, 0.9250858426094055, 0.42833834886550903], "final_mean_entropy": 2.3010368955067615, "final_min_margin": 0.23088645935058594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9831932773109243, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["0970104  :2019xx (/) :201xxx   :       : PET  350ml*24    PET 555ml*24     PET 555ml*12     PET 1555ml*12     PET  4.5L*4    PET  500ml*15    PET 500ml*15        180ml*24       280ml*24      PET 440ml*15     PET 440ml*15     PET 500ml*15     : : :   "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.736592454214891, "normalized_entropy_first": -0.9066448232615945, "min_margin_first": 0.020349502563476562, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 203, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 205, "total_latency_s": 0.205, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.8039116859436035, 4.396149158477783, 1.4562236070632935, 2.3131818771362305, 4.420506954193115, 0.02958144247531891], "entropies_second": null, "final_normalized_entropy": -0.9066448232615945, "sequence_confidence_first": 0.387481298518703, "sequence_confidence_second": null, "sequence_confidence_final": 0.387481298518703, "token_confidences_first": [0.34731563925743103, 0.15043097734451294, 0.7988879084587097, 0.6092295050621033, 0.15456239879131317, 0.9965947270393372, 0.3348146080970764], "token_confidences_second": null, "final_mean_entropy": 2.736592454214891, "final_min_margin": 0.020349502563476562, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9789915966386554, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["  6 40.00/ 2 40.00/  3 500ml*15-500ml, 0.00/ 1 000 11 4  : :-0.00 0.00 :400.00 :-0.00 : :    1  - - - - 107g*12-107g.  120g/125g/127g *12-120g/125g/127g  105g *12-105g  3 1 40.00/ 120.00 240.00 40.00 400.00"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a receipt", "used_ocr": false, "answer_first": "yes this is a receipt", "answer_second": null, "raw_answer": "yes this is a receipt", "raw_answer_first": "yes this is a receipt", "raw_answer_second": null, "mean_entropy_first": 2.4383265456805625, "normalized_entropy_first": -1.2906986177591735, "min_margin_first": 0.4786357879638672, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 200, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 202, "total_latency_s": 0.202, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.9144134521484375, 4.418036460876465, 1.609410285949707, 2.583521604537964, 2.0846645832061768, 0.01991288736462593], "entropies_second": null, "final_normalized_entropy": -1.2906986177591735, "sequence_confidence_first": 0.4546370340654508, "sequence_confidence_second": null, "sequence_confidence_final": 0.4546370340654508, "token_confidences_first": [0.2519325613975525, 0.1867835968732834, 0.7352542877197266, 0.5101968050003052, 0.6969863176345825, 0.9977467656135559, 0.3270474374294281], "token_confidences_second": null, "final_mean_entropy": 2.4383265456805625, "final_min_margin": 0.4786357879638672, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9888579387186629, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["30  : :? : :? : ? ? : ?  :, ,,  : : : : ,  : ? :  ? : : :    7 :,,"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.387779235839844, "normalized_entropy_first": 1.825325458628191, "min_margin_first": 0.1490478515625, "mean_entropy_second": 4.067679405212402, "normalized_entropy_second": 1.3394587471383692, "min_margin_second": 0.4943094253540039, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 87, "latency_ms_ocr": 415, "latency_ms_second": 105, "total_latency_ms": 608, "total_latency_s": 0.608, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.387779235839844], "entropies_second": [4.067679405212402], "final_normalized_entropy": 1.3394587471383692, "sequence_confidence_first": 0.17307419354980474, "sequence_confidence_second": 0.5028229643532429, "sequence_confidence_final": 0.5028229643532429, "token_confidences_first": [0.1746753603219986, 0.1714877039194107], "token_confidences_second": [0.2695245146751404, 0.938062846660614], "final_mean_entropy": 4.067679405212402, "final_min_margin": 0.4943094253540039, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["# # : :? : :, ,, ,? : : :,,  ,,  :, : : :() : :() : 9 "], "experiment": "entropy_routing_default", "routed": {"answer": "2015", "used_ocr": true, "answer_first": "yes", "answer_second": "2015", "raw_answer": "2015", "raw_answer_first": "yes", "raw_answer_second": "2015", "mean_entropy_first": 4.143418788909912, "normalized_entropy_first": 1.1611357602041608, "min_margin_first": 0.18332386016845703, "mean_entropy_second": 2.3270053386688234, "normalized_entropy_second": -1.3558487789744575, "min_margin_second": 0.06426525115966797, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 95, "latency_ms_ocr": 346, "latency_ms_second": 199, "total_latency_ms": 644, "total_latency_s": 0.644, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.143418788909912], "entropies_second": [4.597197532653809, 2.0144855976104736, 1.423628330230713, 1.667149543762207, 1.932565689086914], "final_normalized_entropy": -1.3558487789744575, "sequence_confidence_first": 0.22328710811790908, "sequence_confidence_second": 0.3447390953843311, "sequence_confidence_final": 0.3447390953843311, "token_confidences_first": [0.2036009430885315, 0.24487672746181488], "token_confidences_second": [0.11863594502210617, 0.24483156204223633, 0.6509604454040527, 0.46606749296188354, 0.2904820442199707, 0.6557477712631226], "final_mean_entropy": 2.3270053386688234, "final_min_margin": 0.06426525115966797, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["3 11 2 2009  :  ,     "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a letter in chinese", "used_ocr": false, "answer_first": "yes this is a letter in chinese", "answer_second": null, "raw_answer": "yes this is a letter in chinese", "raw_answer_first": "yes this is a letter in chinese", "raw_answer_second": null, "mean_entropy_first": 2.7438721507787704, "normalized_entropy_first": -0.884921682810408, "min_margin_first": 0.18122005462646484, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 254, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 256, "total_latency_s": 0.256, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.115992069244385, 4.981464385986328, 1.5233367681503296, 2.6938061714172363, 3.99772047996521, 2.7383594512939453, 1.7081975936889648, 0.19210028648376465], "entropies_second": null, "final_normalized_entropy": -0.884921682810408, "sequence_confidence_first": 0.355831231972823, "sequence_confidence_second": null, "sequence_confidence_final": 0.355831231972823, "token_confidences_first": [0.24093221127986908, 0.1587323695421219, 0.7507799863815308, 0.41702571511268616, 0.16163404285907745, 0.27092745900154114, 0.6659827828407288, 0.968622624874115, 0.27036920189857483], "token_confidences_second": null, "final_mean_entropy": 2.7438721507787704, "final_min_margin": 0.18122005462646484, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9375, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["52  2012 12 21 2012 12 21 2013 1 4 ## : WHT 201205353 (): : : : : () :  ()     () ()    ():          .13."], "experiment": "entropy_routing_default", "routed": {"answer": "35", "used_ocr": true, "answer_first": "yes", "answer_second": "35", "raw_answer": "35", "raw_answer_first": "yes", "raw_answer_second": "35", "mean_entropy_first": 4.3440680503845215, "normalized_entropy_first": 1.4187553120842022, "min_margin_first": 0.4415006637573242, "mean_entropy_second": 3.1791600386301675, "normalized_entropy_second": -0.20260386839665293, "min_margin_second": 0.1709442138671875, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 89, "latency_ms_ocr": 244, "latency_ms_second": 169, "total_latency_ms": 504, "total_latency_s": 0.504, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.3440680503845215], "entropies_second": [4.575593948364258, 2.2510263919830322, 2.710859775543213], "final_normalized_entropy": -0.20260386839665293, "sequence_confidence_first": 0.18494360325434914, "sequence_confidence_second": 0.291443556833109, "sequence_confidence_final": 0.291443556833109, "token_confidences_first": [0.20261535048484802, 0.16881315410137177], "token_confidences_second": [0.18661704659461975, 0.21025045216083527, 0.4170209765434265, 0.4409320652484894], "final_mean_entropy": 3.1791600386301675, "final_min_margin": 0.1709442138671875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 1.0, "cer": 0.9893048128342246, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 1.0, "relaxed_accuracy": 1.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["53  #  # () :  : : :3 : : : :, , ::  ,,,   , ,,  ,  , ,,  : :,,  :,   , :: :,,2009929,,, "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document in chinese", "used_ocr": false, "answer_first": "yes this is a document in chinese", "answer_second": null, "raw_answer": "yes this is a document in chinese", "raw_answer_first": "yes this is a document in chinese", "raw_answer_second": null, "mean_entropy_first": 2.6014982145279646, "normalized_entropy_first": -1.1045421216429072, "min_margin_first": 0.03471946716308594, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 250, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 251, "total_latency_s": 0.251, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.062228202819824, 4.957217216491699, 1.4663279056549072, 2.645679473876953, 3.7441277503967285, 2.3820042610168457, 1.381453037261963, 0.17294786870479584], "entropies_second": null, "final_normalized_entropy": -1.1045421216429072, "sequence_confidence_first": 0.4035146428993223, "sequence_confidence_second": null, "sequence_confidence_final": 0.4035146428993223, "token_confidences_first": [0.26052865386009216, 0.14054548740386963, 0.7384981513023376, 0.428972452878952, 0.2763214409351349, 0.3961332142353058, 0.7519941926002502, 0.9695041179656982, 0.3063814640045166], "token_confidences_second": null, "final_mean_entropy": 2.6014982145279646, "final_min_margin": 0.03471946716308594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9903225806451613, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["33    :,  : : : : :  :,, , ? :,,  :, :, :     8 "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document in chinese", "used_ocr": false, "answer_first": "yes this is a document in chinese", "answer_second": null, "raw_answer": "yes this is a document in chinese", "raw_answer_first": "yes this is a document in chinese", "raw_answer_second": null, "mean_entropy_first": 2.6970576625317335, "normalized_entropy_first": -0.8619605075097768, "min_margin_first": 0.5285816192626953, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 246, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 247, "total_latency_s": 0.247, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.94429612159729, 4.758879661560059, 1.5760509967803955, 2.7479867935180664, 4.072751045227051, 2.4710822105407715, 1.7791872024536133, 0.226227268576622], "entropies_second": null, "final_normalized_entropy": -0.8619605075097768, "sequence_confidence_first": 0.38276492121764205, "sequence_confidence_second": null, "sequence_confidence_final": 0.38276492121764205, "token_confidences_first": [0.24234555661678314, 0.17566822469234467, 0.7436718344688416, 0.4013614356517792, 0.19620728492736816, 0.37035372853279114, 0.6618188619613647, 0.9598843455314636, 0.30064502358436584], "token_confidences_second": null, "final_mean_entropy": 2.6970576625317335, "final_min_margin": 0.5285816192626953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9804560260586319, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["27   : :, ? : :,, : :. :. , :,  ,   : : : : 6"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document in chinese", "used_ocr": false, "answer_first": "yes this is a document in chinese", "answer_second": null, "raw_answer": "yes this is a document in chinese", "raw_answer_first": "yes this is a document in chinese", "raw_answer_second": null, "mean_entropy_first": 2.6422653049230576, "normalized_entropy_first": -0.8631711941192867, "min_margin_first": 0.22353172302246094, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 252, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 253, "total_latency_s": 0.253, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.937211275100708, 4.806525230407715, 1.48806631565094, 2.7368669509887695, 3.975646495819092, 2.4556288719177246, 1.552245020866394, 0.18593227863311768], "entropies_second": null, "final_normalized_entropy": -0.8631711941192867, "sequence_confidence_first": 0.380501008129454, "sequence_confidence_second": null, "sequence_confidence_final": 0.380501008129454, "token_confidences_first": [0.25671321153640747, 0.16027019917964935, 0.7584530711174011, 0.39890938997268677, 0.17861352860927582, 0.35851263999938965, 0.7186750173568726, 0.9671249985694885, 0.3017618656158447], "token_confidences_second": null, "final_mean_entropy": 2.6422653049230576, "final_min_margin": 0.22353172302246094, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.975103734439834, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["#  90% , ,, ,, ,, ,, ,, ,, , :,,? :,, , , :? : : :, : : : :, ? : :,,, ,,, : : : :  : 6"], "experiment": "entropy_routing_default", "routed": {"answer": "yes", "used_ocr": true, "answer_first": "yes", "answer_second": "yes", "raw_answer": "yes", "raw_answer_first": "yes", "raw_answer_second": "yes", "mean_entropy_first": 4.25309419631958, "normalized_entropy_first": 1.4290645755840752, "min_margin_first": 0.3586597442626953, "mean_entropy_second": 3.480175495147705, "normalized_entropy_second": 0.3643098628449043, "min_margin_second": 0.34642887115478516, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 89, "latency_ms_ocr": 562, "latency_ms_second": 126, "total_latency_ms": 779, "total_latency_s": 0.779, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.25309419631958], "entropies_second": [3.480175495147705], "final_normalized_entropy": 0.3643098628449043, "sequence_confidence_first": 0.18088865437768614, "sequence_confidence_second": 0.5344790294260502, "sequence_confidence_final": 0.5344790294260502, "token_confidences_first": [0.22130587697029114, 0.1478528529405594], "token_confidences_second": [0.2870415151119232, 0.9952143430709839], "final_mean_entropy": 3.480175495147705, "final_min_margin": 0.34642887115478516, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["27   , : ?? : : ?? : :, :, ? :, : ? :,105085.33, 2() :,? ::19196.3313100 =130060200=1200060200 =120004(1466712)=4889 20%=35200.885085.332 105085.33  :,, ,? : :,? , , ,24 :, , 3 5001466720-8"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document in chinese", "used_ocr": false, "answer_first": "yes this is a document in chinese", "answer_second": null, "raw_answer": "yes this is a document in chinese", "raw_answer_first": "yes this is a document in chinese", "raw_answer_second": null, "mean_entropy_first": 2.729001833125949, "normalized_entropy_first": -0.7813170811768545, "min_margin_first": 0.3893585205078125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 256, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 256, "total_latency_s": 0.256, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.264517784118652, 4.770362854003906, 1.4572831392288208, 2.625905752182007, 4.2483625411987305, 2.3462467193603516, 1.9387195110321045, 0.1806163638830185], "entropies_second": null, "final_normalized_entropy": -0.7813170811768545, "sequence_confidence_first": 0.3807981608626484, "sequence_confidence_second": null, "sequence_confidence_final": 0.3807981608626484, "token_confidences_first": [0.196511372923851, 0.17696428298950195, 0.7637317180633545, 0.44791847467422485, 0.1989375799894333, 0.392013818025589, 0.6097079515457153, 0.9692025780677795, 0.3071042597293854], "token_confidences_second": null, "final_mean_entropy": 2.729001833125949, "final_min_margin": 0.3893585205078125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9914651493598862, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["## ##    ##  ## 99 :? : , :? : : ,, ,? : : : () : () () : -4-   "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document in chinese", "used_ocr": false, "answer_first": "yes this is a document in chinese", "answer_second": null, "raw_answer": "yes this is a document in chinese", "raw_answer_first": "yes this is a document in chinese", "raw_answer_second": null, "mean_entropy_first": 2.709210939705372, "normalized_entropy_first": -0.7463830499272256, "min_margin_first": 0.05620861053466797, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 249, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 250, "total_latency_s": 0.25, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.029969215393066, 4.599170207977295, 1.5976347923278809, 2.72609281539917, 4.040171146392822, 2.601206064224243, 1.8603909015655518, 0.21905237436294556], "entropies_second": null, "final_normalized_entropy": -0.7463830499272256, "sequence_confidence_first": 0.3733967336817101, "sequence_confidence_second": null, "sequence_confidence_final": 0.3733967336817101, "token_confidences_first": [0.2508571445941925, 0.18577098846435547, 0.7234516143798828, 0.45338186621665955, 0.1488514542579651, 0.30756500363349915, 0.645602822303772, 0.961329460144043, 0.32488447427749634], "token_confidences_second": null, "final_mean_entropy": 2.709210939705372, "final_min_margin": 0.05620861053466797, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9786476868327402, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["39  # :,,  :? : :? : :, ? : :? : :, ,,      "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document in chinese", "used_ocr": false, "answer_first": "yes this is a document in chinese", "answer_second": null, "raw_answer": "yes this is a document in chinese", "raw_answer_first": "yes this is a document in chinese", "raw_answer_second": null, "mean_entropy_first": 2.830855220556259, "normalized_entropy_first": -0.5201593656944761, "min_margin_first": 0.04969978332519531, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 252, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 253, "total_latency_s": 0.253, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.785360336303711, 4.539454460144043, 1.7322144508361816, 2.8384432792663574, 4.567131996154785, 2.801391839981079, 2.1136302947998047, 0.26921510696411133], "entropies_second": null, "final_normalized_entropy": -0.5201593656944761, "sequence_confidence_first": 0.3653380067111281, "sequence_confidence_second": null, "sequence_confidence_final": 0.3653380067111281, "token_confidences_first": [0.3359552323818207, 0.20091839134693146, 0.71731036901474, 0.46249696612358093, 0.12378239631652832, 0.23900851607322693, 0.5712319016456604, 0.9498372077941895, 0.32255420088768005], "token_confidences_second": null, "final_mean_entropy": 2.830855220556259, "final_min_margin": 0.04969978332519531, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.974025974025974, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["() :2017428901015 :212 : :4 : : : :, :, ,  :: () , , () ,, (),,  (),  (),"], "experiment": "entropy_routing_default", "routed": {"answer": "chinese writing", "used_ocr": false, "answer_first": "chinese writing", "answer_second": null, "raw_answer": "chinese writing", "raw_answer_first": "chinese writing", "raw_answer_second": null, "mean_entropy_first": 2.7328782876332602, "normalized_entropy_first": -0.6284911708104767, "min_margin_first": 0.36143970489501953, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 136, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 137, "total_latency_s": 0.137, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.730992317199707, 0.4374682903289795, 3.0301742553710938], "entropies_second": null, "final_normalized_entropy": -0.6284911708104767, "sequence_confidence_first": 0.40351787876312933, "sequence_confidence_second": null, "sequence_confidence_final": 0.40351787876312933, "token_confidences_first": [0.16131585836410522, 0.9152147769927979, 0.28746408224105835, 0.6246941685676575], "token_confidences_second": null, "final_mean_entropy": 2.7328782876332602, "final_min_margin": 0.36143970489501953, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9974683544303797, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["2 #    : : : :  :, , :? : : :, :() : : : :  8"], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a letter in chinese", "used_ocr": false, "answer_first": "yes this is a letter in chinese", "answer_second": null, "raw_answer": "yes this is a letter in chinese", "raw_answer_first": "yes this is a letter in chinese", "raw_answer_second": null, "mean_entropy_first": 2.7116300091147423, "normalized_entropy_first": -0.6165428602781852, "min_margin_first": 0.06287384033203125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 253, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 254, "total_latency_s": 0.254, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.162907600402832, 4.640416622161865, 1.5092170238494873, 2.7648427486419678, 4.192850112915039, 2.6169066429138184, 1.6424072980880737, 0.16349202394485474], "entropies_second": null, "final_normalized_entropy": -0.6165428602781852, "sequence_confidence_first": 0.35822157587575076, "sequence_confidence_second": null, "sequence_confidence_final": 0.35822157587575076, "token_confidences_first": [0.218543142080307, 0.1764308512210846, 0.7641035914421082, 0.39538508653640747, 0.13752958178520203, 0.2915656268596649, 0.6860528588294983, 0.9741281270980835, 0.31115394830703735], "token_confidences_second": null, "final_mean_entropy": 2.7116300091147423, "final_min_margin": 0.06287384033203125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.9744680851063829, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["157  , ,, , :? : :? : :,          2   "], "experiment": "entropy_routing_default", "routed": {"answer": "yes this is a document in chinese", "used_ocr": false, "answer_first": "yes this is a document in chinese", "answer_second": null, "raw_answer": "yes this is a document in chinese", "raw_answer_first": "yes this is a document in chinese", "raw_answer_second": null, "mean_entropy_first": 2.801323778927326, "normalized_entropy_first": -0.4354674719681485, "min_margin_first": 0.2178211212158203, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 265, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 266, "total_latency_s": 0.266, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [3.943119525909424, 4.767675399780273, 1.5580228567123413, 2.6953864097595215, 4.4371137619018555, 2.842426300048828, 1.8898851871490479, 0.2769607901573181], "entropies_second": null, "final_normalized_entropy": -0.4354674719681485, "sequence_confidence_first": 0.36610696128021125, "sequence_confidence_second": null, "sequence_confidence_final": 0.36610696128021125, "token_confidences_first": [0.28523901104927063, 0.17154912650585175, 0.7507335543632507, 0.46919575333595276, 0.14163893461227417, 0.2518673241138458, 0.6414264440536499, 0.9463861584663391, 0.3165664076805115], "token_confidences_second": null, "final_mean_entropy": 2.801323778927326, "final_min_margin": 0.2178211212158203, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 0.967391304347826, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "Please output only the text content from the image without any additional descriptions or formatting.", "image_id": null, "answers": ["# # ## : : :,,  : :, 2 5 ?"], "experiment": "entropy_routing_default", "routed": {"answer": "et", "used_ocr": true, "answer_first": "yes this is a letter", "answer_second": "et", "raw_answer": "et", "raw_answer_first": "yes this is a letter", "raw_answer_second": "et", "mean_entropy_first": 3.559400486946106, "normalized_entropy_first": 0.8142236790934393, "min_margin_first": 0.12185859680175781, "mean_entropy_second": 5.482611656188965, "normalized_entropy_second": 3.9181504994238896, "min_margin_second": 0.25368595123291016, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 188, "latency_ms_ocr": 153, "latency_ms_second": 105, "total_latency_ms": 448, "total_latency_s": 0.448, "model_id": "Salesforce/instructblip-vicuna-7b", "image_source": "in_memory:None", "entropies_first": [4.510822296142578, 4.289669036865234, 1.5769764184951782, 2.9135684967041016, 4.5059661865234375], "entropies_second": [5.482611656188965], "final_normalized_entropy": 3.9181504994238896, "sequence_confidence_first": 0.2585209421906503, "sequence_confidence_second": 0.19458020441793422, "sequence_confidence_final": 0.19458020441793422, "token_confidences_first": [0.16074302792549133, 0.19102847576141357, 0.7617707848548889, 0.42529216408729553, 0.15403421223163605, 0.19481179118156433], "token_confidences_second": [0.0960819274187088, 0.3940538763999939], "final_mean_entropy": 5.482611656188965, "final_min_margin": 0.25368595123291016, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
