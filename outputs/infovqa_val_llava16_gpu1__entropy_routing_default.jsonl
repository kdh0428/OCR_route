{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a graphic or infographic that outlines various statistics", "used_ocr": false, "answer_first": "The image you've provided appears to be a graphic or infographic that outlines various statistics", "answer_second": null, "raw_answer": "The image you've provided appears to be a graphic or infographic that outlines various statistics", "raw_answer_first": "The image you've provided appears to be a graphic or infographic that outlines various statistics", "raw_answer_second": null, "mean_entropy_first": 1.0040595139209472, "normalized_entropy_first": 0.0, "min_margin_first": 0.06568527221679688, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1089, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1090, "total_latency_s": 1.09, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.2473254203796387, 0.036340489983558655, 1.340126633644104, 0.2962206304073334, 0.0034103321377187967, 0.6897839307785034, 0.988472580909729, 0.00012625701492652297, 0.04358694329857826, 0.36846283078193665, 3.3244495391845703, 0.3405956029891968, 1.6133930683135986, 2.5177111625671387, 0.015084482729434967, 2.568286895751953, 2.6263785362243652, 0.00019867900118697435, 1.0478428602218628, 1.0133934020996094], "entropies_second": null, "final_normalized_entropy": 0.0, "sequence_confidence_first": 0.6442665617641415, "sequence_confidence_second": null, "sequence_confidence_final": 0.6442665617641415, "token_confidences_first": [0.5045342445373535, 0.996206521987915, 0.6079142689704895, 0.9322028160095215, 0.9996668100357056, 0.6695553660392761, 0.623001217842102, 0.9999922513961792, 0.9939298629760742, 0.8982290625572205, 0.1541137993335724, 0.9010429382324219, 0.6158211827278137, 0.3577730357646942, 0.9981745481491089, 0.25643858313560486, 0.2781918942928314, 0.9999856948852539, 0.7941819429397583, 0.8274686336517334], "token_confidences_second": null, "final_mean_entropy": 1.0040595139209472, "final_min_margin": 0.06568527221679688, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a promotional or informational graphic related to", "used_ocr": false, "answer_first": "The image you've provided appears to be a promotional or informational graphic related to", "answer_second": null, "raw_answer": "The image you've provided appears to be a promotional or informational graphic related to", "raw_answer_first": "The image you've provided appears to be a promotional or informational graphic related to", "raw_answer_second": null, "mean_entropy_first": 0.6535175091117708, "normalized_entropy_first": -350.5420048091764, "min_margin_first": 0.07353019714355469, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1201, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1203, "total_latency_s": 1.203, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8125138282775879, 0.06363604217767715, 1.3698633909225464, 0.26444438099861145, 0.003217986086383462, 0.7056074142456055, 0.82651686668396, 5.454615893540904e-05, 0.021220900118350983, 0.540946364402771, 3.2395081520080566, 0.0020030452869832516, 0.0004949412541463971, 1.743751049041748, 0.46486711502075195, 0.4473450481891632, 0.8046303391456604, 0.004252550192177296, 1.7552127838134766, 0.00026343821082264185], "entropies_second": null, "final_normalized_entropy": -350.5420048091764, "sequence_confidence_first": 0.7366097481462781, "sequence_confidence_second": null, "sequence_confidence_final": 0.7366097481462781, "token_confidences_first": [0.6658463478088379, 0.992685079574585, 0.5677998661994934, 0.9424121975898743, 0.9996770620346069, 0.6536072492599487, 0.5930841565132141, 0.9999967813491821, 0.997244119644165, 0.8063528537750244, 0.19020451605319977, 0.9998229146003723, 0.999964714050293, 0.365521639585495, 0.8738417625427246, 0.8381020426750183, 0.7793771028518677, 0.9995582699775696, 0.506045937538147, 0.9999823570251465], "token_confidences_second": null, "final_mean_entropy": 0.6535175091117708, "final_min_margin": 0.07353019714355469, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "ANSWER", "used_ocr": false, "answer_first": "ANSWER", "answer_second": null, "raw_answer": "ANSWER: [ANSWER]", "raw_answer_first": "ANSWER: [ANSWER]", "raw_answer_second": null, "mean_entropy_first": 0.6201666116481647, "normalized_entropy_first": -3.3171364820388027, "min_margin_first": 0.12775039672851562, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 782, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 784, "total_latency_s": 0.784, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.4491167068481445, 0.03513430058956146, 0.004054988734424114, 0.002924592001363635, 0.024687882512807846, 1.5238752365112305, 3.119272232055664, 0.006623213645070791, 0.0038453475572168827, 0.0321316160261631], "entropies_second": null, "final_normalized_entropy": -3.3171364820388027, "sequence_confidence_first": 0.8207633556730987, "sequence_confidence_second": null, "sequence_confidence_final": 0.8207633556730987, "token_confidences_first": [0.43985074758529663, 0.9968482851982117, 0.9996544122695923, 0.9997356534004211, 0.9972004890441895, 0.5036923885345459, 0.5202680230140686, 0.9994010925292969, 0.9996252059936523, 0.9972442388534546, 0.9981010556221008], "token_confidences_second": null, "final_mean_entropy": 0.6201666116481647, "final_min_margin": 0.12775039672851562, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a graphic or infographic related to the impact of", "used_ocr": false, "answer_first": "The image you've provided appears to be a graphic or infographic related to the impact of", "answer_second": null, "raw_answer": "The image you've provided appears to be a graphic or infographic related to the impact of", "raw_answer_first": "The image you've provided appears to be a graphic or infographic related to the impact of", "raw_answer_second": null, "mean_entropy_first": 0.8197903697551737, "normalized_entropy_first": -0.7907459231576766, "min_margin_first": 0.10391616821289062, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1243, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1245, "total_latency_s": 1.245, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8592228293418884, 0.07828137278556824, 1.4901095628738403, 0.26763901114463806, 0.005656343884766102, 0.700332522392273, 0.8666965961456299, 4.779584924108349e-05, 0.021548671647906303, 0.7376152873039246, 2.9128551483154297, 0.5401484370231628, 1.4607481956481934, 1.9143235683441162, 0.013736098073422909, 1.9926751852035522, 0.0001539699442218989, 1.0352541208267212, 1.4484095573425293, 0.050353121012449265], "entropies_second": null, "final_normalized_entropy": -0.7907459231576766, "sequence_confidence_first": 0.7131811916641617, "sequence_confidence_second": null, "sequence_confidence_final": 0.7131811916641617, "token_confidences_first": [0.5347285866737366, 0.9894814491271973, 0.5419051051139832, 0.941577672958374, 0.999428927898407, 0.6595543622970581, 0.5101087093353271, 0.9999971389770508, 0.997514009475708, 0.5832636952400208, 0.35236868262290955, 0.7836803793907166, 0.7226975560188293, 0.5022388696670532, 0.9983262419700623, 0.4902784824371338, 0.9999901056289673, 0.7219867706298828, 0.623668372631073, 0.9931893348693848], "token_confidences_second": null, "final_mean_entropy": 0.8197903697551737, "final_min_margin": 0.10391616821289062, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This image is a colorful infographic that provides a snapshot of various social media platforms and their statistics", "used_ocr": true, "answer_first": "This image is a colorful infographic that provides a snapshot of various social media platforms and their statistics", "answer_second": "The image contains a chart with various statistics related to social media platforms. Here is the OCR-", "raw_answer": "This image is a colorful infographic that provides a snapshot of various social media platforms and their statistics", "raw_answer_first": "This image is a colorful infographic that provides a snapshot of various social media platforms and their statistics", "raw_answer_second": "The image contains a chart with various statistics related to social media platforms. Here is the OCR-", "mean_entropy_first": 1.2500789216719568, "normalized_entropy_first": 2.315514147258013, "min_margin_first": 0.3007354736328125, "mean_entropy_second": 1.2654654488316737, "normalized_entropy_second": 2.424337439267481, "min_margin_second": 0.10674476623535156, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1403, "latency_ms_ocr": 566, "latency_ms_second": 1664, "total_latency_ms": 3635, "total_latency_s": 3.635, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8589223027229309, 1.032669186592102, 1.5651192665100098, 0.55264812707901, 2.7012128829956055, 0.024772167205810547, 0.649411678314209, 0.00638994388282299, 1.9539430141448975, 2.3459532260894775, 1.8926613330841064, 2.3960976600646973, 0.022553399205207825, 1.8104619979858398, 0.4587487280368805, 0.37183454632759094, 1.0885602235794067, 1.312171220779419, 0.8563709259033203, 3.101076602935791], "entropies_second": [1.463113784790039, 1.576541781425476, 1.9898995161056519, 1.7002402544021606, 2.9655933380126953, 2.067718982696533, 1.9778081178665161, 1.0721986293792725, 1.538691759109497, 0.0011443536495789886, 0.704224705696106, 0.22699777781963348, 1.5751087665557861, 1.3866902589797974, 1.6995255947113037, 0.8873393535614014, 0.43133145570755005, 1.769165277481079, 0.0008174594258889556, 0.2751578092575073], "final_normalized_entropy": 2.315514147258013, "sequence_confidence_first": 0.6033286041799005, "sequence_confidence_second": 0.5629506448331363, "sequence_confidence_final": 0.6033286041799005, "token_confidences_first": [0.5586363673210144, 0.556226372718811, 0.5445145964622498, 0.8057267665863037, 0.32607272267341614, 0.9967169165611267, 0.8679084777832031, 0.9993160963058472, 0.5787500143051147, 0.28896477818489075, 0.37984699010849, 0.46125125885009766, 0.9976818561553955, 0.4879307448863983, 0.9286122918128967, 0.9310495853424072, 0.6854181885719299, 0.66551274061203, 0.8210838437080383, 0.23009009659290314], "token_confidences_second": [0.6801556348800659, 0.4090331792831421, 0.2878468632698059, 0.5943689346313477, 0.16575177013874054, 0.37038543820381165, 0.5308393836021423, 0.6792001724243164, 0.5203402042388916, 0.999907374382019, 0.8260422945022583, 0.9595552682876587, 0.39412668347358704, 0.5317158699035645, 0.5622562766075134, 0.6269599199295044, 0.8929308652877808, 0.37828898429870605, 0.999930739402771, 0.9426023960113525], "final_mean_entropy": 1.2500789216719568, "final_min_margin": 0.3007354736328125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image is as follows:\n\nA BRIEF", "used_ocr": true, "answer_first": "This image appears to be a brief history of social media platforms, presented in a timeline format.", "answer_second": "The OCR-extracted text from the image is as follows:\n\nA BRIEF", "raw_answer": "The OCR-extracted text from the image is as follows:\n\nA BRIEF", "raw_answer_first": "This image appears to be a brief history of social media platforms, presented in a timeline format.", "raw_answer_second": "The OCR-extracted text from the image is as follows:\n\nA BRIEF", "mean_entropy_first": 0.9765182551476755, "normalized_entropy_first": 0.12686329641376876, "min_margin_first": 0.025058746337890625, "mean_entropy_second": 0.5558080592221813, "normalized_entropy_second": -2.4037438299278904, "min_margin_second": 0.020467758178710938, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1206, "latency_ms_ocr": 329, "latency_ms_second": 1291, "total_latency_ms": 2829, "total_latency_s": 2.829, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.0467885732650757, 0.9102826118469238, 1.6138906478881836, 0.0003240264195483178, 0.044431865215301514, 0.7049456834793091, 2.4501752853393555, 1.014910101890564, 0.6710249781608582, 0.18948954343795776, 0.0006904772599227726, 0.04265013337135315, 1.0345113277435303, 3.6040823459625244, 1.0494316816329956, 0.7598092555999756, 2.9225568771362305, 0.009809484705328941, 0.5847327709197998, 0.875827431678772], "entropies_second": [1.5872331857681274, 1.7305724620819092, 0.0015503661707043648, 0.43751639127731323, 0.15319478511810303, 0.0003234596806578338, 0.003963956609368324, 1.981845736503601, 0.015093538910150528, 0.03307367116212845, 2.107487201690674, 1.9125453233718872, 0.03140535578131676, 0.24097511172294617, 0.0018235491588711739, 0.08035913854837418, 0.7254265546798706, 0.0661860853433609, 0.004881010856479406, 0.0007043000077828765], "final_normalized_entropy": -2.4037438299278904, "sequence_confidence_first": 0.6330561011204244, "sequence_confidence_second": 0.7991251129530086, "sequence_confidence_final": 0.7991251129530086, "token_confidences_first": [0.46482914686203003, 0.573550820350647, 0.3636910915374756, 0.9999737739562988, 0.9949038028717041, 0.6274253129959106, 0.33025291562080383, 0.7503173351287842, 0.8420045971870422, 0.9710896015167236, 0.9999467134475708, 0.9955877065658569, 0.7346594333648682, 0.116425059735775, 0.6348451972007751, 0.7998454570770264, 0.28101813793182373, 0.9990045428276062, 0.8950810432434082, 0.8020877838134766], "token_confidences_second": [0.6659833192825317, 0.34889912605285645, 0.9998526573181152, 0.8938323855400085, 0.9766384959220886, 0.9999743700027466, 0.9996769428253174, 0.4027996063232422, 0.9981022477149963, 0.9954203963279724, 0.3387104272842407, 0.5056569576263428, 0.9965505599975586, 0.9531821012496948, 0.9998470544815063, 0.9869181513786316, 0.8737257122993469, 0.991614580154419, 0.9995875954627991, 0.9999399185180664], "final_mean_entropy": 0.5558080592221813, "final_min_margin": 0.020467758178710938, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "used_ocr": true, "answer_first": "The image you've provided is a graphic that appears to be from a research project or report", "answer_second": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "raw_answer": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "raw_answer_first": "The image you've provided is a graphic that appears to be from a research project or report", "raw_answer_second": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "mean_entropy_first": 1.2522259527584538, "normalized_entropy_first": 1.866963611768296, "min_margin_first": 0.009664535522460938, "mean_entropy_second": 0.8772086841301643, "normalized_entropy_second": -0.5089054312377388, "min_margin_second": 0.09968948364257812, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1346, "latency_ms_ocr": 2360, "latency_ms_second": 1547, "total_latency_ms": 5255, "total_latency_s": 5.255, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.7951995134353638, 0.13127654790878296, 1.69066321849823, 0.22010651230812073, 0.0023070506285876036, 0.7523622512817383, 0.8991255164146423, 0.9079734086990356, 2.708627223968506, 0.5099163055419922, 2.844661235809326, 2.409085273742676, 0.002504433272406459, 1.1183898448944092, 2.2673630714416504, 0.8296520709991455, 1.983137607574463, 0.9179693460464478, 1.959720492362976, 2.094478130340576], "entropies_second": [1.3411216735839844, 1.693407416343689, 0.0020329803228378296, 0.5674893260002136, 0.1786426454782486, 0.00046122356434352696, 0.004361066501587629, 1.9444324970245361, 0.02203359082341194, 0.034138962626457214, 1.9137530326843262, 0.274488627910614, 0.6818905472755432, 2.3012161254882812, 0.4777253568172455, 1.5991449356079102, 1.3917644023895264, 1.4972060918807983, 0.20179565250873566, 1.417067527770996], "final_normalized_entropy": -0.5089054312377388, "sequence_confidence_first": 0.5306361048130829, "sequence_confidence_second": 0.6960664127989815, "sequence_confidence_final": 0.6960664127989815, "token_confidences_first": [0.5804260969161987, 0.9786359667778015, 0.3984537124633789, 0.9549697637557983, 0.9997639060020447, 0.563174307346344, 0.5256689190864563, 0.5655511617660522, 0.3836781680583954, 0.8027178049087524, 0.24615950882434845, 0.2614765763282776, 0.9997969269752502, 0.6029559373855591, 0.20314809679985046, 0.782258152961731, 0.33942297101020813, 0.733630895614624, 0.5365561842918396, 0.3412731885910034], "token_confidences_second": [0.720379114151001, 0.3155865967273712, 0.9998082518577576, 0.848487377166748, 0.972764253616333, 0.9999628067016602, 0.9996237754821777, 0.41789504885673523, 0.9969794750213623, 0.9953376054763794, 0.43224039673805237, 0.9539377689361572, 0.8494777679443359, 0.38170310854911804, 0.8736845850944519, 0.4876311719417572, 0.5021704435348511, 0.46573367714881897, 0.9616942405700684, 0.7155250906944275], "final_mean_entropy": 0.8772086841301643, "final_min_margin": 0.09968948364257812, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a graphic or infographic related to healthcare and", "used_ocr": false, "answer_first": "The image you've provided appears to be a graphic or infographic related to healthcare and", "answer_second": null, "raw_answer": "The image you've provided appears to be a graphic or infographic related to healthcare and", "raw_answer_first": "The image you've provided appears to be a graphic or infographic related to healthcare and", "raw_answer_second": null, "mean_entropy_first": 0.8818273892436992, "normalized_entropy_first": -0.6048402203379625, "min_margin_first": 0.03394126892089844, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1196, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1199, "total_latency_s": 1.199, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.025993824005127, 0.05004606395959854, 1.3682788610458374, 0.28025466203689575, 0.0033334344625473022, 0.7023671865463257, 0.9168649911880493, 9.65478247962892e-05, 0.02424847148358822, 0.6936192512512207, 3.369722366333008, 0.26108312606811523, 1.3044987916946411, 2.4341962337493896, 0.011822152882814407, 2.2646448612213135, 0.00013660467811860144, 1.5037157535552979, 0.12709790468215942, 1.2945266962051392], "entropies_second": null, "final_normalized_entropy": -0.6048402203379625, "sequence_confidence_first": 0.66607707682983, "sequence_confidence_second": null, "sequence_confidence_final": 0.66607707682983, "token_confidences_first": [0.5464200377464294, 0.9942317605018616, 0.600750744342804, 0.9380779266357422, 0.9996588230133057, 0.6443992853164673, 0.5479298233985901, 0.9999940395355225, 0.9968767166137695, 0.6273706555366516, 0.19726309180259705, 0.9304287433624268, 0.7290988564491272, 0.23413844406604767, 0.9985981583595276, 0.4320785105228424, 0.9999914169311523, 0.4371226727962494, 0.9768970608711243, 0.7572817206382751], "token_confidences_second": null, "final_mean_entropy": 0.8818273892436992, "final_min_margin": 0.03394126892089844, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided is a salary guide for social media jobs in the United States.", "used_ocr": false, "answer_first": "The image you've provided is a salary guide for social media jobs in the United States.", "answer_second": null, "raw_answer": "The image you've provided is a salary guide for social media jobs in the United States.", "raw_answer_first": "The image you've provided is a salary guide for social media jobs in the United States.", "raw_answer_second": null, "mean_entropy_first": 0.6778413798567271, "normalized_entropy_first": -1.7780719120721487, "min_margin_first": 0.18651390075683594, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1182, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1183, "total_latency_s": 1.183, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.9744505882263184, 0.07110393047332764, 1.5734057426452637, 0.26262935996055603, 0.0026725383941084146, 0.689913272857666, 0.8021138310432434, 0.8176734447479248, 2.975107431411743, 4.810495374840684e-05, 0.06543498486280441, 1.1441307067871094, 0.7170368432998657, 0.0004578124498948455, 0.2997265160083771, 1.6091020107269287, 0.4595857858657837, 0.25196772813796997, 0.0007804845226928592, 0.8394864797592163], "entropies_second": null, "final_normalized_entropy": -1.7780719120721487, "sequence_confidence_first": 0.7391192330400403, "sequence_confidence_second": null, "sequence_confidence_final": 0.7391192330400403, "token_confidences_first": [0.517148494720459, 0.9918403625488281, 0.5357896685600281, 0.9414313435554504, 0.9997349381446838, 0.6687652468681335, 0.5416426658630371, 0.7382591962814331, 0.2011493593454361, 0.9999969005584717, 0.9922388792037964, 0.7838777899742126, 0.8281567096710205, 0.9999655485153198, 0.9383668303489685, 0.48004093766212463, 0.9051236510276794, 0.9547756314277649, 0.9999345541000366, 0.678669810295105], "token_confidences_second": null, "final_mean_entropy": 0.6778413798567271, "final_min_margin": 0.18651390075683594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This is a colorful calendar for the year 2018, specifically designed for social media", "used_ocr": false, "answer_first": "This is a colorful calendar for the year 2018, specifically designed for social media", "answer_second": null, "raw_answer": "This is a colorful calendar for the year 2018, specifically designed for social media", "raw_answer_first": "This is a colorful calendar for the year 2018, specifically designed for social media", "raw_answer_second": null, "mean_entropy_first": 0.9383604382876001, "normalized_entropy_first": -0.04519936680224115, "min_margin_first": 0.031009674072265625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1352, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1353, "total_latency_s": 1.353, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.1120718717575073, 0.7699912786483765, 0.5608746409416199, 2.067239999771118, 0.1934879571199417, 2.0432028770446777, 2.0132689476013184, 0.9819005131721497, 0.5902202129364014, 0.005812718998640776, 5.192045500734821e-05, 4.382605038699694e-05, 0.005287627689540386, 0.02023523859679699, 2.0078413486480713, 2.519803047180176, 2.0946080684661865, 0.5418830513954163, 1.2298405170440674, 0.009543102234601974], "entropies_second": null, "final_normalized_entropy": -0.04519936680224115, "sequence_confidence_first": 0.6834546245468484, "sequence_confidence_second": null, "sequence_confidence_final": 0.6834546245468484, "token_confidences_first": [0.4631752669811249, 0.5328591465950012, 0.8132816553115845, 0.345740407705307, 0.9571990370750427, 0.4194180965423584, 0.4884262681007385, 0.633376955986023, 0.8823779225349426, 0.9993917942047119, 0.9999964237213135, 0.9999971389770508, 0.9993770718574524, 0.9974276423454285, 0.4516693949699402, 0.46355751156806946, 0.4909646809101105, 0.840269148349762, 0.7563849091529846, 0.9990792274475098], "token_confidences_second": null, "final_mean_entropy": 0.9383604382876001, "final_min_margin": 0.031009674072265625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a poster or infographic related to social media impact on", "used_ocr": true, "answer_first": "The image you've provided appears to be a poster or infographic related to social media impact on", "answer_second": "The image appears to be an infographic or poster that discusses the impact of social media on non", "raw_answer": "The image you've provided appears to be a poster or infographic related to social media impact on", "raw_answer_first": "The image you've provided appears to be a poster or infographic related to social media impact on", "raw_answer_second": "The image appears to be an infographic or poster that discusses the impact of social media on non", "mean_entropy_first": 0.9024706868243811, "normalized_entropy_first": -0.24980504760740932, "min_margin_first": 0.1622905731201172, "mean_entropy_second": 1.0729246526243514, "normalized_entropy_second": 0.7329813958306005, "min_margin_second": 0.06247711181640625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1055, "latency_ms_ocr": 3030, "latency_ms_second": 1549, "total_latency_ms": 5639, "total_latency_s": 5.639, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.1418606042861938, 0.0868847668170929, 1.7143127918243408, 0.2781217694282532, 0.0018767069559544325, 0.7269100546836853, 1.0121374130249023, 0.00020332243002485484, 0.040099188685417175, 0.6838460564613342, 2.6653261184692383, 0.4574604630470276, 2.0785136222839355, 0.016217030584812164, 2.342714786529541, 0.000202239491045475, 1.1125435829162598, 0.017866667360067368, 1.9586524963378906, 1.7136640548706055], "entropies_second": [1.866363525390625, 1.5269274711608887, 2.032341957092285, 0.0016329402569681406, 0.4398213028907776, 0.7887433171272278, 0.38547950983047485, 0.08094392716884613, 3.1243984699249268, 1.9494911432266235, 2.7038512229919434, 2.4871363639831543, 0.0004498955968301743, 0.9059856534004211, 0.9499104022979736, 0.119460329413414, 0.692617654800415, 0.0029370361007750034, 0.6163649559020996, 0.7836359739303589], "final_normalized_entropy": -0.24980504760740932, "sequence_confidence_first": 0.6570937120320218, "sequence_confidence_second": 0.6120375506210862, "sequence_confidence_final": 0.6570937120320218, "token_confidences_first": [0.6313332915306091, 0.9890692830085754, 0.42144790291786194, 0.9383177757263184, 0.9998226761817932, 0.6630375385284424, 0.6165451407432556, 0.9999872446060181, 0.9947645664215088, 0.7018365263938904, 0.2765548825263977, 0.9269630908966064, 0.2959694266319275, 0.9979411959648132, 0.3468559980392456, 0.9999873638153076, 0.7129108309745789, 0.9982807636260986, 0.41506874561309814, 0.4119485914707184], "token_confidences_second": [0.6533461809158325, 0.4157603681087494, 0.2747858166694641, 0.999884843826294, 0.9191412925720215, 0.5900415778160095, 0.9281435608863831, 0.985797107219696, 0.14095309376716614, 0.4677107334136963, 0.21242591738700867, 0.3254382014274597, 0.9999696016311646, 0.7521191239356995, 0.8097068071365356, 0.9792245030403137, 0.7694686055183411, 0.9997294545173645, 0.8881953358650208, 0.7909876108169556], "final_mean_entropy": 0.9024706868243811, "final_min_margin": 0.1622905731201172, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided is a visual representation of the \"State of Social Media 20", "used_ocr": false, "answer_first": "The image you've provided is a visual representation of the \"State of Social Media 20", "answer_second": null, "raw_answer": "The image you've provided is a visual representation of the \"State of Social Media 20", "raw_answer_first": "The image you've provided is a visual representation of the \"State of Social Media 20", "raw_answer_second": null, "mean_entropy_first": 0.9212502389258589, "normalized_entropy_first": -0.12247008964903387, "min_margin_first": 0.15719985961914062, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1152, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1154, "total_latency_s": 1.154, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.178861141204834, 0.08296379446983337, 1.5098551511764526, 0.26087895035743713, 0.005759468302130699, 0.7359864711761475, 0.9163696765899658, 0.5354756712913513, 3.2562713623046875, 2.205258846282959, 0.5744473934173584, 1.9535731077194214, 2.617952346801758, 1.2515170574188232, 0.05904729664325714, 0.06983407586812973, 0.012914812192320824, 1.1955838203430176, 0.0019743323791772127, 0.00048000257811509073], "entropies_second": null, "final_normalized_entropy": -0.12247008964903387, "sequence_confidence_first": 0.6616837170864607, "sequence_confidence_second": null, "sequence_confidence_final": 0.6616837170864607, "token_confidences_first": [0.4909537732601166, 0.9905845522880554, 0.5796287655830383, 0.9438018202781677, 0.9993963241577148, 0.6428612470626831, 0.5174102783203125, 0.8655679225921631, 0.18341156840324402, 0.36107757687568665, 0.8982999324798584, 0.397665411233902, 0.4518532156944275, 0.7077656388282776, 0.9901161789894104, 0.991300642490387, 0.9987198114395142, 0.45599043369293213, 0.9998290538787842, 0.9999651908874512], "token_confidences_second": null, "final_mean_entropy": 0.9212502389258589, "final_min_margin": 0.15719985961914062, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a promotional or informational graphic related to", "used_ocr": false, "answer_first": "The image you've provided appears to be a promotional or informational graphic related to", "answer_second": null, "raw_answer": "The image you've provided appears to be a promotional or informational graphic related to", "raw_answer_first": "The image you've provided appears to be a promotional or informational graphic related to", "raw_answer_second": null, "mean_entropy_first": 0.5968988269230977, "normalized_entropy_first": -2.185996714408755, "min_margin_first": 0.040431976318359375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1397, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1398, "total_latency_s": 1.398, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8540416955947876, 0.04023291915655136, 1.5527892112731934, 0.23873235285282135, 0.0043242936953902245, 0.6878085732460022, 0.8321197032928467, 4.19212992710527e-05, 0.016622621566057205, 0.6757993698120117, 2.9298768043518066, 0.0008981787832453847, 0.00023084627173375338, 1.1798090934753418, 0.4066593647003174, 0.43242043256759644, 0.33635181188583374, 0.0015534789999946952, 1.747511863708496, 0.00015200192865449935], "entropies_second": null, "final_normalized_entropy": -2.185996714408755, "sequence_confidence_first": 0.7433063076669653, "sequence_confidence_second": null, "sequence_confidence_final": 0.7433063076669653, "token_confidences_first": [0.6127974987030029, 0.9953983426094055, 0.4881463646888733, 0.9486700296401978, 0.9995423555374146, 0.6751965284347534, 0.5649052262306213, 0.9999974966049194, 0.99797123670578, 0.6784231066703796, 0.2485368549823761, 0.9999229907989502, 0.999984622001648, 0.4626327455043793, 0.8946638703346252, 0.8471395373344421, 0.9444292187690735, 0.999852180480957, 0.4418248236179352, 0.9999895095825195], "token_confidences_second": null, "final_mean_entropy": 0.5968988269230977, "final_min_margin": 0.040431976318359375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a page from a publication or a report, specifically foc", "used_ocr": true, "answer_first": "The image you've provided appears to be a page from a publication or a report, specifically foc", "answer_second": "The text extracted from the image appears to be mostly accurate, with a few minor errors. Here is", "raw_answer": "The image you've provided appears to be a page from a publication or a report, specifically foc", "raw_answer_first": "The image you've provided appears to be a page from a publication or a report, specifically foc", "raw_answer_second": "The text extracted from the image appears to be mostly accurate, with a few minor errors. Here is", "mean_entropy_first": 1.1236845869530954, "normalized_entropy_first": 1.209036907226685, "min_margin_first": 0.26200103759765625, "mean_entropy_second": 1.127452426031232, "normalized_entropy_second": 1.229886038038215, "min_margin_second": 0.10359001159667969, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1343, "latency_ms_ocr": 1545, "latency_ms_second": 1538, "total_latency_ms": 4429, "total_latency_s": 4.429, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.7897266149520874, 0.019103532657027245, 1.6051576137542725, 0.2370195835828781, 0.0027378404047340155, 0.6829816699028015, 0.8131086826324463, 3.624536475399509e-05, 0.01157880388200283, 0.6827639937400818, 2.32125186920166, 0.2013123482465744, 0.34563347697257996, 2.061387062072754, 1.4201794862747192, 1.7871904373168945, 2.688717842102051, 2.4621896743774414, 2.064066171646118, 2.2775487899780273], "entropies_second": [1.3855448961257935, 1.7416775226593018, 1.4378100633621216, 0.17036406695842743, 0.006047510541975498, 0.014550118707120419, 1.8237361907958984, 0.2899729013442993, 0.5473539233207703, 2.2205286026000977, 0.5087530016899109, 1.5563712120056152, 1.465546727180481, 1.4770523309707642, 0.30872344970703125, 1.3266990184783936, 2.2547125816345215, 1.6192307472229004, 1.295279860496521, 1.0990937948226929], "final_normalized_entropy": 1.209036907226685, "sequence_confidence_first": 0.6049367143196217, "sequence_confidence_second": 0.591716071218282, "sequence_confidence_final": 0.6049367143196217, "token_confidences_first": [0.571570634841919, 0.9981673955917358, 0.39322030544281006, 0.9497188329696655, 0.9997215867042542, 0.6727036237716675, 0.5521339178085327, 0.9999978542327881, 0.9986238479614258, 0.8053450584411621, 0.4403688311576843, 0.9630887508392334, 0.9280796051025391, 0.3993639647960663, 0.5541916489601135, 0.48347386717796326, 0.30396488308906555, 0.25629109144210815, 0.42753735184669495, 0.48257339000701904], "token_confidences_second": [0.7065738439559937, 0.3140885829925537, 0.4476638436317444, 0.9760690927505493, 0.9993315935134888, 0.9985185265541077, 0.43778425455093384, 0.9499011039733887, 0.8778203725814819, 0.33128249645233154, 0.834447979927063, 0.48827049136161804, 0.4859340786933899, 0.48985549807548523, 0.9299905896186829, 0.74111008644104, 0.3173747658729553, 0.4210527539253235, 0.6586883068084717, 0.4021252691745758], "final_mean_entropy": 1.1236845869530954, "final_min_margin": 0.26200103759765625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This image appears to be a graphic or infographic related to the topic of \"Microblog", "used_ocr": false, "answer_first": "This image appears to be a graphic or infographic related to the topic of \"Microblog", "answer_second": null, "raw_answer": "This image appears to be a graphic or infographic related to the topic of \"Microblog", "raw_answer_first": "This image appears to be a graphic or infographic related to the topic of \"Microblog", "raw_answer_second": null, "mean_entropy_first": 0.9675536343012936, "normalized_entropy_first": 0.22073508748189855, "min_margin_first": 0.27416038513183594, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1512, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1514, "total_latency_s": 1.514, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.77558434009552, 0.7218120098114014, 1.0150868892669678, 0.000156637019244954, 0.03257237374782562, 0.7485805153846741, 2.8913393020629883, 0.46034958958625793, 1.8092565536499023, 2.110567331314087, 0.011899641714990139, 2.1343374252319336, 0.00023432032321579754, 1.5233721733093262, 2.8020505905151367, 0.08361518383026123, 1.2899138927459717, 0.5018777251243591, 0.3753972351551056, 0.06306895613670349], "entropies_second": null, "final_normalized_entropy": 0.22073508748189855, "sequence_confidence_first": 0.6645217685195886, "sequence_confidence_second": null, "sequence_confidence_final": 0.6645217685195886, "token_confidences_first": [0.604101300239563, 0.7209487557411194, 0.6502768397331238, 0.99998939037323, 0.9962676167488098, 0.5902435183525085, 0.26349908113479614, 0.8348175883293152, 0.5900272130966187, 0.39672863483428955, 0.9986087679862976, 0.5220915079116821, 0.9999845027923584, 0.5849698185920715, 0.2815593183040619, 0.9845232963562012, 0.491112619638443, 0.8783565163612366, 0.9096246957778931, 0.9911835193634033], "token_confidences_second": null, "final_mean_entropy": 0.9675536343012936, "final_min_margin": 0.27416038513183594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a graphic or infographic related to the future of", "used_ocr": false, "answer_first": "The image you've provided appears to be a graphic or infographic related to the future of", "answer_second": null, "raw_answer": "The image you've provided appears to be a graphic or infographic related to the future of", "raw_answer_first": "The image you've provided appears to be a graphic or infographic related to the future of", "raw_answer_second": null, "mean_entropy_first": 0.7729824744877988, "normalized_entropy_first": -0.9057807385891922, "min_margin_first": 0.45868873596191406, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1195, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1197, "total_latency_s": 1.197, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.9379072189331055, 0.0527571365237236, 1.4055585861206055, 0.24844247102737427, 0.004581007175147533, 0.7169687747955322, 0.8405572175979614, 6.749553722329438e-05, 0.01897415891289711, 0.6795810461044312, 3.0914509296417236, 0.4394744634628296, 1.2785248756408691, 1.9557974338531494, 0.011871588416397572, 1.9892723560333252, 0.00014884467236697674, 0.7448869943618774, 0.9010536670684814, 0.14177322387695312], "entropies_second": null, "final_normalized_entropy": -0.9057807385891922, "sequence_confidence_first": 0.7435550767615531, "sequence_confidence_second": null, "sequence_confidence_final": 0.7435550767615531, "token_confidences_first": [0.6492300033569336, 0.9939596652984619, 0.5828936696052551, 0.946852445602417, 0.9995229244232178, 0.6558442115783691, 0.612156331539154, 0.9999959468841553, 0.9978156089782715, 0.6570581793785095, 0.3286130130290985, 0.8497571349143982, 0.7388449907302856, 0.42708832025527954, 0.9985694885253906, 0.5177043080329895, 0.9999902248382568, 0.8020686507225037, 0.7950145602226257, 0.9804437160491943], "token_confidences_second": null, "final_mean_entropy": 0.7729824744877988, "final_min_margin": 0.45868873596191406, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image is as follows:\n\nTHE DATA B", "used_ocr": true, "answer_first": "The image you've provided appears to be an infographic or a chart that lists the types of", "answer_second": "The OCR-extracted text from the image is as follows:\n\nTHE DATA B", "raw_answer": "The OCR-extracted text from the image is as follows:\n\nTHE DATA B", "raw_answer_first": "The image you've provided appears to be an infographic or a chart that lists the types of", "raw_answer_second": "The OCR-extracted text from the image is as follows:\n\nTHE DATA B", "mean_entropy_first": 1.1379097249882761, "normalized_entropy_first": 1.2924493081585589, "min_margin_first": 0.028690338134765625, "mean_entropy_second": 0.5629185238285572, "normalized_entropy_second": -2.0455734984787637, "min_margin_second": 0.021183013916015625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1306, "latency_ms_ocr": 486, "latency_ms_second": 1368, "total_latency_ms": 3162, "total_latency_s": 3.162, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8755019307136536, 0.07202501595020294, 1.8261778354644775, 0.2737160921096802, 0.004047741182148457, 0.7247317433357239, 1.0109888315200806, 0.0002117204712703824, 0.06893078982830048, 0.744162917137146, 0.4837140440940857, 0.012912214733660221, 2.552593469619751, 2.2233448028564453, 2.793229579925537, 2.85176420211792, 2.6499922275543213, 2.301103353500366, 1.2837724685668945, 0.005273519083857536], "entropies_second": [2.3661065101623535, 1.6742274761199951, 0.001197211560793221, 0.625641942024231, 0.15351541340351105, 0.0004618646635208279, 0.004577981308102608, 1.8117479085922241, 0.012359043583273888, 0.04585228115320206, 1.7672423124313354, 1.610396385192871, 0.019480321556329727, 0.20477911829948425, 0.0018583463970571756, 0.05898353084921837, 0.6749405860900879, 0.03782106563448906, 0.0027000633999705315, 0.18448111414909363], "final_normalized_entropy": -2.0455734984787637, "sequence_confidence_first": 0.5827771656830808, "sequence_confidence_second": 0.8007322645683272, "sequence_confidence_final": 0.8007322645683272, "token_confidences_first": [0.5972214937210083, 0.9910197854042053, 0.36033234000205994, 0.9390000700950623, 0.9995629191398621, 0.6545714735984802, 0.4782876670360565, 0.9999849796295166, 0.990918755531311, 0.5040327310562134, 0.8990408182144165, 0.9984766840934753, 0.3483683466911316, 0.3529978096485138, 0.3882068693637848, 0.27093735337257385, 0.21584609150886536, 0.35952651500701904, 0.7244806289672852, 0.9994365572929382], "token_confidences_second": [0.40574464201927185, 0.4366379380226135, 0.9998900890350342, 0.8391618132591248, 0.9769017100334167, 0.9999617338180542, 0.9996248483657837, 0.4450746178627014, 0.998475968837738, 0.9931496977806091, 0.3832733929157257, 0.6099110245704651, 0.9979718327522278, 0.9638261795043945, 0.9998476505279541, 0.9909960627555847, 0.8569788932800293, 0.9957976341247559, 0.9997703433036804, 0.9642252326011658], "final_mean_entropy": 0.5629185238285572, "final_min_margin": 0.021183013916015625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a graphic or poster related to the topic of G", "used_ocr": true, "answer_first": "The image you've provided appears to be a graphic or poster related to the topic of G", "answer_second": "The text extracted from the image appears to be a mix of factual information and some interpretations or", "raw_answer": "The image you've provided appears to be a graphic or poster related to the topic of G", "raw_answer_first": "The image you've provided appears to be a graphic or poster related to the topic of G", "raw_answer_second": "The text extracted from the image appears to be a mix of factual information and some interpretations or", "mean_entropy_first": 1.2711725343586295, "normalized_entropy_first": 1.8898589562037067, "min_margin_first": 0.08714103698730469, "mean_entropy_second": 1.4126733913319185, "normalized_entropy_second": 2.6913941130798014, "min_margin_second": 0.0788106918334961, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1028, "latency_ms_ocr": 4949, "latency_ms_second": 1390, "total_latency_ms": 7370, "total_latency_s": 7.37, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.9989275932312012, 0.03235765919089317, 1.1463310718536377, 0.3585955798625946, 0.0073576136492192745, 0.6636326313018799, 0.8770767450332642, 0.00010823810589499772, 0.04555749148130417, 0.8530430197715759, 3.790914297103882, 0.40925878286361694, 1.624571681022644, 2.5375823974609375, 2.28922963142395, 0.00038801872869953513, 3.2210073471069336, 3.2929155826568604, 0.07635574042797089, 3.19823956489563], "entropies_second": [1.637770652770996, 1.6128681898117065, 1.6033779382705688, 0.13349908590316772, 0.00510374316945672, 0.02442835085093975, 2.209364414215088, 0.27023112773895264, 0.7443244457244873, 2.8465464115142822, 2.503598690032959, 0.01593051292002201, 3.616210699081421, 0.2991703152656555, 0.5319944620132446, 0.713353157043457, 3.8675224781036377, 4.043697357177734, 0.2221931517124176, 1.3522826433181763], "final_normalized_entropy": 1.8898589562037067, "sequence_confidence_first": 0.5588554141185671, "sequence_confidence_second": 0.5391297752420835, "sequence_confidence_final": 0.5588554141185671, "token_confidences_first": [0.6023445725440979, 0.9968326687812805, 0.6632325649261475, 0.9142433404922485, 0.9993228912353516, 0.7152685523033142, 0.7020746469497681, 0.9999935626983643, 0.9939990043640137, 0.508134126663208, 0.11617777496576309, 0.8635566830635071, 0.688291072845459, 0.31445959210395813, 0.316733717918396, 0.9999740123748779, 0.18410469591617584, 0.323629766702652, 0.9863212704658508, 0.23676033318042755], "token_confidences_second": [0.6687586307525635, 0.49240797758102417, 0.4447139501571655, 0.9824428558349609, 0.9994625449180603, 0.997323751449585, 0.3232157826423645, 0.9537985920906067, 0.8197028636932373, 0.30861684679985046, 0.4325296878814697, 0.9980181455612183, 0.1685820370912552, 0.9261974096298218, 0.876585066318512, 0.8342075943946838, 0.14455975592136383, 0.09567803889513016, 0.9546693563461304, 0.5912970900535583], "final_mean_entropy": 1.2711725343586295, "final_min_margin": 0.08714103698730469, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a promotional graphic or advertisement for", "used_ocr": false, "answer_first": "The image you've provided appears to be a promotional graphic or advertisement for", "answer_second": null, "raw_answer": "The image you've provided appears to be a promotional graphic or advertisement for", "raw_answer_first": "The image you've provided appears to be a promotional graphic or advertisement for", "raw_answer_second": null, "mean_entropy_first": 0.7296528455051885, "normalized_entropy_first": -1.2365122774206558, "min_margin_first": 0.019189834594726562, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1185, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1188, "total_latency_s": 1.188, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.0551087856292725, 0.1376313418149948, 1.629453420639038, 0.33663269877433777, 0.0034549315460026264, 0.6583424210548401, 0.8928977847099304, 0.00020141062850598246, 0.040837518870830536, 0.7702603340148926, 3.254925489425659, 0.0020240508019924164, 0.000559744075872004, 1.9321831464767456, 0.007771408185362816, 1.1142687797546387, 1.6898810863494873, 0.004565867595374584, 0.0023536973167210817, 1.05970299243927], "entropies_second": null, "final_normalized_entropy": -1.2365122774206558, "sequence_confidence_first": 0.6929240367957837, "sequence_confidence_second": null, "sequence_confidence_final": 0.6929240367957837, "token_confidences_first": [0.610156774520874, 0.9826547503471375, 0.3716824948787689, 0.9205245971679688, 0.9996416568756104, 0.7265149354934692, 0.6545701622962952, 0.9999873638153076, 0.9945810437202454, 0.513169527053833, 0.20982961356639862, 0.9998236298561096, 0.9999603033065796, 0.2925069034099579, 0.9991126656532288, 0.4807376265525818, 0.5663217902183533, 0.9995467066764832, 0.9997671246528625, 0.7843775153160095], "token_confidences_second": null, "final_mean_entropy": 0.7296528455051885, "final_min_margin": 0.019189834594726562, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be an infographic related to the popular ride-sharing", "used_ocr": false, "answer_first": "The image you've provided appears to be an infographic related to the popular ride-sharing", "answer_second": null, "raw_answer": "The image you've provided appears to be an infographic related to the popular ride-sharing", "raw_answer_first": "The image you've provided appears to be an infographic related to the popular ride-sharing", "raw_answer_second": null, "mean_entropy_first": 0.7369440056070744, "normalized_entropy_first": -1.0558212603577386, "min_margin_first": 0.021392822265625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1227, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1229, "total_latency_s": 1.229, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8306269645690918, 0.18588435649871826, 2.0314228534698486, 0.2938770055770874, 0.00282111088745296, 0.740925133228302, 1.09506356716156, 0.00015316410281229764, 0.06662372499704361, 0.7377848625183105, 0.47618964314460754, 0.013702446594834328, 2.6608543395996094, 0.00026759126922115684, 1.0313878059387207, 2.906614065170288, 1.078940510749817, 0.024523092433810234, 0.5610886812210083, 0.00012919300934299827], "entropies_second": null, "final_normalized_entropy": -1.0558212603577386, "sequence_confidence_first": 0.65001142305101, "sequence_confidence_second": null, "sequence_confidence_final": 0.65001142305101, "token_confidences_first": [0.5405671000480652, 0.9681189060211182, 0.25593113899230957, 0.9322484135627747, 0.9997157454490662, 0.6436454653739929, 0.46828222274780273, 0.9999903440475464, 0.9917405843734741, 0.5879102349281311, 0.883605420589447, 0.9983647465705872, 0.21753567457199097, 0.9999816417694092, 0.5774295926094055, 0.14838525652885437, 0.6562489867210388, 0.9971108436584473, 0.7682146430015564, 0.9999914169311523], "token_confidences_second": null, "final_mean_entropy": 0.7369440056070744, "final_min_margin": 0.021392822265625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image is a graphic representation of a speech by President Obama, summarizing key terms from", "used_ocr": true, "answer_first": "The image is a graphic representation of a speech by President Obama, summarizing key terms from", "answer_second": "The text extracted from the image appears to be a mix of words and phrases that are related to", "raw_answer": "The image is a graphic representation of a speech by President Obama, summarizing key terms from", "raw_answer_first": "The image is a graphic representation of a speech by President Obama, summarizing key terms from", "raw_answer_second": "The text extracted from the image appears to be a mix of words and phrases that are related to", "mean_entropy_first": 1.3815297801414999, "normalized_entropy_first": 2.292718042885493, "min_margin_first": 0.024053573608398438, "mean_entropy_second": 1.4724941987427882, "normalized_entropy_second": 2.7503445402591833, "min_margin_second": 0.0037927627563476562, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1345, "latency_ms_ocr": 275, "latency_ms_second": 1404, "total_latency_ms": 3027, "total_latency_s": 3.027, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.9607316851615906, 0.09610985219478607, 1.991161823272705, 0.6663722395896912, 1.8071107864379883, 0.6031472086906433, 2.356271505355835, 2.2472052574157715, 1.9313044548034668, 2.0554354190826416, 2.802992343902588, 0.5136030912399292, 0.36927464604377747, 7.899924094090238e-05, 1.9876503944396973, 3.3165576457977295, 0.7017604112625122, 1.404404878616333, 0.4903601408004761, 1.329062819480896], "entropies_second": [2.149141311645508, 2.07763409614563, 1.1020537614822388, 0.18322351574897766, 0.003996602725237608, 0.016968023031949997, 2.0757055282592773, 0.16780558228492737, 1.1760636568069458, 2.5799293518066406, 2.9517736434936523, 0.01821516826748848, 3.3856096267700195, 1.8837870359420776, 1.1672444343566895, 0.0005839469376951456, 1.977646827697754, 2.946780204772949, 3.3750317096710205, 0.2106899470090866], "final_normalized_entropy": 2.292718042885493, "sequence_confidence_first": 0.5303472012205395, "sequence_confidence_second": 0.5475647025531943, "sequence_confidence_final": 0.5303472012205395, "token_confidences_first": [0.7533354163169861, 0.9880784153938293, 0.21290059387683868, 0.8504207134246826, 0.5320273637771606, 0.7200223803520203, 0.3374769985675812, 0.4516837000846863, 0.32693976163864136, 0.5578778982162476, 0.3024047613143921, 0.9000746011734009, 0.8792380690574646, 0.9999943971633911, 0.29913315176963806, 0.20833200216293335, 0.5166162252426147, 0.43486568331718445, 0.8916105031967163, 0.7227025628089905], "token_confidences_second": [0.4499608874320984, 0.35808566212654114, 0.7405421733856201, 0.9746399521827698, 0.9995966553688049, 0.9982631802558899, 0.36970090866088867, 0.9757183790206909, 0.59858638048172, 0.3998391926288605, 0.37424418330192566, 0.9978339076042175, 0.1993880569934845, 0.4261227548122406, 0.8184741735458374, 0.9999520778656006, 0.5167064666748047, 0.2758023738861084, 0.1637156456708908, 0.9672365784645081], "final_mean_entropy": 1.3815297801414999, "final_min_margin": 0.024053573608398438, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided is a colorful infographic titled \"Government Support for the", "used_ocr": false, "answer_first": "The image you've provided is a colorful infographic titled \"Government Support for the", "answer_second": null, "raw_answer": "The image you've provided is a colorful infographic titled \"Government Support for the", "raw_answer_first": "The image you've provided is a colorful infographic titled \"Government Support for the", "raw_answer_second": null, "mean_entropy_first": 0.5441875745367725, "normalized_entropy_first": -1.8340156211024785, "min_margin_first": 0.016819000244140625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1367, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1368, "total_latency_s": 1.368, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.7694011926651001, 0.06929410994052887, 1.6519417762756348, 0.2468266487121582, 0.0027866759337484837, 0.6643735766410828, 0.849817156791687, 0.7330406308174133, 2.5550122261047363, 0.033853113651275635, 0.967083215713501, 0.014533255249261856, 1.802969217300415, 0.012311909347772598, 0.22257055342197418, 0.0023601404391229153, 0.000862681888975203, 0.15815132856369019, 0.025450170040130615, 0.10111191123723984], "entropies_second": null, "final_normalized_entropy": -1.8340156211024785, "sequence_confidence_first": 0.7754268552733758, "sequence_confidence_second": null, "sequence_confidence_final": 0.7754268552733758, "token_confidences_first": [0.49911150336265564, 0.990439772605896, 0.45138445496559143, 0.9467222690582275, 0.9997161030769348, 0.7077839970588684, 0.561635434627533, 0.6193642616271973, 0.37575194239616394, 0.9950693845748901, 0.7859963178634644, 0.998242974281311, 0.44558584690093994, 0.9987323880195618, 0.9612559676170349, 0.9997742772102356, 0.9999295473098755, 0.9651520848274231, 0.9973247051239014, 0.9838054180145264], "token_confidences_second": null, "final_mean_entropy": 0.5441875745367725, "final_min_margin": 0.016819000244140625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This image is a graphical representation of the \"2018 Cruise Industry\" presented", "used_ocr": false, "answer_first": "This image is a graphical representation of the \"2018 Cruise Industry\" presented", "answer_second": null, "raw_answer": "This image is a graphical representation of the \"2018 Cruise Industry\" presented", "raw_answer_first": "This image is a graphical representation of the \"2018 Cruise Industry\" presented", "raw_answer_second": null, "mean_entropy_first": 0.7554345158865544, "normalized_entropy_first": -0.6781051058254716, "min_margin_first": 0.10697555541992188, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1409, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1410, "total_latency_s": 1.41, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8383422493934631, 0.8272779583930969, 1.0833877325057983, 1.046446442604065, 2.65549635887146, 0.6764215230941772, 0.7066824436187744, 0.536691427230835, 0.5680491328239441, 1.5303685665130615, 0.3788716495037079, 0.00346803548745811, 0.0009398562251590192, 0.006321600638329983, 0.10382243245840073, 0.0005322805372998118, 0.004888657480478287, 3.992342317360453e-05, 2.28759765625, 1.8530443906784058], "entropies_second": null, "final_normalized_entropy": -0.6781051058254716, "sequence_confidence_first": 0.7017105315569204, "sequence_confidence_second": null, "sequence_confidence_final": 0.7017105315569204, "token_confidences_first": [0.5857920050621033, 0.5846335291862488, 0.5503997802734375, 0.6099112033843994, 0.35236307978630066, 0.6347089409828186, 0.8634845018386841, 0.903042197227478, 0.9054517149925232, 0.3086567521095276, 0.9100362658500671, 0.9996304512023926, 0.9999241828918457, 0.9993435740470886, 0.983111560344696, 0.9999597072601318, 0.9995748400688171, 0.9999974966049194, 0.2901271879673004, 0.5769672393798828], "token_confidences_second": null, "final_mean_entropy": 0.7554345158865544, "final_min_margin": 0.10697555541992188, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a collage of various statistics and data points related to", "used_ocr": true, "answer_first": "The image you've provided appears to be a collage of various statistics and data points related to", "answer_second": "The image you've provided appears to be a collage of various charts and statistics related to cloud", "raw_answer": "The image you've provided appears to be a collage of various statistics and data points related to", "raw_answer_first": "The image you've provided appears to be a collage of various statistics and data points related to", "raw_answer_second": "The image you've provided appears to be a collage of various charts and statistics related to cloud", "mean_entropy_first": 0.9634888624786981, "normalized_entropy_first": 0.21045257504602424, "min_margin_first": 0.14855575561523438, "mean_entropy_second": 1.064922998615657, "normalized_entropy_second": 0.6197203405580781, "min_margin_second": 0.08917999267578125, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1053, "latency_ms_ocr": 3354, "latency_ms_second": 1413, "total_latency_ms": 5823, "total_latency_s": 5.823, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.1023128032684326, 0.044175781309604645, 1.24643075466156, 0.3397102653980255, 0.0014794457238167524, 0.6005931496620178, 0.9281830191612244, 0.0003641823132056743, 0.051100291311740875, 0.4728739261627197, 3.558896541595459, 0.002307418268173933, 0.804377555847168, 0.9455569386482239, 2.50201416015625, 1.0108702182769775, 2.819460391998291, 1.1455764770507812, 1.6797423362731934, 0.013751592487096786], "entropies_second": [1.7569224834442139, 1.6696525812149048, 1.7298530340194702, 0.6909955739974976, 0.012740245088934898, 0.29867368936538696, 1.0740033388137817, 0.000954102782998234, 0.34410473704338074, 0.8557024598121643, 3.646480083465576, 0.0031714215874671936, 0.685280442237854, 1.3082973957061768, 2.4707491397857666, 0.6367602944374084, 2.073331594467163, 0.8938652276992798, 0.0041754404082894325, 1.1427466869354248], "final_normalized_entropy": 0.21045257504602424, "sequence_confidence_first": 0.6676081379567383, "sequence_confidence_second": 0.6258435615149379, "sequence_confidence_final": 0.6676081379567383, "token_confidences_first": [0.5739341974258423, 0.9951320886611938, 0.6332454681396484, 0.9181810021400452, 0.9998724460601807, 0.7534253001213074, 0.6838316321372986, 0.9999767541885376, 0.9927865862846375, 0.8450731635093689, 0.2335486263036728, 0.9997943043708801, 0.6158198714256287, 0.8290721774101257, 0.2797877788543701, 0.6025919914245605, 0.26935186982154846, 0.7585986256599426, 0.5256142616271973, 0.9984580278396606], "token_confidences_second": [0.6345939040184021, 0.40044647455215454, 0.30742087960243225, 0.7242047190666199, 0.9984911680221558, 0.9244159460067749, 0.6521890163421631, 0.9999363422393799, 0.9207061529159546, 0.5370796918869019, 0.2256101369857788, 0.9997027516365051, 0.7534431219100952, 0.7438551783561707, 0.3030250072479248, 0.7121807336807251, 0.3251516819000244, 0.8224765062332153, 0.9995943903923035, 0.6919792294502258], "final_mean_entropy": 0.9634888624786981, "final_min_margin": 0.14855575561523438, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image is as follows:\n\nCOVID-1", "used_ocr": true, "answer_first": "The image shows a bar chart titled \"COVID-19: France\" which compares daily", "answer_second": "The OCR-extracted text from the image is as follows:\n\nCOVID-1", "raw_answer": "The OCR-extracted text from the image is as follows:\n\nCOVID-1", "raw_answer_first": "The image shows a bar chart titled \"COVID-19: France\" which compares daily", "raw_answer_second": "The OCR-extracted text from the image is as follows:\n\nCOVID-1", "mean_entropy_first": 0.7518044019117951, "normalized_entropy_first": -0.6991087222795505, "min_margin_first": 0.022510528564453125, "mean_entropy_second": 0.46870974865159953, "normalized_entropy_second": -1.900471549993795, "min_margin_second": 0.4112262725830078, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1616, "latency_ms_ocr": 295, "latency_ms_second": 1666, "total_latency_ms": 3579, "total_latency_s": 3.579, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.7693886756896973, 0.16279947757720947, 1.8908517360687256, 0.23056304454803467, 2.037971019744873, 0.40156155824661255, 1.4537707567214966, 0.04925090819597244, 0.1348177194595337, 0.010489379987120628, 0.08002910763025284, 0.0013686828315258026, 0.0015051108784973621, 0.20176246762275696, 0.4980494976043701, 1.1929253339767456, 2.497222900390625, 2.3768527507781982, 0.0007450408302247524, 1.0441628694534302], "entropies_second": [1.1426540613174438, 1.5808579921722412, 0.0018226526444777846, 0.6032036542892456, 0.15011902153491974, 0.0005723426584154367, 0.00443282863125205, 1.590652346611023, 0.011572975665330887, 0.020645923912525177, 1.5571577548980713, 2.0438289642333984, 0.026602063328027725, 0.08782042562961578, 0.0038836870808154345, 0.08826354146003723, 0.4281681180000305, 0.018846046179533005, 0.009765957482159138, 0.003324615303426981], "final_normalized_entropy": -1.900471549993795, "sequence_confidence_first": 0.6758278018271113, "sequence_confidence_second": 0.8376558915373209, "sequence_confidence_final": 0.8376558915373209, "token_confidences_first": [0.5267897844314575, 0.9726938605308533, 0.24656689167022705, 0.9601825475692749, 0.3498021960258484, 0.8684709668159485, 0.6886947751045227, 0.9942828416824341, 0.9746299982070923, 0.9987945556640625, 0.9891806244850159, 0.999895453453064, 0.9998780488967896, 0.9723390340805054, 0.8622724413871765, 0.5292214751243591, 0.2296496331691742, 0.3386862874031067, 0.9999299049377441, 0.4712795913219452], "token_confidences_second": [0.7680761814117432, 0.4263565242290497, 0.9998260140419006, 0.8528090119361877, 0.97525554895401, 0.9999513626098633, 0.9996384382247925, 0.5147701501846313, 0.9985927939414978, 0.9973989725112915, 0.5251675844192505, 0.4413025975227356, 0.9971886277198792, 0.9864717125892639, 0.9996399879455566, 0.986624002456665, 0.9247221946716309, 0.9980000853538513, 0.9991624355316162, 0.999721348285675], "final_mean_entropy": 0.46870974865159953, "final_min_margin": 0.4112262725830078, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a graphic or poster related to environmental and health issues", "used_ocr": false, "answer_first": "The image you've provided appears to be a graphic or poster related to environmental and health issues", "answer_second": null, "raw_answer": "The image you've provided appears to be a graphic or poster related to environmental and health issues", "raw_answer_first": "The image you've provided appears to be a graphic or poster related to environmental and health issues", "raw_answer_second": null, "mean_entropy_first": 0.8915425437960949, "normalized_entropy_first": -0.03725236277141936, "min_margin_first": 0.17681884765625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1353, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1354, "total_latency_s": 1.354, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8524731993675232, 0.02341974899172783, 1.7722892761230469, 0.2802850902080536, 0.0019978913478553295, 0.6459797024726868, 0.8675801157951355, 7.629759784322232e-05, 0.024016767740249634, 0.9124659895896912, 2.693321704864502, 0.45422840118408203, 1.6778002977371216, 2.0465331077575684, 1.8597043752670288, 0.00011386309051886201, 1.449549913406372, 1.0048155784606934, 0.39708656072616577, 0.8671129941940308], "entropies_second": null, "final_normalized_entropy": -0.03725236277141936, "sequence_confidence_first": 0.6719289026809468, "sequence_confidence_second": null, "sequence_confidence_final": 0.6719289026809468, "token_confidences_first": [0.5712921023368835, 0.9974842071533203, 0.32131868600845337, 0.9367141723632812, 0.9998067021369934, 0.7301216721534729, 0.6014341711997986, 0.9999953508377075, 0.9970312118530273, 0.55143803358078, 0.36156901717185974, 0.8368420004844666, 0.6037968397140503, 0.46974995732307434, 0.5496646165847778, 0.999993085861206, 0.48230576515197754, 0.5191284418106079, 0.8754416704177856, 0.8221380710601807], "token_confidences_second": null, "final_mean_entropy": 0.8915425437960949, "final_min_margin": 0.17681884765625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a graphic or poster related to healthcare trends", "used_ocr": true, "answer_first": "The image you've provided appears to be a graphic or poster related to healthcare trends", "answer_second": "The text extracted from the image appears to be a summary of a report or presentation on trends in", "raw_answer": "The image you've provided appears to be a graphic or poster related to healthcare trends", "raw_answer_first": "The image you've provided appears to be a graphic or poster related to healthcare trends", "raw_answer_second": "The text extracted from the image appears to be a summary of a report or presentation on trends in", "mean_entropy_first": 0.9993006998924102, "normalized_entropy_first": 0.4607490509562353, "min_margin_first": 0.19261550903320312, "mean_entropy_second": 1.1714760134229436, "normalized_entropy_second": 1.2533942517882253, "min_margin_second": 0.014162063598632812, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1165, "latency_ms_ocr": 2731, "latency_ms_second": 1446, "total_latency_ms": 5345, "total_latency_s": 5.345, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.1778345108032227, 0.05399210751056671, 1.6706832647323608, 0.29361388087272644, 0.0058284481056034565, 0.6828184723854065, 0.8865731954574585, 9.486130147706717e-05, 0.03806179016828537, 0.7843794822692871, 2.7592849731445312, 0.3725675940513611, 1.2815072536468506, 1.9422024488449097, 2.3019115924835205, 0.00012109986710129306, 2.31265926361084, 1.4592007398605347, 1.9601690769195557, 0.0025099418126046658], "entropies_second": [1.4132567644119263, 1.656481385231018, 1.394485354423523, 0.12481193244457245, 0.0036305696703493595, 0.01623408868908882, 2.130776882171631, 0.2860648036003113, 0.511396050453186, 2.4831438064575195, 2.694244384765625, 0.2853454351425171, 1.8325800895690918, 1.2319259643554688, 1.214516520500183, 1.4883918762207031, 2.34375, 1.894345760345459, 0.0049412790685892105, 0.41919732093811035], "final_normalized_entropy": 0.4607490509562353, "sequence_confidence_first": 0.6373240730253452, "sequence_confidence_second": 0.6046441575344838, "sequence_confidence_final": 0.6373240730253452, "token_confidences_first": [0.5942129492759705, 0.9939040541648865, 0.43163520097732544, 0.9332970976829529, 0.9993694424629211, 0.7020887732505798, 0.6529701352119446, 0.9999942779541016, 0.9947673082351685, 0.5948847532272339, 0.2477036863565445, 0.8836647868156433, 0.7370012998580933, 0.5133023262023926, 0.3844816982746124, 0.9999924898147583, 0.26211050152778625, 0.5659298896789551, 0.4013727605342865, 0.9997490048408508], "token_confidences_second": [0.7146367430686951, 0.36781495809555054, 0.5029910802841187, 0.9838895797729492, 0.9996306896209717, 0.998264729976654, 0.3581060767173767, 0.9503052830696106, 0.905348002910614, 0.2147216498851776, 0.33235299587249756, 0.9281442761421204, 0.5218217968940735, 0.7066488265991211, 0.7194695472717285, 0.6396511793136597, 0.34399110078811646, 0.30551451444625854, 0.9994255304336548, 0.9034377932548523], "final_mean_entropy": 0.9993006998924102, "final_min_margin": 0.19261550903320312, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a poster or infographic that compares the United Kingdom", "used_ocr": false, "answer_first": "The image you've provided appears to be a poster or infographic that compares the United Kingdom", "answer_second": null, "raw_answer": "The image you've provided appears to be a poster or infographic that compares the United Kingdom", "raw_answer_first": "The image you've provided appears to be a poster or infographic that compares the United Kingdom", "raw_answer_second": null, "mean_entropy_first": 0.9459702790525626, "normalized_entropy_first": 0.17644343658383518, "min_margin_first": 0.0502777099609375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1134, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1136, "total_latency_s": 1.136, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8893977999687195, 0.06397822499275208, 1.5792505741119385, 0.27243638038635254, 0.0031682983972132206, 0.6808744072914124, 0.9383114576339722, 8.733735012356192e-05, 0.0367768332362175, 0.786929726600647, 3.4128165245056152, 0.4911714792251587, 2.087411880493164, 0.015396124683320522, 2.4233031272888184, 2.4907703399658203, 0.00018094883125741035, 1.0123696327209473, 1.7218728065490723, 0.012901676818728447], "entropies_second": null, "final_normalized_entropy": 0.17644343658383518, "sequence_confidence_first": 0.6709058812368521, "sequence_confidence_second": null, "sequence_confidence_final": 0.6709058812368521, "token_confidences_first": [0.5254231691360474, 0.9927809834480286, 0.47875210642814636, 0.941007137298584, 0.9996851682662964, 0.7063456773757935, 0.6130038499832153, 0.9999948740005493, 0.9954745173454285, 0.5052139759063721, 0.27484261989593506, 0.9215070009231567, 0.3284379541873932, 0.9980814456939697, 0.38129377365112305, 0.4223613440990448, 0.9999854564666748, 0.7715644240379333, 0.6477379202842712, 0.998636782169342], "token_confidences_second": null, "final_mean_entropy": 0.9459702790525626, "final_min_margin": 0.0502777099609375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image is as follows:\n\nEQUITY RE", "used_ocr": true, "answer_first": "The image is an infographic titled \"Equity Report: The Latest Statistics.\" It provides information", "answer_second": "The OCR-extracted text from the image is as follows:\n\nEQUITY RE", "raw_answer": "The OCR-extracted text from the image is as follows:\n\nEQUITY RE", "raw_answer_first": "The image is an infographic titled \"Equity Report: The Latest Statistics.\" It provides information", "raw_answer_second": "The OCR-extracted text from the image is as follows:\n\nEQUITY RE", "mean_entropy_first": 0.7186026796567603, "normalized_entropy_first": -0.9819700925545254, "min_margin_first": 0.18853759765625, "mean_entropy_second": 0.540721491430304, "normalized_entropy_second": -1.8809685004410905, "min_margin_second": 0.06071662902832031, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1415, "latency_ms_ocr": 644, "latency_ms_second": 1452, "total_latency_ms": 3513, "total_latency_s": 3.513, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.7494274973869324, 0.055151280015707016, 1.8436400890350342, 0.9437320828437805, 0.5860645771026611, 0.016726963222026825, 1.827518105506897, 0.015199394896626472, 1.0969327688217163, 0.003607799531891942, 0.11259472370147705, 1.5428649187088013, 0.12942934036254883, 0.011259537190198898, 0.0003092591359745711, 0.03589404374361038, 1.1364011764526367, 0.5507220029830933, 1.6762439012527466, 2.0383341312408447], "entropies_second": [1.2511591911315918, 1.5705140829086304, 0.000915731827262789, 0.6036761403083801, 0.1606667935848236, 0.0003213388263247907, 0.004849300254136324, 1.8113816976547241, 0.009315037168562412, 0.024267073720693588, 1.6882107257843018, 2.352799654006958, 0.045173175632953644, 0.16018563508987427, 0.0024329712614417076, 0.12101300805807114, 1.0004642009735107, 0.0007632622146047652, 0.0019381350139155984, 0.004382673185318708], "final_normalized_entropy": -1.8809685004410905, "sequence_confidence_first": 0.7130248295459632, "sequence_confidence_second": 0.7815315464656596, "sequence_confidence_final": 0.7815315464656596, "token_confidences_first": [0.5984680652618408, 0.993724524974823, 0.2890361249446869, 0.5285791158676147, 0.877345085144043, 0.9979404807090759, 0.6014781594276428, 0.9983665347099304, 0.48786893486976624, 0.9996654987335205, 0.9786081910133362, 0.5303885340690613, 0.9791673421859741, 0.9987633228302002, 0.9999738931655884, 0.995416522026062, 0.549319326877594, 0.8590890765190125, 0.5868350267410278, 0.35390445590019226], "token_confidences_second": [0.7385019063949585, 0.36430466175079346, 0.999916672706604, 0.8504069447517395, 0.973849356174469, 0.9999744892120361, 0.999581515789032, 0.36703962087631226, 0.998923122882843, 0.9968926310539246, 0.39408761262893677, 0.2988234758377075, 0.99491947889328, 0.9732310175895691, 0.9997857213020325, 0.9791311025619507, 0.7958992123603821, 0.9999440908432007, 0.9997997879981995, 0.9995971322059631], "final_mean_entropy": 0.540721491430304, "final_min_margin": 0.06071662902832031, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This image is an infographic titled \"ECOLOGY\" that provides various statistics and facts about", "used_ocr": true, "answer_first": "This image is an infographic titled \"ECOLOGY\" that provides various statistics and facts about", "answer_second": "The text extracted from the image appears to be accurate based on the visual content. Here is the corrected", "raw_answer": "This image is an infographic titled \"ECOLOGY\" that provides various statistics and facts about", "raw_answer_first": "This image is an infographic titled \"ECOLOGY\" that provides various statistics and facts about", "raw_answer_second": "The text extracted from the image appears to be accurate based on the visual content. Here is the corrected", "mean_entropy_first": 0.9824199038848747, "normalized_entropy_first": 0.45254007304782357, "min_margin_first": 0.236419677734375, "mean_entropy_second": 1.0485980723053216, "normalized_entropy_second": 0.7892319372685297, "min_margin_second": 0.05066108703613281, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1617, "latency_ms_ocr": 354, "latency_ms_second": 1671, "total_latency_ms": 3644, "total_latency_s": 3.644, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.7866036891937256, 0.9275543093681335, 1.3241658210754395, 0.878404974937439, 0.7006866335868835, 0.009238108061254025, 2.440500497817993, 0.005968122743070126, 0.3083150088787079, 0.20408500730991364, 0.004170057829469442, 0.0006027623312547803, 1.8602662086486816, 1.7627084255218506, 2.0503668785095215, 1.898480772972107, 1.0533738136291504, 0.7965070009231567, 1.7145155668258667, 0.9218844175338745], "entropies_second": [1.923689603805542, 1.617518424987793, 1.3317911624908447, 0.23734091222286224, 0.01007855124771595, 0.020604519173502922, 1.9821462631225586, 0.2369912564754486, 0.9612187147140503, 2.6357674598693848, 2.060377597808838, 0.002247057855129242, 0.2451300024986267, 1.1608012914657593, 0.23241886496543884, 1.0879067182540894, 1.7921476364135742, 1.03166663646698, 0.34379634261131287, 2.0583224296569824], "final_normalized_entropy": 0.45254007304782357, "sequence_confidence_first": 0.6471125476615969, "sequence_confidence_second": 0.6153097211857468, "sequence_confidence_final": 0.6471125476615969, "token_confidences_first": [0.5754215717315674, 0.6142662763595581, 0.609605610370636, 0.6632235646247864, 0.8155077695846558, 0.9988711476325989, 0.33221009373664856, 0.9994298815727234, 0.9530968070030212, 0.9560285806655884, 0.9996125102043152, 0.9999507665634155, 0.41523054242134094, 0.46237942576408386, 0.4661557972431183, 0.3562210500240326, 0.7551336288452148, 0.7609233260154724, 0.4408514201641083, 0.5832145810127258], "token_confidences_second": [0.5230370759963989, 0.3449448347091675, 0.6371882557868958, 0.964629590511322, 0.9988131523132324, 0.9977300763130188, 0.3877512812614441, 0.9616531133651733, 0.7071029543876648, 0.21412904560565948, 0.31908491253852844, 0.9997798800468445, 0.9575627446174622, 0.6266005039215088, 0.960446298122406, 0.7234227657318115, 0.35137662291526794, 0.5218513011932373, 0.911342978477478, 0.4364177882671356], "final_mean_entropy": 0.9824199038848747, "final_min_margin": 0.236419677734375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a map showing the global carbon footprint by nation.", "used_ocr": true, "answer_first": "This image is a colorful infographic that illustrates the global carbon footprint by nation. The", "answer_second": "The image you've provided appears to be a map showing the global carbon footprint by nation.", "raw_answer": "The image you've provided appears to be a map showing the global carbon footprint by nation.", "raw_answer_first": "This image is a colorful infographic that illustrates the global carbon footprint by nation. The", "raw_answer_second": "The image you've provided appears to be a map showing the global carbon footprint by nation.", "mean_entropy_first": 1.0283237409661523, "normalized_entropy_first": 0.6686808138435097, "min_margin_first": 0.026580810546875, "mean_entropy_second": 1.0543183029047214, "normalized_entropy_second": 0.8066801628985881, "min_margin_second": 0.045322418212890625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1212, "latency_ms_ocr": 1019, "latency_ms_second": 1452, "total_latency_ms": 3686, "total_latency_s": 3.686, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.9512369632720947, 0.8041659593582153, 1.8872207403182983, 0.5248076319694519, 2.4227843284606934, 0.17500652372837067, 2.267009735107422, 0.013699909672141075, 2.2731683254241943, 1.784806728363037, 0.00012736732605844736, 0.6544861793518066, 1.135671854019165, 0.6078363060951233, 0.08475571870803833, 0.00021445390302687883, 1.3185639381408691, 1.255144476890564, 0.8238208293914795, 1.581946849822998], "entropies_second": [1.686816692352295, 1.4697961807250977, 2.0800743103027344, 0.6927961707115173, 0.009062042459845543, 0.35151588916778564, 1.121280312538147, 0.0008675436256453395, 0.40156126022338867, 0.6065148115158081, 3.093125581741333, 2.7169740200042725, 1.291560173034668, 1.5381865501403809, 0.4443630278110504, 0.06310577690601349, 0.0009351641638204455, 1.768357753753662, 0.7259897589683533, 1.0234830379486084], "final_normalized_entropy": 0.8066801628985881, "sequence_confidence_first": 0.6246306016126603, "sequence_confidence_second": 0.6332757311625502, "sequence_confidence_final": 0.6332757311625502, "token_confidences_first": [0.579841673374176, 0.5604121088981628, 0.3745579123497009, 0.8748452067375183, 0.3839007019996643, 0.962825357913971, 0.2623726427555084, 0.998353123664856, 0.22216728329658508, 0.4947395622730255, 0.9999911785125732, 0.8304718136787415, 0.7635982036590576, 0.7827095985412598, 0.9887984395027161, 0.9999862909317017, 0.6833831667900085, 0.6213443279266357, 0.8085988163948059, 0.4281086027622223], "token_confidences_second": [0.6637403964996338, 0.5680341124534607, 0.3054591715335846, 0.7369483709335327, 0.9989601373672485, 0.9081064462661743, 0.6749898195266724, 0.9999428987503052, 0.9159389138221741, 0.8285385370254517, 0.18028825521469116, 0.18566974997520447, 0.5959596633911133, 0.6257015466690063, 0.8625556230545044, 0.9920353293418884, 0.9999332427978516, 0.4845260977745056, 0.8443716168403625, 0.6244946122169495], "final_mean_entropy": 1.0543183029047214, "final_min_margin": 0.045322418212890625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a promotional graphic for a report titled \"", "used_ocr": true, "answer_first": "The image you've provided appears to be a promotional graphic for a report titled \"", "answer_second": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "raw_answer": "The image you've provided appears to be a promotional graphic for a report titled \"", "raw_answer_first": "The image you've provided appears to be a promotional graphic for a report titled \"", "raw_answer_second": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "mean_entropy_first": 0.7609853850077343, "normalized_entropy_first": -0.8430031971323296, "min_margin_first": 0.09691429138183594, "mean_entropy_second": 0.8408069932207581, "normalized_entropy_second": -0.4059893780228801, "min_margin_second": 0.04222869873046875, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1233, "latency_ms_ocr": 1215, "latency_ms_second": 1398, "total_latency_ms": 3848, "total_latency_s": 3.848, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.931304931640625, 0.07362061738967896, 1.7065916061401367, 0.2574446201324463, 0.003346408950164914, 0.7357567548751831, 0.8560948967933655, 6.229030987014994e-05, 0.010523716919124126, 0.8493128418922424, 2.034191131591797, 0.0016860461328178644, 0.00021511618979275227, 1.5045042037963867, 0.003696481930091977, 1.1591613292694092, 1.2464133501052856, 2.4181551933288574, 1.4109359979629517, 0.016690164804458618], "entropies_second": [1.4501765966415405, 1.6938259601593018, 0.0015149553073570132, 0.5213987827301025, 0.16385269165039062, 0.0002878490195143968, 0.003790708491578698, 1.8643096685409546, 0.01586802862584591, 0.042943768203258514, 1.813689947128296, 0.3234349489212036, 0.4295300245285034, 2.005110740661621, 0.33679354190826416, 1.651221513748169, 1.3695290088653564, 1.630903720855713, 0.23983758687973022, 1.258119821548462], "final_normalized_entropy": -0.8430031971323296, "sequence_confidence_first": 0.6795589905199153, "sequence_confidence_second": 0.6918555575916293, "sequence_confidence_final": 0.6795589905199153, "token_confidences_first": [0.5127274990081787, 0.990860104560852, 0.3289514482021332, 0.9443880319595337, 0.9996548891067505, 0.6260823607444763, 0.5092800855636597, 0.9999961853027344, 0.9988538026809692, 0.5073579549789429, 0.3665616512298584, 0.9998440742492676, 0.999985933303833, 0.5580824613571167, 0.999631404876709, 0.6086991429328918, 0.6420538425445557, 0.4175955653190613, 0.5194942951202393, 0.9981291890144348], "token_confidences_second": [0.6934033632278442, 0.3351687490940094, 0.9998558759689331, 0.8658722639083862, 0.973960280418396, 0.9999774694442749, 0.9996910095214844, 0.41026800870895386, 0.9980295300483704, 0.9938132762908936, 0.3889884650707245, 0.941373348236084, 0.9118784666061401, 0.35346874594688416, 0.911861002445221, 0.415058970451355, 0.5943067669868469, 0.4210265874862671, 0.9515331983566284, 0.744707465171814], "final_mean_entropy": 0.7609853850077343, "final_min_margin": 0.09691429138183594, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The text extracted from the image appears to be mostly accurate, but there are a few minor errors:", "used_ocr": true, "answer_first": "This is a graphic design that appears to be a poster or an advertisement for a cr", "answer_second": "The text extracted from the image appears to be mostly accurate, but there are a few minor errors:", "raw_answer": "The text extracted from the image appears to be mostly accurate, but there are a few minor errors:", "raw_answer_first": "This is a graphic design that appears to be a poster or an advertisement for a cr", "raw_answer_second": "The text extracted from the image appears to be mostly accurate, but there are a few minor errors:", "mean_entropy_first": 1.277954246714944, "normalized_entropy_first": 2.1100127192840663, "min_margin_first": 0.08574676513671875, "mean_entropy_second": 1.0866095886565745, "normalized_entropy_second": 1.0430192007489407, "min_margin_second": 0.012105941772460938, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1341, "latency_ms_ocr": 1396, "latency_ms_second": 1498, "total_latency_ms": 4236, "total_latency_s": 4.236, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.937311589717865, 0.9413816928863525, 0.7097421884536743, 2.7905993461608887, 0.2307664155960083, 1.3235664367675781, 3.027761936187744, 1.4384413957595825, 0.001590483239851892, 0.1808038353919983, 1.674614429473877, 3.164182662963867, 0.3739958107471466, 2.2369208335876465, 1.651229739189148, 0.010923406109213829, 0.002130149630829692, 1.0617059469223022, 1.9441146850585938, 1.857301950454712], "entropies_second": [1.4310153722763062, 1.6560328006744385, 1.587791919708252, 0.21752473711967468, 0.005573049187660217, 0.017974214628338814, 1.9774894714355469, 0.2498854696750641, 0.5739602446556091, 2.3230714797973633, 0.6637815833091736, 1.4178576469421387, 1.4751002788543701, 0.49644583463668823, 0.8346887826919556, 0.5192040801048279, 0.4217703342437744, 2.250870704650879, 1.9488978385925293, 1.6632559299468994], "final_normalized_entropy": 1.0430192007489407, "sequence_confidence_first": 0.5681492347070792, "sequence_confidence_second": 0.6072418859694659, "sequence_confidence_final": 0.6072418859694659, "token_confidences_first": [0.6100077629089355, 0.5568665862083435, 0.5201081037521362, 0.2710319757461548, 0.9389434456825256, 0.7519423961639404, 0.23834484815597534, 0.671326756477356, 0.9998779296875, 0.9752041697502136, 0.4830872416496277, 0.22833232581615448, 0.9212990999221802, 0.2604493796825409, 0.40744441747665405, 0.9988036155700684, 0.9997976422309875, 0.7644409537315369, 0.4566936790943146, 0.6192914843559265], "token_confidences_second": [0.7111144065856934, 0.45928943157196045, 0.4132261872291565, 0.9686877131462097, 0.9994043111801147, 0.9980429410934448, 0.374105304479599, 0.9578553438186646, 0.8644530177116394, 0.2843572497367859, 0.7555913329124451, 0.5688332915306091, 0.4474399983882904, 0.9079874157905579, 0.7057577967643738, 0.8418921232223511, 0.851547122001648, 0.3687243163585663, 0.3879837095737457, 0.3201284110546112], "final_mean_entropy": 1.0866095886565745, "final_min_margin": 0.012105941772460938, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The text extracted from the image appears to be accurate based on the visual content. Here is the text", "used_ocr": true, "answer_first": "This image appears to be a graphic representation of the demographics of LinkedIn users, established", "answer_second": "The text extracted from the image appears to be accurate based on the visual content. Here is the text", "raw_answer": "The text extracted from the image appears to be accurate based on the visual content. Here is the text", "raw_answer_first": "This image appears to be a graphic representation of the demographics of LinkedIn users, established", "raw_answer_second": "The text extracted from the image appears to be accurate based on the visual content. Here is the text", "mean_entropy_first": 1.188888588349073, "normalized_entropy_first": 1.2296189658057555, "min_margin_first": 0.049816131591796875, "mean_entropy_second": 0.9949371300230269, "normalized_entropy_second": 0.2813076160518361, "min_margin_second": 0.12123298645019531, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1357, "latency_ms_ocr": 326, "latency_ms_second": 1435, "total_latency_ms": 3121, "total_latency_s": 3.121, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.9740837216377258, 0.9081591963768005, 1.4361822605133057, 0.00010912999277934432, 0.06685087829828262, 0.6832490563392639, 3.1677024364471436, 0.6706861853599548, 2.0882811546325684, 0.9796733856201172, 2.1408660411834717, 1.8480850458145142, 0.6123910546302795, 0.0001883677177829668, 0.7156966924667358, 1.43003511428833, 0.016642160713672638, 1.3855605125427246, 2.0107674598693848, 2.642561912536621], "entropies_second": [1.7423193454742432, 1.6545202732086182, 1.4258277416229248, 0.1743503212928772, 0.004977548029273748, 0.018253980204463005, 1.855629563331604, 0.2648489475250244, 0.61513352394104, 2.1122305393218994, 1.8566019535064697, 0.0018080543959513307, 0.3022485673427582, 1.0116671323776245, 0.1597204953432083, 0.9014968872070312, 1.978184700012207, 1.0435839891433716, 0.3551284372806549, 2.420210599899292], "final_normalized_entropy": 0.2813076160518361, "sequence_confidence_first": 0.5478409519925858, "sequence_confidence_second": 0.6263012437206861, "sequence_confidence_final": 0.6263012437206861, "token_confidences_first": [0.4933897852897644, 0.6211072206497192, 0.48397311568260193, 0.999992847442627, 0.9908778071403503, 0.7193254828453064, 0.36457502841949463, 0.7191320061683655, 0.3595164120197296, 0.7720673084259033, 0.35543254017829895, 0.40908142924308777, 0.717204749584198, 0.9999876022338867, 0.7493579387664795, 0.3863928020000458, 0.9977614879608154, 0.4123350977897644, 0.24783317744731903, 0.2504035532474518], "token_confidences_second": [0.6048493981361389, 0.3802332878112793, 0.6174460649490356, 0.9759079217910767, 0.9994687438011169, 0.9980549812316895, 0.4010424315929413, 0.9542994499206543, 0.8641754984855652, 0.32880648970603943, 0.34861913323402405, 0.9998257756233215, 0.9455006122589111, 0.7122187614440918, 0.9758565425872803, 0.7850408554077148, 0.2511785626411438, 0.5349169969558716, 0.9032554030418396, 0.26285162568092346], "final_mean_entropy": 0.9949371300230269, "final_min_margin": 0.12123298645019531, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a comparison chart between the Indian cricket team and the", "used_ocr": false, "answer_first": "The image you've provided appears to be a comparison chart between the Indian cricket team and the", "answer_second": null, "raw_answer": "The image you've provided appears to be a comparison chart between the Indian cricket team and the", "raw_answer_first": "The image you've provided appears to be a comparison chart between the Indian cricket team and the", "raw_answer_second": null, "mean_entropy_first": 0.7718672906084976, "normalized_entropy_first": -0.9159617790951408, "min_margin_first": 0.01557159423828125, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1149, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1150, "total_latency_s": 1.15, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.1588480472564697, 0.05786997079849243, 1.6302567720413208, 0.30743250250816345, 0.0038513329345732927, 0.6782688498497009, 0.9976011514663696, 0.00011436764907557517, 0.05206409469246864, 0.36604174971580505, 3.0468220710754395, 1.796250581741333, 1.7476389408111572, 1.3346803188323975, 1.2311969995498657, 0.8620246648788452, 0.00537507189437747, 0.013658881187438965, 0.10890036821365356, 0.03844907507300377], "entropies_second": null, "final_normalized_entropy": -0.9159617790951408, "sequence_confidence_first": 0.6898285276622197, "sequence_confidence_second": null, "sequence_confidence_final": 0.6898285276622197, "token_confidences_first": [0.4555966556072235, 0.9930800795555115, 0.4461822509765625, 0.9303678870201111, 0.9995957016944885, 0.6861672401428223, 0.483602911233902, 0.999993085861206, 0.9925946593284607, 0.9041336178779602, 0.24332508444786072, 0.3829626441001892, 0.4450069069862366, 0.6070900559425354, 0.6849404573440552, 0.6319136619567871, 0.9993613362312317, 0.9985973238945007, 0.9845731854438782, 0.9947448968887329], "token_confidences_second": null, "final_mean_entropy": 0.7718672906084976, "final_min_margin": 0.01557159423828125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "used_ocr": true, "answer_first": "The image you've provided appears to be an infographic or a poster that outlines the impact", "answer_second": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "raw_answer": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "raw_answer_first": "The image you've provided appears to be an infographic or a poster that outlines the impact", "raw_answer_second": "The OCR-extracted text from the image appears to be mostly accurate, with a few minor", "mean_entropy_first": 1.1000270996904873, "normalized_entropy_first": 0.7613460997161857, "min_margin_first": 0.018795013427734375, "mean_entropy_second": 0.8907951571265584, "normalized_entropy_second": -0.2562474856403498, "min_margin_second": 0.38607215881347656, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1306, "latency_ms_ocr": 1549, "latency_ms_second": 1463, "total_latency_ms": 4324, "total_latency_s": 4.324, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8040822148323059, 0.06837146729230881, 2.0064988136291504, 0.32485517859458923, 0.0030946198385208845, 0.7223082780838013, 1.0264828205108643, 0.00018216155876871198, 0.05489557236433029, 0.779826283454895, 0.657236635684967, 0.010161802172660828, 2.1954593658447266, 2.353269577026367, 3.016547679901123, 2.3747386932373047, 2.34407377243042, 0.0001813100534491241, 1.0600781440734863, 2.198197603225708], "entropies_second": [1.3388094902038574, 1.5596923828125, 0.0012144851498305798, 0.47706925868988037, 0.12271656841039658, 0.0002507986209820956, 0.003466187044978142, 1.7746073007583618, 0.016986552625894547, 0.030964670702815056, 2.039947509765625, 0.224249929189682, 0.7622168064117432, 2.383010149002075, 0.6714109778404236, 1.5702475309371948, 1.6544080972671509, 1.60384202003479, 0.18152642250061035, 1.399266004562378], "final_normalized_entropy": -0.2562474856403498, "sequence_confidence_first": 0.596354444194675, "sequence_confidence_second": 0.6972038133964579, "sequence_confidence_final": 0.6972038133964579, "token_confidences_first": [0.691789984703064, 0.9917995929718018, 0.2825295031070709, 0.9221145510673523, 0.9996720552444458, 0.675208568572998, 0.6036069989204407, 0.9999874830245972, 0.9930035471916199, 0.49817219376564026, 0.8258531093597412, 0.9988464117050171, 0.4507744610309601, 0.27550527453422546, 0.2091473639011383, 0.3395595848560333, 0.3395605683326721, 0.9999865293502808, 0.6842029094696045, 0.5315110087394714], "token_confidences_second": [0.7317328453063965, 0.38254085183143616, 0.9998871088027954, 0.8807733654975891, 0.9815504550933838, 0.9999808073043823, 0.9996981620788574, 0.49797046184539795, 0.9977959394454956, 0.995863676071167, 0.43488940596580505, 0.9638025760650635, 0.8212267756462097, 0.3272688686847687, 0.8140284419059753, 0.532159149646759, 0.4563353955745697, 0.4015795588493347, 0.9657599329948425, 0.7125090956687927], "final_mean_entropy": 0.8907951571265584, "final_min_margin": 0.38607215881347656, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image appears to be a promotional poster for the \"UAE's First T2", "used_ocr": false, "answer_first": "The image appears to be a promotional poster for the \"UAE's First T2", "answer_second": null, "raw_answer": "The image appears to be a promotional poster for the \"UAE's First T2", "raw_answer_first": "The image appears to be a promotional poster for the \"UAE's First T2", "raw_answer_second": null, "mean_entropy_first": 0.48070533756399525, "normalized_entropy_first": -2.3845700068533917, "min_margin_first": 0.05377197265625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1378, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1378, "total_latency_s": 1.378, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8619088530540466, 0.11753323674201965, 1.809885859489441, 0.00011804095993284136, 0.0179925374686718, 0.6853686571121216, 1.0534507036209106, 0.0009185374365188181, 0.00011018830991815776, 1.075671911239624, 0.7170721292495728, 1.044421672821045, 1.45768404006958, 0.3028492331504822, 0.008108381181955338, 0.06954661756753922, 0.012064467184245586, 0.04487617313861847, 0.333175390958786, 0.0013501205248758197], "entropies_second": null, "final_normalized_entropy": -2.3845700068533917, "sequence_confidence_first": 0.7703812929241997, "sequence_confidence_second": null, "sequence_confidence_final": 0.7703812929241997, "token_confidences_first": [0.6409093141555786, 0.9819660782814026, 0.25839564204216003, 0.9999920129776001, 0.9979652166366577, 0.6780222058296204, 0.5567919611930847, 0.9999222755432129, 0.9999929666519165, 0.6479422450065613, 0.5652055144309998, 0.7053366899490356, 0.39754483103752136, 0.9553366899490356, 0.9990097284317017, 0.9894009232521057, 0.9983817338943481, 0.9939292669296265, 0.9198100566864014, 0.9998855590820312], "token_confidences_second": null, "final_mean_entropy": 0.48070533756399525, "final_min_margin": 0.05377197265625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This image is a graphic representation of MS Dhoni's milestone runs in OD", "used_ocr": false, "answer_first": "This image is a graphic representation of MS Dhoni's milestone runs in OD", "answer_second": null, "raw_answer": "This image is a graphic representation of MS Dhoni's milestone runs in OD", "raw_answer_first": "This image is a graphic representation of MS Dhoni's milestone runs in OD", "raw_answer_second": null, "mean_entropy_first": 0.8503978848177212, "normalized_entropy_first": -0.25544814448452285, "min_margin_first": 0.016262054443359375, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1288, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1289, "total_latency_s": 1.289, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.0019152164459229, 0.8412851095199585, 1.424398422241211, 0.33509188890457153, 3.1741814613342285, 0.6971480250358582, 3.3030734062194824, 1.0083980560302734, 2.572512149810791, 0.0016009529354050756, 0.008867669850587845, 8.859955414664e-05, 0.04534471780061722, 2.522415161365643e-05, 0.5097307562828064, 0.20739567279815674, 0.0642532929778099, 0.23190659284591675, 1.3786015510559082, 0.20213893055915833], "entropies_second": null, "final_normalized_entropy": -0.25544814448452285, "sequence_confidence_first": 0.6700240013076647, "sequence_confidence_second": null, "sequence_confidence_final": 0.6700240013076647, "token_confidences_first": [0.477102667093277, 0.5674414038658142, 0.42011287808418274, 0.9264553189277649, 0.3151934742927551, 0.5505571365356445, 0.19693711400032043, 0.8211026191711426, 0.3279537856578827, 0.9998571872711182, 0.998992383480072, 0.999994158744812, 0.9929715991020203, 0.9999985694885254, 0.9221025109291077, 0.947404146194458, 0.9930325746536255, 0.9666809439659119, 0.4299311339855194, 0.9588987231254578], "token_confidences_second": null, "final_mean_entropy": 0.8503978848177212, "final_min_margin": 0.016262054443359375, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image appears to be a promotional poster for the \"Road to Final Champions Trophy", "used_ocr": false, "answer_first": "The image appears to be a promotional poster for the \"Road to Final Champions Trophy", "answer_second": null, "raw_answer": "The image appears to be a promotional poster for the \"Road to Final Champions Trophy", "raw_answer_first": "The image appears to be a promotional poster for the \"Road to Final Champions Trophy", "raw_answer_second": null, "mean_entropy_first": 0.6604873893425974, "normalized_entropy_first": -1.0785518489397399, "min_margin_first": 0.13614463806152344, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1140, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1141, "total_latency_s": 1.141, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.1821069717407227, 0.2160566747188568, 1.6033935546875, 0.00019657102529890835, 0.023395221680402756, 0.7225409150123596, 1.0978538990020752, 0.0011772711295634508, 0.00013555803161580116, 1.2158315181732178, 0.7334019541740417, 0.9687836170196533, 2.675448417663574, 0.3780154287815094, 0.0008108915062621236, 0.11068832129240036, 0.2408807873725891, 1.9847495555877686, 0.0537295825779438, 0.0005510756745934486], "entropies_second": null, "final_normalized_entropy": -1.0785518489397399, "sequence_confidence_first": 0.7051905277645169, "sequence_confidence_second": null, "sequence_confidence_final": 0.7051905277645169, "token_confidences_first": [0.5449097752571106, 0.9605342745780945, 0.3539922833442688, 0.9999864101409912, 0.9973880648612976, 0.6531459093093872, 0.498930424451828, 0.9998980760574341, 0.9999911785125732, 0.6363496780395508, 0.6057474613189697, 0.5154014825820923, 0.22971700131893158, 0.9415194988250732, 0.9999349117279053, 0.9768730401992798, 0.9524369835853577, 0.3866204023361206, 0.9939637780189514, 0.9999557733535767], "token_confidences_second": null, "final_mean_entropy": 0.6604873893425974, "final_min_margin": 0.13614463806152344, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a promotional or informational graphic for a", "used_ocr": false, "answer_first": "The image you've provided appears to be a promotional or informational graphic for a", "answer_second": null, "raw_answer": "The image you've provided appears to be a promotional or informational graphic for a", "raw_answer_first": "The image you've provided appears to be a promotional or informational graphic for a", "raw_answer_second": null, "mean_entropy_first": 0.5844850247405702, "normalized_entropy_first": -1.3026105103826549, "min_margin_first": 0.08770179748535156, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1254, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1256, "total_latency_s": 1.256, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8403223752975464, 0.012233288027346134, 1.4145541191101074, 0.23647548258304596, 0.0019258027896285057, 0.6419774889945984, 0.7740586996078491, 3.8519036024808884e-05, 0.02161656692624092, 0.6103468537330627, 2.5507469177246094, 0.00047091420856304467, 0.0001931740262079984, 1.1111509799957275, 0.32290366291999817, 0.26988857984542847, 0.6659384369850159, 0.005051535088568926, 1.2989047765731812, 0.9109023213386536], "entropies_second": null, "final_normalized_entropy": -1.3026105103826549, "sequence_confidence_first": 0.7667993325467157, "sequence_confidence_second": null, "sequence_confidence_final": 0.7667993325467157, "token_confidences_first": [0.5780907869338989, 0.9988312125205994, 0.5237092971801758, 0.9497085213661194, 0.9998096823692322, 0.7172563076019287, 0.6718795895576477, 0.9999977350234985, 0.997260570526123, 0.7821648716926575, 0.3091319501399994, 0.9999638795852661, 0.9999873638153076, 0.6921322345733643, 0.9260367751121521, 0.9245983362197876, 0.8699070811271667, 0.9994328618049622, 0.41822561621665955, 0.686983585357666], "token_confidences_second": null, "final_mean_entropy": 0.5844850247405702, "final_min_margin": 0.08770179748535156, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The text extracted from the image is as follows:\n\nSQUADS MCL rcl", "used_ocr": true, "answer_first": "The image you've provided appears to be a collage of various cricket players, each representing", "answer_second": "The text extracted from the image is as follows:\n\nSQUADS MCL rcl", "raw_answer": "The text extracted from the image is as follows:\n\nSQUADS MCL rcl", "raw_answer_first": "The image you've provided appears to be a collage of various cricket players, each representing", "raw_answer_second": "The text extracted from the image is as follows:\n\nSQUADS MCL rcl", "mean_entropy_first": 1.2570863430781174, "normalized_entropy_first": 1.7398306267672698, "min_margin_first": 0.12296295166015625, "mean_entropy_second": 0.7114008950185962, "normalized_entropy_second": -0.598719957369987, "min_margin_second": 0.0728302001953125, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1133, "latency_ms_ocr": 1496, "latency_ms_second": 1487, "total_latency_ms": 4119, "total_latency_s": 4.119, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.3910199403762817, 0.07202987372875214, 1.6426022052764893, 0.309006005525589, 0.0048635974526405334, 0.7498747706413269, 1.113955020904541, 0.00036050923517905176, 0.08251062780618668, 0.4984220862388611, 2.7245373725891113, 0.0022591548040509224, 1.328728437423706, 3.0975611209869385, 2.6990365982055664, 0.2817429304122925, 1.8456313610076904, 1.9353625774383545, 2.3941969871520996, 2.9680256843566895], "entropies_second": [1.442519187927246, 1.7108700275421143, 1.4851806163787842, 0.11454609036445618, 0.010845489799976349, 0.04231622815132141, 2.01208233833313, 2.349853515625, 0.07770069688558578, 0.26951271295547485, 0.010557292029261589, 0.17168956995010376, 2.240135669708252, 0.013655005022883415, 0.00348845892585814, 0.037549152970314026, 0.6546170711517334, 0.3216097950935364, 1.1437937021255493, 0.11549527943134308], "final_normalized_entropy": -0.598719957369987, "sequence_confidence_first": 0.5700910261495993, "sequence_confidence_second": 0.775199200492518, "sequence_confidence_final": 0.775199200492518, "token_confidences_first": [0.4934437572956085, 0.9918491840362549, 0.40785109996795654, 0.9310837388038635, 0.9995392560958862, 0.635069727897644, 0.5835862755775452, 0.9999760389328003, 0.9872819781303406, 0.8618133664131165, 0.27787625789642334, 0.9997996687889099, 0.4758754074573517, 0.3347218632698059, 0.317543089389801, 0.9203686714172363, 0.5034206509590149, 0.3661109507083893, 0.3064330816268921, 0.30729421973228455], "token_confidences_second": [0.7344427108764648, 0.38098224997520447, 0.5021615028381348, 0.9853619337081909, 0.9987448453903198, 0.9952817559242249, 0.35443735122680664, 0.4201991856098175, 0.9903985261917114, 0.9467213153839111, 0.9989495873451233, 0.9718768000602722, 0.5254067778587341, 0.9987541437149048, 0.9996912479400635, 0.9964830875396729, 0.862962543964386, 0.9231281876564026, 0.8016476035118103, 0.9859495759010315], "final_mean_entropy": 0.7114008950185962, "final_min_margin": 0.0728302001953125, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image appears to be accurate based on the visual content.", "used_ocr": true, "answer_first": "The image shows two bar charts, each representing the percentage of people who follow five different sports. The", "answer_second": "The OCR-extracted text from the image appears to be accurate based on the visual content.", "raw_answer": "The OCR-extracted text from the image appears to be accurate based on the visual content.", "raw_answer_first": "The image shows two bar charts, each representing the percentage of people who follow five different sports. The", "raw_answer_second": "The OCR-extracted text from the image appears to be accurate based on the visual content.", "mean_entropy_first": 1.4425458371639253, "normalized_entropy_first": 2.1801482998881703, "min_margin_first": 0.21609878540039062, "mean_entropy_second": 0.7160555683280109, "normalized_entropy_second": -0.6952006586635666, "min_margin_second": 0.12022209167480469, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1298, "latency_ms_ocr": 369, "latency_ms_second": 1350, "total_latency_ms": 3020, "total_latency_s": 3.02, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8474916219711304, 0.08520388603210449, 1.8427095413208008, 0.8101556301116943, 2.3480851650238037, 0.7779484391212463, 2.324918270111084, 0.7144593000411987, 1.7108709812164307, 1.727565884590149, 2.9279098510742188, 0.3919845223426819, 3.186461925506592, 1.482008695602417, 0.7898755073547363, 2.1988558769226074, 0.9033653736114502, 0.12326610088348389, 2.5300376415252686, 1.1277425289154053], "entropies_second": [1.2950589656829834, 1.6258286237716675, 0.001110972836613655, 0.63972008228302, 0.20073740184307098, 0.000636171258520335, 0.003825631458312273, 1.9216225147247314, 0.017311785370111465, 0.018198110163211823, 1.828303337097168, 0.24963407218456268, 0.7208700180053711, 2.110269069671631, 2.024888038635254, 0.0015258064959198236, 0.08566061407327652, 0.4072396755218506, 0.06887608766555786, 1.0997943878173828], "final_normalized_entropy": -0.6952006586635666, "sequence_confidence_first": 0.519882847356213, "sequence_confidence_second": 0.726317889743997, "sequence_confidence_final": 0.726317889743997, "token_confidences_first": [0.6727489233016968, 0.989116370677948, 0.27729666233062744, 0.6037305593490601, 0.4478001594543457, 0.63324373960495, 0.3008204400539398, 0.8550348877906799, 0.5966914892196655, 0.4374087154865265, 0.28198814392089844, 0.9430409669876099, 0.18773165345191956, 0.6145079731941223, 0.8854975700378418, 0.2710500657558441, 0.6835039854049683, 0.9854234457015991, 0.2617223858833313, 0.7557355165481567], "token_confidences_second": [0.7367035150527954, 0.38195449113845825, 0.9999047517776489, 0.8363680243492126, 0.9686678051948547, 0.999946117401123, 0.9997052550315857, 0.3740445375442505, 0.997688889503479, 0.9979220032691956, 0.37998467683792114, 0.956181526184082, 0.8255159854888916, 0.31349068880081177, 0.32917770743370056, 0.99985671043396, 0.9880666732788086, 0.926717221736908, 0.9916178584098816, 0.7000569105148315], "final_mean_entropy": 0.7160555683280109, "final_min_margin": 0.12022209167480469, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This is an advertisement for the 2015 edition of the Wisden Crick", "used_ocr": false, "answer_first": "This is an advertisement for the 2015 edition of the Wisden Crick", "answer_second": null, "raw_answer": "This is an advertisement for the 2015 edition of the Wisden Crick", "raw_answer_first": "This is an advertisement for the 2015 edition of the Wisden Crick", "raw_answer_second": null, "mean_entropy_first": 0.6643111772427801, "normalized_entropy_first": -0.9702521748511197, "min_margin_first": 0.07108306884765625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1226, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1227, "total_latency_s": 1.227, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8840620517730713, 0.9050589799880981, 0.7195506691932678, 0.7897473573684692, 0.006380184553563595, 0.001825563726015389, 1.384756326675415, 1.0462262630462646, 1.7650651931762695, 0.5836752653121948, 0.04937785491347313, 0.016713237389922142, 0.02933354675769806, 1.2394672632217407, 0.013060025870800018, 1.042593002319336, 2.052302598953247, 0.008014647290110588, 0.4410630166530609, 0.307950496673584], "entropies_second": null, "final_normalized_entropy": -0.9702521748511197, "sequence_confidence_first": 0.7495221302065276, "sequence_confidence_second": null, "sequence_confidence_final": 0.7495221302065276, "token_confidences_first": [0.5015984177589417, 0.5065242052078247, 0.5637067556381226, 0.7927020192146301, 0.9992881417274475, 0.9998243451118469, 0.6004640460014343, 0.7703229188919067, 0.4739515483379364, 0.7558462023735046, 0.9927453398704529, 0.9978832602500916, 0.9962908029556274, 0.7399997711181641, 0.9987226128578186, 0.730570912361145, 0.3657057583332062, 0.9991466999053955, 0.9412304162979126, 0.9089257717132568], "token_confidences_second": null, "final_mean_entropy": 0.6643111772427801, "final_min_margin": 0.07108306884765625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "This image is a graphical representation of demographic estimates for the census metropolitan areas (CMA", "used_ocr": false, "answer_first": "This image is a graphical representation of demographic estimates for the census metropolitan areas (CMA", "answer_second": null, "raw_answer": "This image is a graphical representation of demographic estimates for the census metropolitan areas (CMA", "raw_answer_first": "This image is a graphical representation of demographic estimates for the census metropolitan areas (CMA", "raw_answer_second": null, "mean_entropy_first": 0.8134199848398567, "normalized_entropy_first": -0.3638610130835156, "min_margin_first": 0.039371490478515625, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1423, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1424, "total_latency_s": 1.424, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.7881197929382324, 0.8621994256973267, 1.2961912155151367, 0.5218984484672546, 3.1923718452453613, 0.711105227470398, 0.6236380934715271, 0.3287031352519989, 1.2003719806671143, 0.0671033263206482, 1.1372830867767334, 0.7444412708282471, 1.8957006931304932, 1.7221295833587646, 0.03506278246641159, 0.0023918149527162313, 0.08375555276870728, 1.0393089056015015, 0.015697410330176353, 0.0009261055383831263], "entropies_second": null, "final_normalized_entropy": -0.3638610130835156, "sequence_confidence_first": 0.6610081433673096, "sequence_confidence_second": null, "sequence_confidence_final": 0.6610081433673096, "token_confidences_first": [0.5071970224380493, 0.6270313262939453, 0.5936214923858643, 0.8791757822036743, 0.16401250660419464, 0.5370656847953796, 0.8775992393493652, 0.9445536136627197, 0.7095033526420593, 0.9879512190818787, 0.6026887893676758, 0.8588252067565918, 0.2960434556007385, 0.40880700945854187, 0.9956883788108826, 0.9997653365135193, 0.9845356345176697, 0.48709461092948914, 0.9983022212982178, 0.9999257326126099], "token_confidences_second": null, "final_mean_entropy": 0.8134199848398567, "final_min_margin": 0.039371490478515625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided appears to be a poster or infographic related to the ICC Cr", "used_ocr": false, "answer_first": "The image you've provided appears to be a poster or infographic related to the ICC Cr", "answer_second": null, "raw_answer": "The image you've provided appears to be a poster or infographic related to the ICC Cr", "raw_answer_first": "The image you've provided appears to be a poster or infographic related to the ICC Cr", "raw_answer_second": null, "mean_entropy_first": 0.6600416308181594, "normalized_entropy_first": -0.8988662456891235, "min_margin_first": 0.07561111450195312, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1126, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1133, "total_latency_s": 1.133, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.0547516345977783, 0.036918770521879196, 1.4661051034927368, 0.29649630188941956, 0.0021258238703012466, 0.6597391366958618, 0.8627341985702515, 6.692980241496116e-05, 0.02388366311788559, 0.564218282699585, 2.627333641052246, 0.24058309197425842, 2.3425674438476562, 0.024474555626511574, 1.6888574361801147, 0.00015694925969000906, 0.21097859740257263, 0.8671131134033203, 0.0015072966925799847, 0.23022064566612244], "entropies_second": null, "final_normalized_entropy": -0.8988662456891235, "sequence_confidence_first": 0.7255719544765111, "sequence_confidence_second": null, "sequence_confidence_final": 0.7255719544765111, "token_confidences_first": [0.4802348017692566, 0.9958646297454834, 0.5325955152511597, 0.9333095550537109, 0.9998088479042053, 0.7049670219421387, 0.608156144618988, 0.9999961853027344, 0.9970510005950928, 0.7928636074066162, 0.2261659950017929, 0.9612001180648804, 0.29892513155937195, 0.996595561504364, 0.4628352224826813, 0.99998939037323, 0.9646754264831543, 0.7377484440803528, 0.9998615980148315, 0.9517958760261536], "token_confidences_second": null, "final_mean_entropy": 0.6600416308181594, "final_min_margin": 0.07561111450195312, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image you've provided is a colorful infographic that provides information about healthcare jobs and", "used_ocr": false, "answer_first": "The image you've provided is a colorful infographic that provides information about healthcare jobs and", "answer_second": null, "raw_answer": "The image you've provided is a colorful infographic that provides information about healthcare jobs and", "raw_answer_first": "The image you've provided is a colorful infographic that provides information about healthcare jobs and", "raw_answer_second": null, "mean_entropy_first": 0.9116902415174991, "normalized_entropy_first": 0.10459050328578673, "min_margin_first": 0.07690811157226562, "mean_entropy_second": null, "normalized_entropy_second": null, "min_margin_second": null, "triggered": false, "ocr_engine": null, "latency_ms_first": 1252, "latency_ms_ocr": 0, "latency_ms_second": 0, "total_latency_ms": 1254, "total_latency_s": 1.254, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.9151940941810608, 0.09942060708999634, 1.5669599771499634, 0.27899444103240967, 0.0027957335114479065, 0.7002187967300415, 0.8623234033584595, 0.7453742623329163, 1.8258076906204224, 0.007213170640170574, 0.7270767688751221, 0.007854122668504715, 2.3742241859436035, 2.467761993408203, 1.9627184867858887, 0.7818142771720886, 1.0399771928787231, 0.011622326448559761, 0.4087725877761841, 1.4476807117462158], "entropies_second": null, "final_normalized_entropy": 0.10459050328578673, "sequence_confidence_first": 0.6295065296853382, "sequence_confidence_second": null, "sequence_confidence_final": 0.6295065296853382, "token_confidences_first": [0.5297808051109314, 0.9861722588539124, 0.47473111748695374, 0.9377537965774536, 0.9997488856315613, 0.6552152037620544, 0.5043584108352661, 0.6014837622642517, 0.4658946394920349, 0.9991734623908997, 0.807470440864563, 0.9991255402565002, 0.3915245234966278, 0.3049828112125397, 0.32959675788879395, 0.7183911800384521, 0.52687007188797, 0.9985935091972351, 0.9155208468437195, 0.40398675203323364], "token_confidences_second": null, "final_mean_entropy": 0.9116902415174991, "final_min_margin": 0.07690811157226562, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The image contains a table listing the fastest fifty in Twenty20 cricket, along with", "used_ocr": true, "answer_first": "The image appears to be a promotional graphic for a cricket match or event. It", "answer_second": "The image contains a table listing the fastest fifty in Twenty20 cricket, along with", "raw_answer": "The image contains a table listing the fastest fifty in Twenty20 cricket, along with", "raw_answer_first": "The image appears to be a promotional graphic for a cricket match or event. It", "raw_answer_second": "The image contains a table listing the fastest fifty in Twenty20 cricket, along with", "mean_entropy_first": 1.0892966968443942, "normalized_entropy_first": 0.7868243453864378, "min_margin_first": 0.12819480895996094, "mean_entropy_second": 1.0203613842095365, "normalized_entropy_second": 0.5199211318910024, "min_margin_second": 0.03459930419921875, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1347, "latency_ms_ocr": 803, "latency_ms_second": 1559, "total_latency_ms": 3712, "total_latency_s": 3.712, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [1.001951813697815, 0.08943117409944534, 1.72477388381958, 0.0003148504183627665, 0.05332638695836067, 0.659058153629303, 3.459420680999756, 0.0024372534826397896, 0.0007148374570533633, 1.4766712188720703, 0.008868762291967869, 1.4271448850631714, 1.520468831062317, 1.4592673778533936, 0.008924974128603935, 2.4929404258728027, 1.9345213174819946, 2.1948747634887695, 1.4363691806793213, 0.8344531655311584], "entropies_second": [1.4389926195144653, 1.7507905960083008, 1.8403630256652832, 1.9105708599090576, 2.0825796127319336, 2.1261696815490723, 0.9260122179985046, 1.4256739616394043, 0.0005689748213626444, 0.8389126062393188, 0.8555198311805725, 0.620945155620575, 0.005123055540025234, 0.023508399724960327, 0.010206996463239193, 0.1330602467060089, 0.014978081919252872, 2.235426902770996, 2.1674914360046387, 0.00033342218375764787], "final_normalized_entropy": 0.5199211318910024, "sequence_confidence_first": 0.5921022063497152, "sequence_confidence_second": 0.6467718324863493, "sequence_confidence_final": 0.6467718324863493, "token_confidences_first": [0.5057618021965027, 0.9892372488975525, 0.3219951093196869, 0.999976396560669, 0.9926322102546692, 0.7468427419662476, 0.17833875119686127, 0.9997797608375549, 0.99994957447052, 0.5593758821487427, 0.999053418636322, 0.5208714604377747, 0.5241838097572327, 0.7135167717933655, 0.9988835453987122, 0.23836608231067657, 0.29680871963500977, 0.3746471703052521, 0.5824009776115417, 0.7847133874893188], "token_confidences_second": [0.7031642198562622, 0.30265170335769653, 0.34898272156715393, 0.4143679440021515, 0.4909662902355194, 0.34986412525177, 0.8183063268661499, 0.5554283261299133, 0.9999549388885498, 0.7658059597015381, 0.8499454259872437, 0.8102328181266785, 0.999438464641571, 0.9976083040237427, 0.9989412426948547, 0.9751490950584412, 0.9980022311210632, 0.3553841710090637, 0.3759155571460724, 0.9999768733978271], "final_mean_entropy": 1.0203613842095365, "final_min_margin": 0.03459930419921875, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The OCR-extracted text from the image is mostly accurate, but there are a few minor", "used_ocr": true, "answer_first": "The image appears to be a promotional graphic for a cricket-related event or article", "answer_second": "The OCR-extracted text from the image is mostly accurate, but there are a few minor", "raw_answer": "The OCR-extracted text from the image is mostly accurate, but there are a few minor", "raw_answer_first": "The image appears to be a promotional graphic for a cricket-related event or article", "raw_answer_second": "The OCR-extracted text from the image is mostly accurate, but there are a few minor", "mean_entropy_first": 0.9850705653108889, "normalized_entropy_first": 0.31157665259200806, "min_margin_first": 0.08351325988769531, "mean_entropy_second": 0.8586877061432461, "normalized_entropy_second": -0.18895929328348124, "min_margin_second": 0.0401763916015625, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1349, "latency_ms_ocr": 334, "latency_ms_second": 1437, "total_latency_ms": 3123, "total_latency_s": 3.123, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8642092347145081, 0.038754113018512726, 1.4301531314849854, 0.000268679519649595, 0.028138747438788414, 0.7340455055236816, 1.4861083030700684, 0.0011466712458059192, 0.00034128129482269287, 1.431349754333496, 0.0017088046297430992, 1.5711941719055176, 1.6050310134887695, 2.013827085494995, 0.00871873740106821, 2.0680336952209473, 0.13269254565238953, 1.484510898590088, 1.395801067352295, 3.4053778648376465], "entropies_second": [1.0247564315795898, 1.5394270420074463, 0.0033987020142376423, 0.5235545039176941, 0.164115771651268, 0.000626633467618376, 0.0035142141859978437, 1.870084524154663, 0.010736626572906971, 0.027862509712576866, 1.7629904747009277, 2.402191162109375, 0.7197215557098389, 1.512535572052002, 1.3129409551620483, 0.6286017298698425, 0.6990140676498413, 0.5816096663475037, 0.42133814096450806, 1.9647338390350342], "final_normalized_entropy": -0.18895929328348124, "sequence_confidence_first": 0.6491304384812917, "sequence_confidence_second": 0.6706559126256706, "sequence_confidence_final": 0.6706559126256706, "token_confidences_first": [0.5066058039665222, 0.9953655004501343, 0.46891212463378906, 0.9999806880950928, 0.9967315196990967, 0.6039505004882812, 0.6818056702613831, 0.9999034404754639, 0.999976634979248, 0.5300574898719788, 0.9998378753662109, 0.4892389178276062, 0.49622368812561035, 0.5711011290550232, 0.9989511966705322, 0.36832255125045776, 0.9762544631958008, 0.6905179023742676, 0.5339337587356567, 0.18687602877616882], "token_confidences_second": [0.8080924153327942, 0.377512127161026, 0.9996832609176636, 0.8699017763137817, 0.9741591215133667, 0.9999463558197021, 0.9997208714485168, 0.368576318025589, 0.9987391829490662, 0.9963817596435547, 0.40423429012298584, 0.31047162413597107, 0.7233181595802307, 0.5314959287643433, 0.4379035234451294, 0.8687064051628113, 0.749740719795227, 0.8348038792610168, 0.8525990843772888, 0.3650931417942047], "final_mean_entropy": 0.8586877061432461, "final_min_margin": 0.0401763916015625, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
{"question": "", "image_id": null, "answers": [], "experiment": "entropy_routing_default", "routed": {"answer": "The text extracted from the image appears to be mostly accurate, with a few minor errors. Here'", "used_ocr": true, "answer_first": "This image appears to be a graphic or poster that presents a list of reasons why people might choose", "answer_second": "The text extracted from the image appears to be mostly accurate, with a few minor errors. Here'", "raw_answer": "The text extracted from the image appears to be mostly accurate, with a few minor errors. Here'", "raw_answer_first": "This image appears to be a graphic or poster that presents a list of reasons why people might choose", "raw_answer_second": "The text extracted from the image appears to be mostly accurate, with a few minor errors. Here'", "mean_entropy_first": 1.6839033095602645, "normalized_entropy_first": 3.197525143634765, "min_margin_first": 0.03495979309082031, "mean_entropy_second": 1.1453555983724073, "normalized_entropy_second": 0.9600813906174233, "min_margin_second": 0.04469490051269531, "triggered": true, "ocr_engine": "easyocr", "latency_ms_first": 1305, "latency_ms_ocr": 1276, "latency_ms_second": 1443, "total_latency_ms": 4025, "total_latency_s": 4.025, "model_id": "/root/OCR_route/OCR-route/llava-v1.6-vicuna-7b-hf", "image_source": "in_memory:None", "entropies_first": [0.8951196670532227, 0.829898476600647, 1.637256383895874, 0.0002945036976598203, 0.08622965216636658, 0.7457317113876343, 3.007737874984741, 0.3463120758533478, 2.223452568054199, 1.79723060131073, 2.445507049560547, 3.088528633117676, 2.3964884281158447, 2.7428746223449707, 0.3638714551925659, 3.2432801723480225, 2.2435836791992188, 2.3625502586364746, 2.1367902755737305, 1.0853281021118164], "entropies_second": [1.4203391075134277, 1.4306200742721558, 1.5060763359069824, 0.18501190841197968, 0.0034785824827849865, 0.00824130978435278, 1.8703854084014893, 0.18854689598083496, 0.7693133354187012, 2.427375316619873, 0.6142188310623169, 1.4389588832855225, 1.4963254928588867, 1.585054636001587, 0.46213969588279724, 1.3527854681015015, 2.1645960807800293, 1.5680277347564697, 1.350563883781433, 1.0650529861450195], "final_normalized_entropy": 0.9600813906174233, "sequence_confidence_first": 0.47625006088410404, "sequence_confidence_second": 0.5998586494621916, "sequence_confidence_final": 0.5998586494621916, "token_confidences_first": [0.5034105181694031, 0.7288331985473633, 0.3892824947834015, 0.999977707862854, 0.9889727234840393, 0.5563401579856873, 0.19889187812805176, 0.8987273573875427, 0.45233163237571716, 0.4335336983203888, 0.39572590589523315, 0.2103395313024521, 0.36004215478897095, 0.3910258114337921, 0.9417364597320557, 0.32874172925949097, 0.29147088527679443, 0.42356592416763306, 0.3573630154132843, 0.8172624111175537], "token_confidences_second": [0.7070393562316895, 0.47124913334846497, 0.4756263792514801, 0.973750114440918, 0.9996466636657715, 0.9991981387138367, 0.445026159286499, 0.9703670740127563, 0.8007816076278687, 0.2721306085586548, 0.8014861941337585, 0.5515814423561096, 0.4057700037956238, 0.4275887608528137, 0.9007490277290344, 0.7293246984481812, 0.3956994414329529, 0.46144673228263855, 0.621545672416687, 0.4386953115463257], "final_mean_entropy": 1.1453555983724073, "final_min_margin": 0.04469490051269531, "experiment": "entropy_routing_default"}, "routed_metrics": {"exact_match": 0.0, "accuracy": 0.0, "cer": 1.0, "wer": 1.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "rouge_l": 0.0, "anls": 0.0, "relaxed_accuracy": 0.0}}
